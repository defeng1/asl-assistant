{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_RNN.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZenXatqLrV"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KQj7fhn6v3G",
        "outputId": "65ef2c1e-c718-4dda-c30d-ea3c6ae0ad33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')\n",
        "#drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C11rm5RhqCwD"
      },
      "source": [
        "data_dir=\"/content/gdrive/My Drive/Capstone/Dataset/master_training_set\"\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9HlC_cI1c7K"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 200\n",
        "img_width = 200"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apRxKjFg2WIs",
        "outputId": "ab3ad681-3920-4bb7-d2f7-a8215174517e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4900 files belonging to 29 classes.\n",
            "Using 3920 files for training.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Mp_O8A2aaf",
        "outputId": "4008ac0b-04c7-4b39-d016-c9aee3dc5fd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4900 files belonging to 29 classes.\n",
            "Using 980 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5TEDMa2xth",
        "outputId": "ce3725e9-303d-40c2-f000-458bea013aaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 180
        }
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-4793ea69604d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'PrefetchDataset' object has no attribute 'class_names'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEj-n0X4fgC"
      },
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7FkueH35WQ2"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMmfr2Qe5aAD"
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZP7wb9c9zl_"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_pLFwx92UF",
        "outputId": "201b81a8-20d4-430e-e2c8-7ba6ce563ac7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        }
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-ce06c3301011>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    838\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 840\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    841\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 28 which is outside the valid range of [0, 2).  Label values: 19 19 14 5 7 12 28 20 20 10 3 18 10 1 28 20 26 19 16 26 24 10 17 11 0 15 11 23 12 15 24 8\n\t [[node sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at <ipython-input-28-ce06c3301011>:4) ]] [Op:__inference_train_function_1566]\n\nFunction call stack:\ntrain_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ek_pMgIC3Z5",
        "outputId": "c93e560c-90e4-4c03-a055-c120d8d5cdbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_dir=\"/content/gdrive/My Drive/Capstone/Dataset/Jing\"\n",
        "test_dir = pathlib.Path(test_dir)\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 200 files belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjInTfx7DuOG"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec4Svl7IgvxU",
        "outputId": "92d367cb-d1c8-4b5c-8853-3d679607557a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "data_dir=\"/content/gdrive/My Drive/Capstone/Dataset/master_training_set\"\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 200\n",
        "img_width = 200\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "print(class_names)\n",
        "\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "num_classes = 29\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=50\n",
        ")\n",
        "\n",
        "test_dir=\"/content/gdrive/My Drive/Capstone/Dataset/Jing\"\n",
        "test_dir = pathlib.Path(test_dir)\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 4900 files belonging to 29 classes.\n",
            "Using 3920 files for training.\n",
            "Found 4900 files belonging to 29 classes.\n",
            "Using 980 files for validation.\n",
            "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
            "Epoch 1/50\n",
            "123/123 [==============================] - 35s 285ms/step - loss: 1.8156 - accuracy: 0.4911 - val_loss: 0.3528 - val_accuracy: 0.9143\n",
            "Epoch 2/50\n",
            "123/123 [==============================] - 33s 268ms/step - loss: 0.1882 - accuracy: 0.9469 - val_loss: 0.1635 - val_accuracy: 0.9612\n",
            "Epoch 3/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.0453 - val_accuracy: 0.9939\n",
            "Epoch 4/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 0.0440 - accuracy: 0.9883 - val_loss: 0.0984 - val_accuracy: 0.9796\n",
            "Epoch 5/50\n",
            "123/123 [==============================] - 32s 263ms/step - loss: 0.0185 - accuracy: 0.9957 - val_loss: 0.0769 - val_accuracy: 0.9776\n",
            "Epoch 6/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 0.0230 - accuracy: 0.9934 - val_loss: 0.0747 - val_accuracy: 0.9847\n",
            "Epoch 7/50\n",
            "123/123 [==============================] - 32s 263ms/step - loss: 0.1168 - accuracy: 0.9730 - val_loss: 0.0766 - val_accuracy: 0.9857\n",
            "Epoch 8/50\n",
            "123/123 [==============================] - 32s 263ms/step - loss: 0.0275 - accuracy: 0.9939 - val_loss: 0.0215 - val_accuracy: 0.9949\n",
            "Epoch 9/50\n",
            "123/123 [==============================] - 32s 263ms/step - loss: 0.0031 - accuracy: 0.9995 - val_loss: 0.0118 - val_accuracy: 0.9980\n",
            "Epoch 10/50\n",
            "123/123 [==============================] - 32s 263ms/step - loss: 2.4915e-04 - accuracy: 1.0000 - val_loss: 0.0084 - val_accuracy: 0.9980\n",
            "Epoch 11/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 9.7197e-05 - accuracy: 1.0000 - val_loss: 0.0100 - val_accuracy: 0.9980\n",
            "Epoch 12/50\n",
            "123/123 [==============================] - 33s 270ms/step - loss: 6.7866e-05 - accuracy: 1.0000 - val_loss: 0.0098 - val_accuracy: 0.9980\n",
            "Epoch 13/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 5.5009e-05 - accuracy: 1.0000 - val_loss: 0.0097 - val_accuracy: 0.9980\n",
            "Epoch 14/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 4.6082e-05 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 0.9980\n",
            "Epoch 15/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 3.9487e-05 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
            "Epoch 16/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 3.4345e-05 - accuracy: 1.0000 - val_loss: 0.0095 - val_accuracy: 0.9980\n",
            "Epoch 17/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 3.0191e-05 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
            "Epoch 18/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 2.6798e-05 - accuracy: 1.0000 - val_loss: 0.0094 - val_accuracy: 0.9980\n",
            "Epoch 19/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 2.3953e-05 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
            "Epoch 20/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 2.1537e-05 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
            "Epoch 21/50\n",
            "123/123 [==============================] - 33s 269ms/step - loss: 1.9431e-05 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 0.9980\n",
            "Epoch 22/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 1.7561e-05 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
            "Epoch 23/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 1.5915e-05 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
            "Epoch 24/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 1.4467e-05 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
            "Epoch 25/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 1.3187e-05 - accuracy: 1.0000 - val_loss: 0.0092 - val_accuracy: 0.9980\n",
            "Epoch 26/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 1.2051e-05 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
            "Epoch 27/50\n",
            "123/123 [==============================] - 33s 264ms/step - loss: 1.1048e-05 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
            "Epoch 28/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 1.0146e-05 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
            "Epoch 29/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 9.3354e-06 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 0.9980\n",
            "Epoch 30/50\n",
            "123/123 [==============================] - 33s 267ms/step - loss: 8.6041e-06 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 31/50\n",
            "123/123 [==============================] - 33s 269ms/step - loss: 7.9408e-06 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 32/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 7.3447e-06 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 33/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 6.7987e-06 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 34/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 6.3011e-06 - accuracy: 1.0000 - val_loss: 0.0090 - val_accuracy: 0.9980\n",
            "Epoch 35/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 5.8460e-06 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
            "Epoch 36/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 5.4293e-06 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
            "Epoch 37/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 5.0453e-06 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
            "Epoch 38/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 4.6909e-06 - accuracy: 1.0000 - val_loss: 0.0089 - val_accuracy: 0.9980\n",
            "Epoch 39/50\n",
            "123/123 [==============================] - 33s 267ms/step - loss: 4.3660e-06 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
            "Epoch 40/50\n",
            "123/123 [==============================] - 33s 269ms/step - loss: 4.0631e-06 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
            "Epoch 41/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 3.7882e-06 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
            "Epoch 42/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 3.5288e-06 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 0.9980\n",
            "Epoch 43/50\n",
            "123/123 [==============================] - 33s 264ms/step - loss: 3.2931e-06 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "Epoch 44/50\n",
            "123/123 [==============================] - 32s 264ms/step - loss: 3.0704e-06 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "Epoch 45/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 2.8682e-06 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "Epoch 46/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 2.6746e-06 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "Epoch 47/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 2.4972e-06 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "Epoch 48/50\n",
            "123/123 [==============================] - 33s 266ms/step - loss: 2.3275e-06 - accuracy: 1.0000 - val_loss: 0.0087 - val_accuracy: 0.9980\n",
            "Epoch 49/50\n",
            "123/123 [==============================] - 33s 265ms/step - loss: 2.1711e-06 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
            "Epoch 50/50\n",
            "123/123 [==============================] - 33s 271ms/step - loss: 2.0230e-06 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 0.9980\n",
            "Found 1900 files belonging to 29 classes.\n",
            "60/60 [==============================] - 308s 5s/step - loss: 33.7667 - accuracy: 0.0626\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}