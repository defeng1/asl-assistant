{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_RNN.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZenXatqLrV"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KQj7fhn6v3G"
      },
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')\n",
        "#drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_3oznL7YXSQ"
      },
      "source": [
        "# check number of files in each directory\n",
        "\n",
        "import glob\n",
        "\n",
        "classnames = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
        "totalcount = 0\n",
        "for name in classnames:\n",
        "  data_files = glob.glob(\"/content/gdrive/My Drive/Capstone/Dataset/combined_set/\" + name + \"/*\")\n",
        "  count = 0\n",
        "  for data_file in data_files:\n",
        "    count += 1\n",
        "    totalcount += 1\n",
        "  print(name + \":\" + str(count))\n",
        "print(\"total number of images:\" + str(totalcount))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C11rm5RhqCwD"
      },
      "source": [
        "data_dir=\"/content/gdrive/My Drive/Capstone/Dataset/master_training_set\"\n",
        "data_dir = pathlib.Path(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F9HlC_cI1c7K"
      },
      "source": [
        "batch_size = 32\n",
        "img_height = 200\n",
        "img_width = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apRxKjFg2WIs"
      },
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9Mp_O8A2aaf"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_5TEDMa2xth"
      },
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZEj-n0X4fgC"
      },
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7FkueH35WQ2"
      },
      "source": [
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMmfr2Qe5aAD"
      },
      "source": [
        "num_classes = 2\n",
        "\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZP7wb9c9zl_"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mk_pLFwx92UF"
      },
      "source": [
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=3\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ek_pMgIC3Z5"
      },
      "source": [
        "test_dir=\"/content/gdrive/My Drive/Capstone/Dataset/Jing\"\n",
        "test_dir = pathlib.Path(test_dir)\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IjInTfx7DuOG"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec4Svl7IgvxU",
        "outputId": "ce4090ad-2892-4a35-aec9-e858d9d66057",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#data_dir= \"/content/gdrive/My Drive/Capstone/Dataset/master_training_set\"\n",
        "data_dir = \"/content/gdrive/My Drive/Capstone/Dataset/combined_set\"\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 200\n",
        "img_width = 200\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  follow_links=True)\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  follow_links=True)\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "print(class_names)\n",
        "\n",
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "# AUTOTUNE in keras is -1 as a constant\n",
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "# val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "\n",
        "num_classes = 29\n",
        "model = tf.keras.Sequential([\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Conv2D(32, 3, activation='relu'),\n",
        "  layers.MaxPooling2D(),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(128, activation='relu'),\n",
        "  layers.Dense(num_classes)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(\n",
        "  train_ds,\n",
        "  validation_data=val_ds,\n",
        "  epochs=5\n",
        ")\n",
        "\n",
        "model.save(\"gdrive/My Drive/Capstone/models/nov_6_2020\")\n",
        "\n",
        "# Note: something is wrong with saving the model!\n",
        "# https://www.tensorflow.org/guide/saved_model\n",
        "\n",
        "# test_dir=\"/content/gdrive/My Drive/Capstone/Dataset/Jing\"\n",
        "# test_dir = pathlib.Path(test_dir)\n",
        "# test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "#   test_dir,\n",
        "#   image_size=(img_height, img_width),\n",
        "#   batch_size=batch_size)\n",
        "# test_loss, test_acc = model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 17707 files belonging to 29 classes.\n",
            "Using 14166 files for training.\n",
            "Found 17707 files belonging to 29 classes.\n",
            "Using 3541 files for validation.\n",
            "['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
            "Epoch 1/5\n",
            "443/443 [==============================] - 147s 331ms/step - loss: 2.1036 - sparse_categorical_accuracy: 0.4251 - val_loss: 0.8746 - val_sparse_categorical_accuracy: 0.7509\n",
            "Epoch 2/5\n",
            "443/443 [==============================] - 148s 334ms/step - loss: 0.4429 - sparse_categorical_accuracy: 0.8762 - val_loss: 0.4476 - val_sparse_categorical_accuracy: 0.8752\n",
            "Epoch 3/5\n",
            "443/443 [==============================] - 146s 331ms/step - loss: 0.1325 - sparse_categorical_accuracy: 0.9620 - val_loss: 0.5270 - val_sparse_categorical_accuracy: 0.8709\n",
            "Epoch 4/5\n",
            "443/443 [==============================] - 149s 335ms/step - loss: 0.0855 - sparse_categorical_accuracy: 0.9776 - val_loss: 0.2982 - val_sparse_categorical_accuracy: 0.9274\n",
            "Epoch 5/5\n",
            "443/443 [==============================] - 147s 331ms/step - loss: 0.0914 - sparse_categorical_accuracy: 0.9751 - val_loss: 0.3169 - val_sparse_categorical_accuracy: 0.9175\n",
            "INFO:tensorflow:Assets written to: gdrive/My Drive/Capstone/models/nov_1_2020_2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3glZBL-rwZM"
      },
      "source": [
        "# Model fit -> evaluate -> save -> load: consistently produces ~2-4% accuracy\n",
        "eval_model = tf.keras.models.load_model(\"gdrive/My Drive/Capstone/models/nov_6_2020\")\n",
        "\n",
        "# Model fit -> evaluate: produces good accuracy on results\n",
        "test_loss, test_acc = model.evaluate(val_ds, verbose=1)\n",
        "test_loss, test_acc = eval_model.evaluate(val_ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShplgldkNrNP"
      },
      "source": [
        "eval_model = tf.keras.models.load_model(\"gdrive/My Drive/Capstone/models/nov_6_2020\")\n",
        "dir = \"/content/gdrive/My Drive/Capstone/Dataset/test_set\"\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "test_names = test_ds.class_names\n",
        "\n",
        "test_loss, test_acc = eval_model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywSnjYj8GwXo",
        "outputId": "5f5e6048-a03a-46a8-fd2d-186be26128db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# attempt to train loaded model on additional ASL Alphabet training data\n",
        "model = tf.keras.models.load_model(\"gdrive/My Drive/Capstone/models/nov_6_2020\")\n",
        "\n",
        "asl_alphabet_dir = \"/content/gdrive/My Drive/Capstone/Dataset/ASL Alphabet/asl_alphabet_train/asl_alphabet_train\"\n",
        "asl_alphabet_dir = pathlib.Path(asl_alphabet_dir)\n",
        "\n",
        "batch_size = 32\n",
        "img_height = 200\n",
        "img_width = 200\n",
        "\n",
        "asl_train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  asl_alphabet_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  follow_links=True)\n",
        "\n",
        "asl_val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  asl_alphabet_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size,\n",
        "  follow_links=True)\n",
        "class_names = asl_train_ds.class_names\n",
        "\n",
        "model.fit(\n",
        "  asl_train_ds,\n",
        "  validation_data=asl_val_ds,\n",
        "  epochs=5\n",
        ")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 86000 files belonging to 29 classes.\n",
            "Using 68800 files for training.\n",
            "Found 86000 files belonging to 29 classes.\n",
            "Using 17200 files for validation.\n",
            "Epoch 1/5\n",
            "2150/2150 [==============================] - 19046s 9s/step - loss: 0.8208 - sparse_categorical_accuracy: 0.7727 - val_loss: 0.1862 - val_sparse_categorical_accuracy: 0.9399\n",
            "Epoch 2/5\n",
            "2150/2150 [==============================] - 761s 354ms/step - loss: 0.1120 - sparse_categorical_accuracy: 0.9632 - val_loss: 0.0717 - val_sparse_categorical_accuracy: 0.9762\n",
            "Epoch 3/5\n",
            "2150/2150 [==============================] - 759s 353ms/step - loss: 0.0670 - sparse_categorical_accuracy: 0.9779 - val_loss: 0.0762 - val_sparse_categorical_accuracy: 0.9747\n",
            "Epoch 4/5\n",
            "2150/2150 [==============================] - 720s 335ms/step - loss: 0.0483 - sparse_categorical_accuracy: 0.9849 - val_loss: 0.1124 - val_sparse_categorical_accuracy: 0.9692\n",
            "Epoch 5/5\n",
            "2150/2150 [==============================] - 691s 321ms/step - loss: 0.0399 - sparse_categorical_accuracy: 0.9875 - val_loss: 0.0514 - val_sparse_categorical_accuracy: 0.9853\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ffe733b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3oDNuuT-oFim",
        "outputId": "73048342-c94b-4b0c-cdb6-5c97759cd169",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.save(\"gdrive/My Drive/Capstone/models/nov_8_2020\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: gdrive/My Drive/Capstone/models/nov_8_2020/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrXDcn8woNfH",
        "outputId": "caeb5899-85a0-4d21-89f4-9425f36ecc9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "eval_model = tf.keras.models.load_model(\"gdrive/My Drive/Capstone/models/nov_8_2020\")\n",
        "dir = \"/content/gdrive/My Drive/Capstone/Dataset/test_set\"\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  dir,\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=batch_size)\n",
        "test_names = test_ds.class_names\n",
        "\n",
        "test_loss, test_acc = eval_model.evaluate(test_ds, verbose=1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8702 files belonging to 29 classes.\n",
            "272/272 [==============================] - 1739s 6s/step - loss: 27.3610 - sparse_categorical_accuracy: 0.1230\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}