{"version":3,"file":"tf-backend-cpu.es2017.min.js","sources":["../src/cpu_util.ts","../src/backend_cpu.ts","../src/kernels/Abs.ts","../src/utils/binary_impl.ts","../src/kernels/Complex.ts","../src/kernels/Identity.ts","../src/kernels/Real.ts","../src/kernels/Cast.ts","../src/utils/kernel_utils.ts","../src/kernels/Add.ts","../src/utils/unary_impl.ts","../src/utils/unary_utils.ts","../src/kernels/Ceil.ts","../src/kernels/Exp.ts","../src/kernels/Expm1.ts","../src/kernels/Floor.ts","../src/kernels/Log.ts","../src/kernels/Max_impl.ts","../src/kernels/Multiply.ts","../src/kernels/NotEqual.ts","../src/kernels/Rsqrt.ts","../src/kernels/Slice.ts","../src/kernels/SquaredDifference.ts","../src/kernels/Sub.ts","../src/kernels/Transpose_impl.ts","../src/kernels/Unique_impl.ts","../src/base.ts","../src/kernels/Elu.ts","../src/kernels/Prelu.ts","../src/kernels/Relu.ts","../src/kernels/Relu6.ts","../src/utils/fused_utils.ts","../src/kernels/Reshape.ts","../src/kernels/BatchMatMul.ts","../src/kernels/_FusedMatMul.ts","../src/kernels/Acos.ts","../src/kernels/Acosh.ts","../src/kernels/Asin.ts","../src/kernels/Asinh.ts","../src/kernels/Atan.ts","../src/kernels/Atanh.ts","../src/utils/pool_utils.ts","../src/kernels/AvgPool.ts","../src/kernels/AvgPoolBackprop.ts","../src/kernels/BatchNorm.ts","../src/kernels/Clip.ts","../src/kernels/Imag.ts","../src/kernels/Concat.ts","../src/kernels/Conv2D.ts","../src/kernels/Conv2DBackpropFilter.ts","../src/kernels/Conv2DBackpropInput.ts","../src/kernels/Conv3D.ts","../src/kernels/Conv3DBackpropFilterV2.ts","../src/kernels/Conv3DBackpropInputV2.ts","../src/kernels/Cos.ts","../src/kernels/Cosh.ts","../src/kernels/DepthwiseConv2dNative.ts","../src/kernels/DepthwiseConv2dNativeBackpropFilter.ts","../src/kernels/DepthwiseConv2dNativeBackpropInput.ts","../src/kernels/Dilation2D.ts","../src/kernels/Dilation2DBackpropFilter.ts","../src/kernels/Dilation2DBackpropInput.ts","../src/kernels/Div.ts","../src/kernels/Erf.ts","../src/utils/fft_utils.ts","../src/kernels/FFT.ts","../src/kernels/Fill.ts","../src/kernels/FlipLeftRight.ts","../src/kernels/FusedConv2D.ts","../src/kernels/FusedDepthwiseConv2D.ts","../src/kernels/IFFT.ts","../src/kernels/IsFinite.ts","../src/kernels/IsInf.ts","../src/kernels/IsNaN.ts","../src/kernels/Log1p.ts","../src/kernels/LogicalNot.ts","../src/kernels/Max.ts","../src/kernels/MaxPool.ts","../src/kernels/MaxPoolBackprop.ts","../src/kernels/MaxPoolWithArgmax.ts","../src/kernels/MaxPoolWithArgmax_impl.ts","../src/kernels/MirrorPad.ts","../src/kernels/NonMaxSuppressionV4.ts","../src/kernels/NonMaxSuppressionV5.ts","../src/kernels/PadV2.ts","../src/kernels/Reciprocal.ts","../src/kernels/RotateWithOffset.ts","../src/kernels/Round.ts","../src/kernels/Selu.ts","../src/kernels/Sigmoid.ts","../src/kernels/Sign.ts","../src/kernels/Sin.ts","../src/kernels/Sinh.ts","../src/kernels/Softplus.ts","../src/kernels/Transpose.ts","../src/kernels/SpaceToBatchND.ts","../src/kernels/Sqrt.ts","../src/kernels/Square.ts","../src/kernels/Step.ts","../src/kernels/Tan.ts","../src/kernels/Tanh.ts","../src/kernels/Unique.ts","../src/register_all_kernels.ts","../src/version.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {TensorInfo, util} from '@tensorflow/tfjs-core';\n\nexport function assertNotComplex(\n    tensor: TensorInfo|TensorInfo[], opName: string): void {\n  if (!Array.isArray(tensor)) {\n    tensor = [tensor];\n  }\n  tensor.forEach(t => {\n    if (t != null) {\n      util.assert(\n          t.dtype !== 'complex64',\n          () => `${\n              opName} does not support complex64 tensors in the CPU backend.`);\n    }\n  });\n}\n","/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport * as tf from '@tensorflow/tfjs-core';\nimport {backend_util, BackendTimingInfo, DataStorage, DataType, DataValues, engine, env, kernel_impls, KernelBackend, max, NumericDataType, Rank, Scalar, ShapeMap, slice_util, Tensor, Tensor1D, Tensor2D, Tensor4D, Tensor5D, TensorBuffer, TensorInfo, TypedArray, upcastType, util} from '@tensorflow/tfjs-core';\n\nconst nonMaxSuppressionV3Impl = kernel_impls.nonMaxSuppressionV3Impl;\nconst split = kernel_impls.split;\nconst tile = kernel_impls.tile;\nconst topkImpl = kernel_impls.topkImpl;\nconst whereImpl = kernel_impls.whereImpl;\nimport * as seedrandom from 'seedrandom';\nimport {assertNotComplex} from './cpu_util';\n\ninterface DataId {}\n\nexport interface TensorData<D extends DataType> {\n  values?: backend_util.BackendValues;\n  dtype: D;\n  // For complex numbers, the real and imaginary parts are stored as their own\n  // individual tensors, with a parent joining the two with the\n  // complexTensorInfos field.\n  complexTensorInfos?: {real: TensorInfo, imag: TensorInfo};\n  // refCount keeps track of how many tensors reference it. Used for memory\n  // management.\n  refCount: number;\n}\n\nexport class MathBackendCPU extends KernelBackend {\n  public blockSize = 48;\n\n  data: DataStorage<TensorData<DataType>>;\n  private firstUse = true;\n\n  constructor() {\n    super();\n    this.data = new DataStorage(this, engine());\n  }\n\n  write(values: backend_util.BackendValues, shape: number[], dtype: DataType):\n      DataId {\n    if (this.firstUse) {\n      this.firstUse = false;\n      if (env().get('IS_NODE')) {\n        backend_util.warn(\n            '\\n============================\\n' +\n            'Hi there ðŸ‘‹. Looks like you are running TensorFlow.js in ' +\n            'Node.js. To speed things up dramatically, install our node ' +\n            'backend, which binds to TensorFlow C++, by running ' +\n            'npm i @tensorflow/tfjs-node, ' +\n            'or npm i @tensorflow/tfjs-node-gpu if you have CUDA. ' +\n            'Then call require(\\'@tensorflow/tfjs-node\\'); (-gpu ' +\n            'suffix for CUDA) at the start of your program. ' +\n            'Visit https://github.com/tensorflow/tfjs-node for more details.' +\n            '\\n============================');\n      }\n    }\n    const dataId = {};\n\n    this.data.set(dataId, {values, dtype, refCount: 1});\n\n    return dataId;\n  }\n\n  /**\n   * Create a data bucket in cpu backend.\n   * @param shape Shape of the `TensorInfo`.\n   * @param dtype DType of the `TensorInfo`.\n   * @param values The value of the `TensorInfo` stored as a flattened array.\n   */\n  makeTensorInfo(\n      shape: number[], dtype: DataType,\n      values?: backend_util.BackendValues|string[]): TensorInfo {\n    let outId;\n    if (dtype === 'string' && values != null && values.length > 0 &&\n        util.isString(values[0])) {\n      const encodedValues =\n          (values as {} as string[]).map(d => util.encodeString(d));\n\n      outId = this.write(encodedValues, shape, dtype);\n    } else {\n      outId = this.write(values as TypedArray, shape, dtype);\n    }\n\n    return {dataId: outId, shape, dtype};\n  }\n\n  /** Increase refCount of a `TensorData`. */\n  incRef(dataId: DataId): void {\n    const tensorData = this.data.get(dataId);\n    tensorData.refCount++;\n  }\n\n  /** Decrease refCount of a `TensorData`. */\n  decRef(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n      tensorData.refCount--;\n    }\n  }\n\n  move(\n      dataId: DataId, values: backend_util.BackendValues, shape: number[],\n      dtype: DataType): void {\n    this.data.set(dataId, {values, dtype, refCount: 1});\n  }\n\n  numDataIds(): number {\n    return this.data.numDataIds();\n  }\n\n  async read(dataId: DataId): Promise<backend_util.BackendValues> {\n    return this.readSync(dataId);\n  }\n  readSync(dataId: DataId): backend_util.BackendValues {\n    const {dtype, complexTensorInfos} = this.data.get(dataId);\n\n    if (dtype === 'complex64') {\n      const realValues =\n          this.readSync(complexTensorInfos.real.dataId) as Float32Array;\n      const imagValues =\n          this.readSync(complexTensorInfos.imag.dataId) as Float32Array;\n      return backend_util.mergeRealAndImagArrays(realValues, imagValues);\n    }\n\n    return this.data.get(dataId).values;\n  }\n\n  private bufferSync<R extends Rank>(t: Tensor<R>): TensorBuffer<R> {\n    const data = this.readSync(t.dataId);\n    let decodedData = data as DataValues;\n    if (t.dtype === 'string') {\n      try {\n        // Decode the bytes into string.\n        decodedData = (data as Uint8Array[]).map(d => util.decodeString(d));\n      } catch {\n        throw new Error('Failed to decode encoded string bytes into utf-8');\n      }\n    }\n    return tf.buffer(t.shape, t.dtype, decodedData) as TensorBuffer<R>;\n  }\n\n  makeOutput<T extends Tensor>(\n      values: backend_util.BackendValues, shape: number[], dtype: DataType): T {\n    const dataId = this.write(values, shape, dtype);\n    return engine().makeTensorFromDataId(dataId, shape, dtype, this) as T;\n  }\n\n  disposeData(dataId: DataId): void {\n    if (this.data.has(dataId)) {\n      const {complexTensorInfos} = this.data.get(dataId);\n\n      if (complexTensorInfos != null) {\n        this.disposeData(complexTensorInfos.real.dataId);\n        this.disposeData(complexTensorInfos.imag.dataId);\n      }\n\n      this.data.delete(dataId);\n    }\n  }\n\n  disposeIntermediateTensorInfo(tensorInfo: TensorInfo): void {\n    const dataId = tensorInfo.dataId;\n\n    if (this.data.has(dataId)) {\n      const tensorData = this.data.get(dataId);\n\n      tensorData.refCount--;\n\n      if (tensorData.refCount < 1) {\n        this.disposeData(dataId);\n      }\n    }\n  }\n\n  async time(f: () => void): Promise<BackendTimingInfo> {\n    const start = util.now();\n    f();\n    const kernelMs = util.now() - start;\n    return {kernelMs};\n  }\n\n  memory() {\n    return {\n      // Unreliable due to automatic gc. The numbers above are cumulative.\n      unreliable: true,\n      reasons:\n          ['The reported memory is an upper bound. Due to automatic garbage ' +\n           'collection, the true allocated memory may be less.']\n    };\n  }\n\n  stridedSlice<T extends Tensor>(\n      x: T, begin: number[], end: number[], strides: number[]): T {\n    assertNotComplex(x, 'stridedSlice');\n\n    const outShape = slice_util.computeOutShape(begin, end, strides);\n\n    if (outShape.some(axis => axis === 0)) {\n      return tf.tensor([], outShape) as T;\n    }\n\n    const buffer = tf.buffer(outShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n    for (let i = 0; i < buffer.size; i++) {\n      const loc = buffer.indexToLoc(i);\n\n      const newLoc: number[] = new Array(loc.length);\n      for (let j = 0; j < newLoc.length; j++) {\n        newLoc[j] = loc[j] * strides[j] + begin[j];\n      }\n      buffer.set(xBuf.get(...newLoc), ...loc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  diag(x: Tensor): Tensor {\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    const buffer = tf.buffer([x.size, x.size], x.dtype);\n    const vals = buffer.values;\n    for (let i = 0; i < xVals.length; i++) {\n      vals[i * x.size + i] = xVals[i];\n    }\n    return buffer.toTensor();\n  }\n\n  unstack(x: Tensor, axis: number): Tensor[] {\n    const num = x.shape[axis];\n    const outShape: number[] = new Array(x.rank - 1);\n    let outIndex = 0;\n    for (let i = 0; i < x.rank; i++) {\n      if (i !== axis) {\n        outShape[outIndex++] = x.shape[i];\n      }\n    }\n\n    const begin = new Array(x.rank).fill(0);\n    const size = x.shape.slice();\n    size[axis] = 1;\n    const res = new Array(num);\n    for (let i = 0; i < res.length; i++) {\n      begin[axis] = i;\n      res[i] = tf.slice(x, begin, size).reshape(outShape);\n    }\n    return res;\n  }\n\n  reverse<T extends Tensor>(x: T, axis: number[]): T {\n    assertNotComplex(x, 'reverse');\n\n    const buffer = tf.buffer(x.shape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < buffer.size; i++) {\n      const outLoc = buffer.indexToLoc(i);\n      const inLoc = outLoc.slice();\n      axis.forEach(ax => inLoc[ax] = x.shape[ax] - 1 - inLoc[ax]);\n      buffer.set(xBuf.get(...inLoc), ...outLoc);\n    }\n\n    return buffer.toTensor() as T;\n  }\n\n  neg<T extends Tensor>(x: T): T {\n    assertNotComplex(x, 'neg');\n\n    // TODO(lina128): Use mul directly once neg is modularized.\n    return tf.mul(tf.scalar(-1), x);\n  }\n\n  addN<T extends Tensor>(tensors: T[]): T {\n    assertNotComplex(tensors, 'addN');\n\n    const vals = tensors.map(t => this.readSync(t.dataId) as TypedArray);\n    const result = tf.buffer(tensors[0].shape, tensors[0].dtype as 'float32');\n    const resultVals = result.values;\n    for (let i = 0; i < tensors.length; i++) {\n      const currVals = vals[i];\n      for (let j = 0; j < resultVals.length; j++) {\n        resultVals[j] += currVals[j];\n      }\n    }\n    return result.toTensor() as T;\n  }\n\n  softmax<T extends Tensor>(logits: T, dim: number): T {\n    const axes = util.parseAxisParam([dim], logits.shape);\n    // TODO(annxingyuan): Call maxImpl rather than op as part of softmax kernel\n    // modularization.\n    const maxLogit = max(logits, axes);\n    const expandedShape =\n        backend_util.expandShapeToKeepDim(maxLogit.shape, axes);\n\n    // TODO(lina128): Use sub directly once softmax is modularized.\n    const a = tf.sub(logits, maxLogit.reshape(expandedShape));\n    const b = tf.exp(a);\n    const sumExp = this.sum(b, axes).reshape(expandedShape);\n\n    // TODO(annxingyuan): Call divImpl rather than op as part of softmax\n    // kernel modularization.\n    return tf.div(b, sumExp);\n  }\n\n  pow<T extends Tensor>(a: T, b: Tensor): T {\n    assertNotComplex([a, b], 'pow');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.pow(aValue, bValue)) as\n        T;\n  }\n\n  floorDiv(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'floorDiv');\n\n    const op = (a: number, b: number) => Math.floor(a / b);\n    const outputDtype = 'int32';\n    return this.broadcastedBinaryOp(a, b, outputDtype, op);\n  }\n\n  sum(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    backend_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let sum = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        sum += aVals[offset + j];\n      }\n      vals[i] = sum;\n    }\n    return result;\n  }\n\n  prod(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'sum');\n\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(outShape, resultDtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let prod = 1;\n      for (let j = 0; j < reduceSize; ++j) {\n        prod *= aVals[offset + j];\n      }\n      vals[i] = prod;\n    }\n    return result;\n  }\n\n  unsortedSegmentSum<T extends Tensor>(\n      x: T, segmentIds: Tensor1D, numSegments: number): Tensor {\n    assertNotComplex(x, 'unsortedSegmentSum');\n\n    const res = [];\n\n    // Reshape the segment id's so that they can be broadcast with\n    // x. The new shape should be [segmentIds.shape, 1, ..., 1]\n    const numIters = x.rank - segmentIds.rank;\n    for (let i = 0; i < numIters; ++i) {\n      segmentIds = segmentIds.expandDims(i + 1);\n    }\n\n    for (let i = 0; i < numSegments; ++i) {\n      const segmentId = tf.scalar(i, 'int32');\n      const mask = tf.equal(segmentId, segmentIds).asType('float32');\n      const sum = mask.mul(x).sum(0);\n      res.push(sum);\n    }\n\n    return tf.stack(res);\n  }\n\n  argMin(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMin');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMin', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      let minIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n          minIndex = j;\n        }\n      }\n      vals[i] = minIndex;\n    }\n    return result;\n  }\n\n  argMax(x: Tensor, axis: number): Tensor {\n    assertNotComplex(x, 'argMax');\n\n    const axes = [axis];\n    backend_util.assertAxesAreInnerMostDims('argMax', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, 'int32');\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let max = aVals[offset];\n      let maxIndex = 0;\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value > max) {\n          max = value;\n          maxIndex = j;\n        }\n      }\n      vals[i] = maxIndex;\n    }\n    return result;\n  }\n\n  cumsum(x: Tensor, axis: number, exclusive: boolean, reverse: boolean):\n      Tensor {\n    assertNotComplex(x, 'cumsum');\n\n    if (axis !== x.rank - 1) {\n      throw new Error(\n          `backend.cumsum in CPU expects an inner-most axis=${x.rank - 1} ` +\n          `but got axis=${axis}`);\n    }\n    const resultDtype = upcastType(x.dtype, 'int32');\n    const result = tf.zeros(x.shape, resultDtype);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    const finalDim = x.shape[x.rank - 1];\n    const indexAdjuster = reverse ?\n        (i: number, j: number) => i + finalDim - j - 1 :\n        (i: number, j: number) => i + j;\n    for (let i = 0; i < aVals.length; i += finalDim) {\n      for (let j = 0; j < finalDim; j++) {\n        const idx = indexAdjuster(i, j);\n        if (j === 0) {\n          vals[idx] = exclusive ? 0 : aVals[idx];\n        } else {\n          const prevIdx = indexAdjuster(i, j - 1);\n          vals[idx] = exclusive ? aVals[prevIdx] + vals[prevIdx] :\n                                  aVals[idx] + vals[prevIdx];\n        }\n      }\n    }\n    return result;\n  }\n\n  equal(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'equal');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal === bVal) ? 1 : 0;\n    });\n  }\n\n  notEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'notEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal !== bVal) ? 1 : 0;\n    });\n  }\n\n  less(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'less');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal < bVal) ? 1 : 0;\n    });\n  }\n\n  lessEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'lessEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal <= bVal) ? 1 : 0;\n    });\n  }\n\n  greater(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greater');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal > bVal) ? 1 : 0;\n    });\n  }\n\n  greaterEqual(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'greaterEqual');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return (aVal >= bVal) ? 1 : 0;\n    });\n  }\n\n  logicalAnd(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalAnd');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal && bVal;\n    });\n  }\n\n  logicalOr(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'logicalOr');\n\n    return this.broadcastedBinaryOp(a, b, 'bool', (aVal, bVal) => {\n      return aVal || bVal;\n    });\n  }\n\n  select(condition: Tensor, a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([condition, a, b], 'select');\n\n    const values = this.readSync(condition.dataId) as TypedArray;\n    const aValues = this.readSync(a.dataId) as TypedArray;\n    const bValues = this.readSync(b.dataId) as TypedArray;\n    const result = tf.zeros(a.shape, upcastType(a.dtype, b.dtype));\n    const newValues = this.readSync(result.dataId) as TypedArray;\n    let index = 0;\n    const offset = condition.rank === 0 || condition.rank > 1 || a.rank === 1 ?\n        1 :\n        util.sizeFromShape(a.shape.slice(1));\n\n    for (let i = 0; i < values.length; i++) {\n      for (let j = 0; j < offset; j++) {\n        if (values[i] === 1) {\n          newValues[index++] = aValues[i];\n        } else {\n          newValues[index++] = bValues[i];\n        }\n      }\n    }\n\n    return result;\n  }\n\n  where(condition: Tensor): Tensor2D {\n    assertNotComplex([condition], 'where');\n\n    const condVals = this.readSync(condition.dataId) as TypedArray;\n    return whereImpl(condition.shape, condVals);\n  }\n\n  topk<T extends Tensor>(x: T, k: number, sorted: boolean): [T, T] {\n    assertNotComplex(x, 'topk');\n\n    const xVals = this.readSync(x.dataId) as TypedArray;\n    return topkImpl(xVals, x.shape, x.dtype as NumericDataType, k, sorted);\n  }\n\n  min(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'min');\n\n    backend_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let min = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        if (value < min) {\n          min = value;\n        }\n      }\n      vals[i] = min;\n    }\n    return result;\n  }\n\n  minimum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'minimum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.min(aVal, bVal));\n  }\n\n  mod(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'mod');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const rem = aVal % bVal;\n      if ((aVal < 0 && bVal < 0) || (aVal >= 0 && bVal >= 0)) {\n        return rem;\n      } else {\n        return (rem + bVal) % bVal;\n      }\n    });\n  }\n\n  maximum(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'maximum');\n\n    return this.broadcastedBinaryOp(\n        a, b, a.dtype, (aVal, bVal) => Math.max(aVal, bVal));\n  }\n\n  all(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'all');\n\n    backend_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let all = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        all = all && value;\n      }\n      vals[i] = all;\n    }\n    return result;\n  }\n\n  any(x: Tensor, axes: number[]): Tensor {\n    assertNotComplex(x, 'any');\n\n    backend_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n    const [outShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(x.shape, axes);\n    const result = tf.zeros(outShape, x.dtype);\n    const reduceSize = util.sizeFromShape(reduceShape);\n    const vals = this.readSync(result.dataId) as TypedArray;\n\n    const aVals = this.readSync(x.dataId) as TypedArray;\n    for (let i = 0; i < vals.length; ++i) {\n      const offset = i * reduceSize;\n      let anyVal = aVals[offset];\n      for (let j = 0; j < reduceSize; ++j) {\n        const value = aVals[offset + j];\n        anyVal = anyVal || value;\n      }\n      vals[i] = anyVal;\n    }\n    return result;\n  }\n\n  squaredDifference(a: Tensor, b: Tensor): Tensor {\n    assertNotComplex([a, b], 'squaredDifference');\n\n    return this.broadcastedBinaryOp(a, b, a.dtype, (aVal, bVal) => {\n      const diff = aVal - bVal;\n      return diff * diff;\n    });\n  }\n\n  eluDer<T extends Tensor>(dy: T, y: T): T {\n    assertNotComplex([dy, y], 'eluDer');\n\n    const resultValues = new Float32Array(y.size);\n    const values = this.readSync(y.dataId) as TypedArray;\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    for (let i = 0; i < values.length; ++i) {\n      const v = values[i];\n      if (v >= 1) {\n        resultValues[i] = dyValues[i];\n      } else {\n        resultValues[i] = dyValues[i] * (v + 1);\n      }\n    }\n    return this.makeOutput(resultValues, y.shape, 'float32');\n  }\n\n  atan2<T extends Tensor>(a: T, b: T): T {\n    assertNotComplex([a, b], 'atan2');\n\n    return this.broadcastedBinaryOp(\n               a, b, a.dtype, (aValue, bValue) => Math.atan2(aValue, bValue)) as\n        T;\n  }\n\n  tile<T extends Tensor>(x: T, reps: number[]): T {\n    assertNotComplex(x, 'tile');\n    return tile(this.bufferSync(x), reps) as T;\n  }\n\n  gather<T extends Tensor>(x: T, indices: Tensor1D, axis: number): T {\n    assertNotComplex([x, indices], 'gather');\n\n    const newShape: number[] = x.shape.slice();\n    const indicesValues = this.readSync(indices.dataId) as TypedArray;\n    newShape[axis] = indicesValues.length;\n    const result = tf.buffer(newShape, x.dtype);\n    const xBuf = this.bufferSync(x);\n\n    for (let i = 0; i < result.size; ++i) {\n      const newLoc = result.indexToLoc(i);\n\n      const originalLoc: number[] = newLoc.slice();\n      originalLoc[axis] = indicesValues[newLoc[axis]];\n\n      const originalIndex = xBuf.locToIndex(originalLoc);\n      result.values[i] = xBuf.values[originalIndex];\n    }\n    return result.toTensor() as T;\n  }\n\n  batchToSpaceND<T extends Tensor>(\n      x: T, blockShape: number[], crops: number[][]): T {\n    assertNotComplex([x], 'batchToSpaceND');\n\n    const prod = blockShape.reduce((a, b) => a * b);\n\n    const reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n    const permuted =\n        backend_util.getPermuted(reshaped.length, blockShape.length);\n    const reshapedPermuted =\n        backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n    const sliceBeginCoords =\n        backend_util.getSliceBeginCoords(crops, blockShape.length);\n    const sliceSize =\n        backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n\n    return tf.transpose(x.reshape(reshaped), permuted)\n               .reshape(reshapedPermuted)\n               .slice(sliceBeginCoords, sliceSize) as T;\n  }\n\n  private pool3d(\n      x: Tensor5D, convInfo: backend_util.Conv3DInfo,\n      poolType: 'max'|'avg'): Tensor5D {\n    assertNotComplex(x, 'pool3d');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const initialValue =\n        (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                              Number.POSITIVE_INFINITY);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = tf.buffer(convInfo.outShape, x.dtype);\n    const outputVals = output.values;\n\n    const outputBatchStrides = convInfo.outShape[1] * convInfo.outShape[2] *\n        convInfo.outShape[3] * convInfo.outShape[4];\n    const outputDepthStrides =\n        convInfo.outShape[2] * convInfo.outShape[3] * convInfo.outShape[4];\n    const outputRowStrides = convInfo.outShape[3] * convInfo.outShape[4];\n    const outputColStrides = convInfo.outShape[4];\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      const outputBatchOffset = batch * outputBatchStrides;\n      const inputBatchOffset = batch * x.strides[0];\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          const outputDepthOffset =\n              outputBatchOffset + yDepth * outputDepthStrides;\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            const outputRowOffset = outputDepthOffset + yRow * outputRowStrides;\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n              // Shader code begins\n              const outputColOffset = outputRowOffset + yCol * outputColStrides;\n              let minMaxValue = initialValue;\n              let avgValue = 0;\n              let count = 0;\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const xDepthOffset = inputBatchOffset + xDepth * x.strides[1];\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const xRowOffset = xDepthOffset + xRow * x.strides[2];\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const xColOffset = xRowOffset + xCol * x.strides[3];\n                    const pixel = xValues[xColOffset + channel];\n                    if ((poolType === 'max' && pixel > minMaxValue)) {\n                      minMaxValue = pixel;\n                    } else if (poolType === 'avg') {\n                      avgValue += pixel;\n                      count++;\n                    }\n                    if (isNaN(minMaxValue)) {\n                      break;\n                    }\n                  }\n                  if (isNaN(minMaxValue)) {\n                    break;\n                  }\n                }\n                if (isNaN(minMaxValue)) {\n                  break;\n                }\n              }\n              const outputOffset = outputColOffset + channel;\n              outputVals[outputOffset] =\n                  poolType === 'avg' ? avgValue / count : minMaxValue;\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor5D;\n  }\n\n  avgPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'avgPool3d');\n\n    return this.pool3d(x, convInfo, 'avg').toFloat();\n  }\n\n  avgPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([dy, x], 'avgPool3dBackprop');\n\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const filterDepth = convInfo.filterDepth;\n    const filterHeight = convInfo.filterHeight;\n    const filterWidth = convInfo.filterWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const avgMultiplier = 1 / (filterDepth * filterHeight * filterWidth);\n\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins.\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel;\n                  }\n                }\n              }\n              dx.set(\n                  dotProd * avgMultiplier, batch, dxDepth, dxRow, dxCol,\n                  channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  maxPool3d(x: Tensor5D, convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex(x, 'maxPool3d');\n\n    return this.pool3d(x, convInfo, 'max').toFloat();\n  }\n\n  private maxPool3dPositions(x: Tensor5D, convInfo: backend_util.Conv3DInfo):\n      Tensor5D {\n    const maxPositions = tf.buffer(convInfo.outShape, 'int32');\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = convInfo.padInfo.front;\n    const padTop = convInfo.padInfo.top;\n    const padLeft = convInfo.padInfo.left;\n\n    const xBuf = this.bufferSync(x);\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let yDepth = 0; yDepth < convInfo.outDepth; ++yDepth) {\n          const xDepthCorner = yDepth * strideDepth - padFront;\n          let xDepthMin = xDepthCorner;\n          while (xDepthMin < 0) {\n            xDepthMin += dilationDepth;\n          }\n          const xDepthMax =\n              Math.min(convInfo.inDepth, effectiveFilterDepth + xDepthCorner);\n          for (let yRow = 0; yRow < convInfo.outHeight; ++yRow) {\n            const xRowCorner = yRow * strideHeight - padTop;\n            let xRowMin = xRowCorner;\n            while (xRowMin < 0) {\n              xRowMin += dilationHeight;\n            }\n            const xRowMax =\n                Math.min(convInfo.inHeight, effectiveFilterHeight + xRowCorner);\n            for (let yCol = 0; yCol < convInfo.outWidth; ++yCol) {\n              const xColCorner = yCol * strideWidth - padLeft;\n              let xColMin = xColCorner;\n              while (xColMin < 0) {\n                xColMin += dilationWidth;\n              }\n              const xColMax =\n                  Math.min(convInfo.inWidth, effectiveFilterWidth + xColCorner);\n\n              // Shader code begins\n              let maxValue = Number.NEGATIVE_INFINITY;\n              let maxPosition = -1;\n\n              for (let xDepth = xDepthMin; xDepth < xDepthMax;\n                   xDepth += dilationDepth) {\n                const wDepth = xDepth - xDepthCorner;\n                for (let xRow = xRowMin; xRow < xRowMax;\n                     xRow += dilationHeight) {\n                  const wRow = xRow - xRowCorner;\n                  for (let xCol = xColMin; xCol < xColMax;\n                       xCol += dilationWidth) {\n                    const wCol = xCol - xColCorner;\n                    const pixel = xBuf.get(batch, xDepth, xRow, xCol, channel);\n                    if (pixel >= maxValue) {\n                      maxValue = pixel;\n                      maxPosition = wDepth * effectiveFilterHeight *\n                              effectiveFilterWidth +\n                          wRow * effectiveFilterHeight + wCol;\n                    }\n                  }\n                }\n              }\n\n              maxPositions.set(maxPosition, batch, yDepth, yRow, yCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return maxPositions.toTensor() as Tensor5D;\n  }\n\n  maxPool3dBackprop(\n      dy: Tensor5D, x: Tensor5D, y: Tensor5D,\n      convInfo: backend_util.Conv3DInfo): Tensor5D {\n    assertNotComplex([x, y], 'maxPool3dBackprop');\n\n    const maxPositions = this.maxPool3dPositions(x, convInfo);\n    const strideDepth = convInfo.strideDepth;\n    const strideHeight = convInfo.strideHeight;\n    const strideWidth = convInfo.strideWidth;\n    const dilationDepth = convInfo.dilationDepth;\n    const dilationHeight = convInfo.dilationHeight;\n    const dilationWidth = convInfo.dilationWidth;\n    const effectiveFilterDepth = convInfo.effectiveFilterDepth;\n    const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n    const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n    const padFront = effectiveFilterDepth - 1 - convInfo.padInfo.front;\n    const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n    const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n    const dx = tf.buffer<Rank.R5>(x.shape, 'float32');\n\n    const maxPosBuf = this.bufferSync(maxPositions);\n    const dyBuf = this.bufferSync(dy);\n\n    for (let batch = 0; batch < convInfo.batchSize; ++batch) {\n      for (let channel = 0; channel < convInfo.inChannels; ++channel) {\n        for (let dxDepth = 0; dxDepth < convInfo.inDepth; ++dxDepth) {\n          for (let dxRow = 0; dxRow < convInfo.inHeight; ++dxRow) {\n            for (let dxCol = 0; dxCol < convInfo.inWidth; ++dxCol) {\n              // Shader code begins\n              const dyDepthCorner = dxDepth - padFront;\n              const dyRowCorner = dxRow - padTop;\n              const dyColCorner = dxCol - padLeft;\n              let dotProd = 0;\n              for (let wDepth = 0; wDepth < effectiveFilterDepth;\n                   wDepth += dilationDepth) {\n                const dyDepth = (dyDepthCorner + wDepth) / strideDepth;\n                if (dyDepth < 0 || dyDepth >= convInfo.outDepth ||\n                    Math.floor(dyDepth) !== dyDepth) {\n                  continue;\n                }\n                for (let wRow = 0; wRow < effectiveFilterHeight;\n                     wRow += dilationHeight) {\n                  const dyRow = (dyRowCorner + wRow) / strideHeight;\n                  if (dyRow < 0 || dyRow >= convInfo.outHeight ||\n                      Math.floor(dyRow) !== dyRow) {\n                    continue;\n                  }\n                  for (let wCol = 0; wCol < effectiveFilterWidth;\n                       wCol += dilationWidth) {\n                    const dyCol = (dyColCorner + wCol) / strideWidth;\n                    if (dyCol < 0 || dyCol >= convInfo.outWidth ||\n                        Math.floor(dyCol) !== dyCol) {\n                      continue;\n                    }\n\n                    const maxPos = effectiveFilterDepth *\n                            effectiveFilterHeight * effectiveFilterWidth -\n                        1 -\n                        maxPosBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    const curPos =\n                        wDepth * effectiveFilterHeight * effectiveFilterWidth +\n                        wRow * effectiveFilterWidth + wCol;\n\n                    const mask = maxPos === curPos ? 1 : 0;\n                    if (mask === 0) {\n                      continue;\n                    }\n\n                    const pixel =\n                        dyBuf.get(batch, dyDepth, dyRow, dyCol, channel);\n                    dotProd += pixel * mask;\n                  }\n                }\n              }\n              dx.set(dotProd, batch, dxDepth, dxRow, dxCol, channel);\n            }\n          }\n        }\n      }\n    }\n    return dx.toTensor();\n  }\n\n  resizeBilinear(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeBilinear');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result = new Float32Array(\n        util.sizeFromShape([batch, newHeight, newWidth, numChannels]));\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n    let outputIdx = 0;\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n    for (let b = 0; b < batch; b++) {\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceRowFloor = Math.floor(sourceFracRow);\n        const rowFrac = sourceFracRow - sourceRowFloor;\n        const sourceRowCeil = Math.min(oldHeight - 1, Math.ceil(sourceFracRow));\n        const topRowOffset = b * x.strides[0] + sourceRowFloor * x.strides[1];\n        const botRowOffset = b * x.strides[0] + sourceRowCeil * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceColFloor = Math.floor(sourceFracCol);\n          const colFrac = sourceFracCol - sourceColFloor;\n          const sourceColCeil =\n              Math.min(oldWidth - 1, Math.ceil(sourceFracCol));\n          const topLeftOffest = topRowOffset + sourceColFloor * x.strides[2];\n          const botLeftOffset = botRowOffset + sourceColFloor * x.strides[2];\n          const topRightOffset = topRowOffset + sourceColCeil * x.strides[2];\n          const botRightOffest = botRowOffset + sourceColCeil * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n\n            // Compute the fractional index of the source.\n            const topLeft = xValues[topLeftOffest + d];\n            const bottomLeft = xValues[botLeftOffset + d];\n            const topRight = xValues[topRightOffset + d];\n            const bottomRight = xValues[botRightOffest + d];\n\n            const top = topLeft + (topRight - topLeft) * colFrac;\n            const bottom = bottomLeft + (bottomRight - bottomLeft) * colFrac;\n            const newValue = top + (bottom - top) * rowFrac;\n\n            result[outputIdx++] = newValue;\n          }\n        }\n      }\n    }\n    return tf.tensor(result, [batch, newHeight, newWidth, numChannels]);\n  }\n\n  resizeBilinearBackprop(dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeBilinearBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass and add the\n    // corresponding coefficient from dy to the gradient (with some\n    // interpolation).\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/3039375c86a5bbc9610c7725dcaa95d635f87ba2/tensorflow/core/kernels/resize_bilinear_op.cc#L275\n\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    let offset = 0;\n    for (let b = 0; b < batch; b++) {\n      const bOffset = b * x.strides[0];\n      for (let r = 0; r < yHeight; r++) {\n        const dxR = r * heightScale;\n        const topDxRIndex = Math.floor(dxR);\n        const bottomDxRIndex = Math.min(Math.ceil(dxR), xHeight - 1);\n\n        const topDxROffset = bOffset + topDxRIndex * x.strides[1];\n        const bottomDxROffset = bOffset + bottomDxRIndex * x.strides[1];\n\n        const dxRLerp = dxR - topDxRIndex;\n        const inverseDxRLerp = 1.0 - dxRLerp;\n        for (let c = 0; c < yWidth; c++) {\n          const dxC = c * widthScale;\n          const leftDxCIndex = Math.floor(dxC);\n          const rightDxCIndex = Math.min(Math.ceil(dxC), xWidth - 1);\n          const dxCLerp = dxC - leftDxCIndex;\n          const inverseDxCLerp = 1.0 - dxCLerp;\n\n          const topLeftRCOffset = topDxROffset + leftDxCIndex * x.strides[2];\n          const topRightRCOffset = topDxROffset + rightDxCIndex * x.strides[2];\n          const bottomLeftRCOffset =\n              bottomDxROffset + leftDxCIndex * x.strides[2];\n          const bottomRightRCOffset =\n              bottomDxROffset + rightDxCIndex * x.strides[2];\n\n          const inverseDxRLerpTimesInverseDxCLerp =\n              inverseDxRLerp * inverseDxCLerp;\n          const inverseDxRLerpTimesDxCLerp = inverseDxRLerp * dxCLerp;\n          const dxRLerpTimesInverseDxCLerp = dxRLerp * inverseDxCLerp;\n          const dxRLerpTimesDxCLerp = dxRLerp * dxCLerp;\n          for (let d = 0; d < depth; d++) {\n            const dyVal = dyValues[offset++];\n            output[topLeftRCOffset + d] +=\n                dyVal * inverseDxRLerpTimesInverseDxCLerp;\n            output[topRightRCOffset + d] += dyVal * inverseDxRLerpTimesDxCLerp;\n            output[bottomLeftRCOffset + d] +=\n                dyVal * dxRLerpTimesInverseDxCLerp;\n            output[bottomRightRCOffset + d] += dyVal * dxRLerpTimesDxCLerp;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, [batch, xWidth, xHeight, depth], x.dtype);\n  }\n\n  resizeNearestNeighbor(\n      x: Tensor4D, newHeight: number, newWidth: number,\n      alignCorners: boolean): Tensor4D {\n    assertNotComplex(x, 'resizeNearestNeighbor');\n\n    const [batch, oldHeight, oldWidth, numChannels] = x.shape;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const output = new Float32Array(batch * newHeight * newWidth * numChannels);\n\n    const effectiveInputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? oldHeight - 1 : oldHeight,\n      (alignCorners && newWidth > 1) ? oldWidth - 1 : oldWidth\n    ];\n\n    const effectiveOutputSize: [number, number] = [\n      (alignCorners && newHeight > 1) ? newHeight - 1 : newHeight,\n      (alignCorners && newWidth > 1) ? newWidth - 1 : newWidth\n    ];\n\n    const effectiveRowSizeRatio =\n        effectiveInputSize[0] / effectiveOutputSize[0];\n    const effectiveColSizeRatio =\n        effectiveInputSize[1] / effectiveOutputSize[1];\n\n    let outputOffset = 0;\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < newHeight; r++) {\n        const sourceFracRow = effectiveRowSizeRatio * r;\n        const sourceNearestRow = Math.min(\n            oldHeight - 1,\n            alignCorners ? Math.round(sourceFracRow) :\n                           Math.floor(sourceFracRow));\n        const rowOffset = batchOffset + sourceNearestRow * x.strides[1];\n        for (let c = 0; c < newWidth; c++) {\n          const sourceFracCol = effectiveColSizeRatio * c;\n          const sourceNearestCol = Math.min(\n              oldWidth - 1,\n              alignCorners ? Math.round(sourceFracCol) :\n                             Math.floor(sourceFracCol));\n          const colOffset = rowOffset + sourceNearestCol * x.strides[2];\n          for (let d = 0; d < numChannels; d++) {\n            // Begin shader.\n            // Compute the fractional index of the source.\n            const newVal = xValues[colOffset + d];\n            output[outputOffset++] = newVal;\n          }\n        }\n      }\n    }\n    return tf.tensor(\n        output, [batch, newHeight, newWidth, numChannels], x.dtype);\n  }\n\n  resizeNearestNeighborBackprop(\n      dy: Tensor4D, x: Tensor4D, alignCorners: boolean) {\n    assertNotComplex([dy, x], 'resizeNearestNeighborBackprop');\n\n    const [batch, xHeight, xWidth, depth] = x.shape;\n    const [, yHeight, yWidth] = dy.shape;\n\n    const output = new Float32Array(batch * xHeight * xWidth * depth);\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n\n    // In the backwards pass, we want to find the pixels that were generated\n    // for each pixel in the input image the forward pass\n\n    const effectiveXSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? xHeight - 1 : xHeight,\n      (alignCorners && yWidth > 1) ? xWidth - 1 : xWidth\n    ];\n\n    const effectiveYSize: [number, number] = [\n      (alignCorners && yHeight > 1) ? yHeight - 1 : yHeight,\n      (alignCorners && yWidth > 1) ? yWidth - 1 : yWidth\n    ];\n\n    const heightScale = effectiveXSize[0] / effectiveYSize[0];\n    const widthScale = effectiveXSize[1] / effectiveYSize[1];\n\n    const invHeightScale = 1 / heightScale;\n    const invWidthScale = 1 / widthScale;\n\n    // This defines the size of the window of values around a particular\n    // index in dy that we want to search for contributions to dx.\n    const winHeight = (Math.ceil(invHeightScale) * 2) + 2;\n    const winWidth = (Math.ceil(invWidthScale) * 2) + 2;\n\n    // Loop over the output space.\n    for (let b = 0; b < batch; b++) {\n      const batchOffset = b * x.strides[0];\n      for (let r = 0; r < xHeight; r++) {\n        const rowOffset = batchOffset + r * x.strides[1];\n\n        // Compute bounds for where in dy we will look\n        const startRLerp = Math.floor(r * invHeightScale);\n        const startDyR = Math.floor(startRLerp - (winHeight / 2));\n        for (let c = 0; c < xWidth; c++) {\n          const colOffset = rowOffset + c * x.strides[2];\n\n          // Compute bounds for where in dy we will look\n          const startCLerp = Math.floor(c * invWidthScale);\n          const startDyC = Math.floor(startCLerp - (winWidth / 2));\n\n          for (let d = 0; d < depth; d++) {\n            let accum = 0;\n            // loop over dy\n\n            for (let dyRIndex = 0; dyRIndex < winHeight; dyRIndex++) {\n              const dyR = dyRIndex + startDyR;\n              // Guard against the window exceeding the bounds of dy\n              if (dyR < 0 || dyR >= yHeight) {\n                continue;\n              }\n\n              const dyROffset = batchOffset + dyR * dy.strides[1];\n              const sourceFracRow = dyR * heightScale;\n              const sourceNearestRow = Math.min(\n                  xHeight - 1,\n                  alignCorners ? Math.round(sourceFracRow) :\n                                 Math.floor(sourceFracRow));\n              if (r !== sourceNearestRow) {\n                continue;\n              }\n              for (let dyCIndex = 0; dyCIndex < winWidth; dyCIndex++) {\n                const dyC = dyCIndex + startDyC;\n                // Guard against the window exceeding the bounds of dy\n                if (dyC < 0 || dyC >= yWidth) {\n                  continue;\n                }\n\n                const dyCOffset = dyROffset + dyC * dy.strides[2];\n                const sourceFracCol = dyC * widthScale;\n                const sourceNearestCol = Math.min(\n                    xWidth - 1,\n                    alignCorners ? Math.round(sourceFracCol) :\n                                   Math.floor(sourceFracCol));\n\n                if (c === sourceNearestCol) {\n                  accum += dyValues[dyCOffset + d];\n                }\n              }\n            }\n            output[colOffset + d] = accum;\n          }\n        }\n      }\n    }\n    return tf.tensor4d(output, x.shape, x.dtype);\n  }\n\n  localResponseNormalization4D(\n      x: Tensor4D, depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(x, 'localResponseNormalization4D');\n\n    const channels = x.shape[3];\n    const maxD = channels - 1;\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const size = x.size;\n    const result = new Float32Array(size);\n\n    function sumAcrossChannels(offset: number) {\n      const currentChannel = offset % channels;\n      let beginSumOffset =\n          offset - currentChannel + Math.max(0, currentChannel - depthRadius);\n      const endSumOffset = offset - currentChannel +\n          Math.min(currentChannel + depthRadius, maxD);\n\n      let sum = 0.0;\n      for (; beginSumOffset <= endSumOffset; beginSumOffset++) {\n        const z = xValues[beginSumOffset];\n        sum += z * z;\n      }\n      return sum;\n    }\n\n    for (let offset = 0; offset < size; offset++) {\n      const sum = sumAcrossChannels(offset);\n      const val = xValues[offset] * Math.pow(bias + alpha * sum, -beta);\n      result[offset] = val;\n    }\n\n    return tf.tensor4d(result, x.shape);\n  }\n\n  LRNGrad(\n      dy: Tensor4D, inputImage: Tensor4D, outputImage: Tensor4D,\n      depthRadius: number, bias: number, alpha: number,\n      beta: number): Tensor4D {\n    assertNotComplex(dy, 'LRNGrad');\n    const channels = dy.shape[3];\n    const dyValues = this.readSync(dy.dataId) as TypedArray;\n    const inputImageValues = this.readSync(inputImage.dataId) as TypedArray;\n    const outputImageValues = this.readSync(outputImage.dataId) as TypedArray;\n    const result = new Float32Array(dy.size);\n    const size = dy.size;\n\n    for (let offset = 0; offset < size; offset++) {\n      const currentChannel = offset % channels;\n      const depthBegin =\n          (offset - currentChannel) + Math.max(0, currentChannel - depthRadius);\n      const depthEnd = (offset - currentChannel) +\n          Math.min(channels, currentChannel + depthRadius + 1);\n\n      let norm = 0;\n      for (let k = depthBegin; k < depthEnd; k++) {\n        norm += Math.pow(inputImageValues[k], 2);\n      }\n      norm = alpha * norm + bias;\n\n      for (let k = depthBegin; k < depthEnd; k++) {\n        let dyi = -2 * alpha * beta * inputImageValues[k] *\n            outputImageValues[offset] / norm;\n        if (offset === k) {\n          dyi += Math.pow(norm, -beta);\n        }\n        dyi *= dyValues[offset];\n        result[k] += dyi;\n      }\n    }\n    return tf.tensor4d(result, dy.shape);\n  }\n\n  multinomial(\n      logits: Tensor2D, normalized: boolean, numSamples: number,\n      seed: number): Tensor2D {\n    assertNotComplex(logits, 'multinomial');\n\n    const probabilities = normalized ? logits : tf.softmax(logits);\n    const batchSize = probabilities.shape[0];\n    const numEvents = probabilities.shape[1];\n    const res = tf.zeros<Rank.R2>([batchSize, numSamples], 'int32');\n    const resVals = this.readSync(res.dataId) as TypedArray;\n    const probVals = this.readSync(probabilities.dataId) as TypedArray;\n\n    for (let b = 0; b < batchSize; ++b) {\n      const offset = b * numEvents;\n      // The cdf won't include the last event. It will be implicit if no other\n      // event happened.\n      const cdf = new Float32Array(numEvents - 1);\n      cdf[0] = probVals[offset];\n      for (let event = 1; event < cdf.length; ++event) {\n        cdf[event] = cdf[event - 1] + probVals[offset + event];\n      }\n\n      const random = seedrandom.alea(seed.toString());\n      const outOffset = b * numSamples;\n      for (let sampleId = 0; sampleId < numSamples; ++sampleId) {\n        const r = random();\n\n        // Assume last event happened by default.\n        resVals[outOffset + sampleId] = cdf.length;\n\n        for (let event = 0; event < cdf.length; event++) {\n          if (r < cdf[event]) {\n            resVals[outOffset + sampleId] = event;\n            break;\n          }\n        }\n      }\n    }\n    return res;\n  }\n\n  oneHot(indices: Tensor1D, depth: number, onValue: number, offValue: number):\n      Tensor2D {\n    assertNotComplex(indices, 'oneHot');\n\n    const res = new Float32Array(indices.size * depth);\n    res.fill(offValue);\n    const indicesVal = this.readSync(indices.dataId) as TypedArray;\n\n    for (let event = 0; event < indices.size; ++event) {\n      if (indicesVal[event] >= 0 && indicesVal[event] < depth) {\n        res[event * depth + indicesVal[event]] = onValue;\n      }\n    }\n    return tf.tensor2d(res, [indices.size, depth], 'int32');\n  }\n\n  nonMaxSuppression(\n      boxes: Tensor2D, scores: Tensor1D, maxOutputSize: number,\n      iouThreshold: number, scoreThreshold: number): Tensor1D {\n    assertNotComplex(boxes, 'nonMaxSuppression');\n\n    const boxesVals = this.readSync(boxes.dataId) as TypedArray;\n    const scoresVals = this.readSync(scores.dataId) as TypedArray;\n    return nonMaxSuppressionV3Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold);\n  }\n\n  depthToSpace(x: Tensor4D, blockSize: number, dataFormat: 'NHWC'|'NCHW'):\n      Tensor4D {\n    util.assert(\n        dataFormat === 'NHWC',\n        () => `Only NHWC dataFormat supported on CPU for depthToSpace. Got ${\n            dataFormat}`);\n    util.assert(\n        blockSize > 1,\n        () =>\n            `blockSize should be > 1 for depthToSpace, but was: ${blockSize}`);\n\n    const batchSize = x.shape[0];\n    const inputHeight = x.shape[1];\n    const inputWidth = x.shape[2];\n    const inputDepth = x.shape[3];\n\n    const outputHeight = inputHeight * blockSize;\n    const outputWidth = inputWidth * blockSize;\n    const outputDepth = inputDepth / (blockSize * blockSize);\n\n    const xValues = this.readSync(x.dataId) as TypedArray;\n    const result =\n        new Float32Array(batchSize * outputHeight * outputWidth * outputDepth);\n\n    let outputIdx = 0;\n    for (let b = 0; b < batchSize; ++b) {\n      for (let h = 0; h < outputHeight; ++h) {\n        const inH = Math.floor(h / blockSize);\n        const offsetH = (h % blockSize);\n        for (let w = 0; w < outputWidth; ++w) {\n          const inW = Math.floor(w / blockSize);\n          const offsetW = (w % blockSize);\n          const offsetD = (offsetH * blockSize + offsetW) * outputDepth;\n          for (let d = 0; d < outputDepth; ++d) {\n            const inD = d + offsetD;\n            const inputIdx =\n                inD + inputDepth * (inW + inputWidth * (inH + inputHeight * b));\n            result[outputIdx++] = xValues[inputIdx];\n          }\n        }\n      }\n    }\n    return tf.tensor4d(\n        result, [batchSize, outputHeight, outputWidth, outputDepth]);\n  }\n\n  private broadcastedBinaryOp(\n      a: Tensor, b: Tensor, dtype: DataType,\n      op: (a: number, b: number) => number): Tensor {\n    const newShape = backend_util.assertAndGetBroadcastShape(a.shape, b.shape);\n    const result = tf.buffer(newShape, dtype);\n    const aVals = this.readSync(a.dataId) as TypedArray;\n    const bVals = this.readSync(b.dataId) as TypedArray;\n    const aBroadcastDims = backend_util.getBroadcastDims(a.shape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(b.shape, newShape);\n\n    const resVals = result.values;\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resVals.length; ++i) {\n        resVals[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      const aBuf = this.bufferSync(a);\n      const bBuf = this.bufferSync(b);\n      for (let i = 0; i < resVals.length; ++i) {\n        const loc = result.indexToLoc(i);\n\n        const aLoc = loc.slice(-a.rank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = aBuf.locToIndex(aLoc);\n\n        const bLoc = loc.slice(-b.rank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = bBuf.locToIndex(bLoc);\n\n        resVals[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n    return result.toTensor();\n  }\n\n  split<T extends Tensor>(x: T, sizeSplits: number[], axis: number): T[] {\n    return split(x, sizeSplits, axis);\n  }\n\n  dispose() {}\n\n  floatPrecision(): 16|32 {\n    return 32;\n  }\n\n  /** Returns the smallest representable number.  */\n  epsilon(): number {\n    return super.epsilon();\n  }\n\n  cropAndResize(\n      images: Tensor4D,\n      boxes: Tensor2D,\n      boxIndex: Tensor1D,\n      cropSize: [number, number],\n      method: string,\n      extrapolationValue: number,\n  ) {\n    const [batch, imageHeight, imageWidth, numChannels] = images.shape;\n    const numBoxes = boxes.shape[0];\n\n    const [cropHeight, cropWidth] = cropSize;\n    const output =\n        tf.buffer([numBoxes, cropHeight, cropWidth, numChannels], 'float32');\n\n    const boxVals = this.readSync(boxes.dataId) as TypedArray;\n    const boxIndVals = this.readSync(boxIndex.dataId) as TypedArray;\n    const imageVals = this.readSync(images.dataId) as TypedArray;\n\n    const inStride = images.strides;   // to calculate flat indexes into image\n    const outStride = output.strides;  // to calculate flat indexes into output\n\n    // Reference implementation\n    // tslint:disable-next-line:max-line-length\n    // https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/kernels/crop_and_resize_op.cc\n    for (let b = 0; b < numBoxes; b++) {\n      const startInd = b * 4;\n      const y1 = boxVals[startInd];\n      const x1 = boxVals[startInd + 1];\n      const y2 = boxVals[startInd + 2];\n      const x2 = boxVals[startInd + 3];\n\n      const bInd: number = boxIndVals[b];\n      if (bInd >= batch) {\n        continue;\n      }\n\n      const heightScale = (cropHeight > 1) ?\n          (y2 - y1) * (imageHeight - 1) / (cropHeight - 1) :\n          0;\n      const widthScale =\n          (cropWidth > 1) ? (x2 - x1) * (imageWidth - 1) / (cropWidth - 1) : 0;\n\n      for (let y = 0; y < cropHeight; y++) {\n        const yInd: number = (cropHeight > 1) ?\n            y1 * (imageHeight - 1) + y * (heightScale) :\n            0.5 * (y1 + y2) * (imageHeight - 1);\n\n        if (yInd < 0 || yInd > imageHeight - 1) {\n          for (let x = 0; x < cropWidth; x++) {\n            for (let c = 0; c < numChannels; c++) {\n              const ind =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = extrapolationValue;\n            }\n          }\n          continue;\n        }\n\n        if (method === 'bilinear') {\n          const topInd = Math.floor(yInd);\n          const bottomInd = Math.ceil(yInd);\n          const yLerp = yInd - topInd;\n\n          for (let x = 0; x < cropWidth; x++) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const leftInd = Math.floor(xInd);\n            const rightInd = Math.ceil(xInd);\n            const xLerp = xInd - leftInd;\n\n            for (let c = 0; c < numChannels; c++) {\n              let ind = c + leftInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + topInd * inStride[1] +\n                  bInd * inStride[0];\n              const topRight = imageVals[ind];\n\n              ind = c + leftInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomLeft = imageVals[ind];\n\n              ind = c + rightInd * inStride[2] + bottomInd * inStride[1] +\n                  bInd * inStride[0];\n              const bottomRight = imageVals[ind];\n\n              const top = topLeft + (topRight - topLeft) * xLerp;\n              const bottom = bottomLeft + (bottomRight - bottomLeft) * xLerp;\n\n              ind = c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[ind] = top + ((bottom - top) * yLerp);\n            }\n          }\n        } else {  // method == \"nearest\"\n          for (let x = 0; x < cropWidth; ++x) {\n            const xInd = (cropWidth > 1) ?\n                x1 * (imageWidth - 1) + x * widthScale :\n                0.5 * (x1 + x2) * (imageWidth - 1);\n\n            if (xInd < 0 || xInd > imageWidth - 1) {\n              for (let c = 0; c < numChannels; c++) {\n                const ind =\n                    c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n                output.values[ind] = extrapolationValue;\n              }\n              continue;\n            }\n\n            const closestX = Math.round(xInd);\n            const closestY = Math.round(yInd);\n            for (let c = 0; c < numChannels; c++) {\n              const inInd = c + closestX * inStride[2] +\n                  closestY * inStride[1] + bInd * inStride[0];\n              const outInd =\n                  c + x * outStride[2] + y * outStride[1] + b * outStride[0];\n              output.values[outInd] = imageVals[inInd];\n            }\n          }\n        }\n      }\n    }\n    return output.toTensor() as Tensor4D;\n  }\n\n  sparseToDense<R extends Rank>(\n      sparseIndices: Tensor, sparseValues: Tensor, outputShape: ShapeMap[R],\n      defaultValue: Scalar): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(sparseValues, sparseIndices, outputShape);\n    const sumDupeIndices = false;\n    return this.scatter(\n        sparseIndices, sparseValues, outputShape, outputSize, sliceSize,\n        numUpdates, sliceRank, strides, defaultValue, sumDupeIndices);\n  }\n\n  gatherND(x: Tensor, indices: Tensor): Tensor {\n    const indicesShape = indices.shape;\n    const sliceRank = indicesShape[indicesShape.length - 1];\n\n    const [resultShape, numSlices, sliceSize, strides] =\n        backend_util.prepareAndValidate(x, indices);\n    if (numSlices === 0) {\n      return tf.tensor([], resultShape, x.dtype);\n    }\n\n    const buffer = new TensorBuffer([numSlices, sliceSize], x.dtype);\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const xData = this.readSync(x.dataId) as TypedArray;\n\n    for (let i = 0; i < numSlices; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        flattenIndex += dim * strides[j];\n        index.push(dim);\n      }\n      if (flattenIndex < 0 || flattenIndex >= x.size / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${x.shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        buffer.values[i * sliceSize + k] = xData[flattenIndex * sliceSize + k];\n      }\n    }\n    return buffer.toTensor().reshape(resultShape);\n  }\n\n  scatterND<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R]): Tensor<R> {\n    const {sliceRank, numUpdates, sliceSize, strides, outputSize} =\n        backend_util.calculateShapes(updates, indices, shape);\n    const defaultValue = tf.scalar(0);\n    const sumDupeIndices = true;\n    return this.scatter(\n        indices, updates, shape, outputSize, sliceSize, numUpdates, sliceRank,\n        strides, defaultValue, sumDupeIndices);\n  }\n\n  onesLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    if (x.dtype === 'string') {\n      throw new Error('onesLike is not supported for string tensors');\n    } else {\n      // TODO(lina128): Use fill kernel directly once this kernel is\n      // modularized.\n      return tf.fill(x.shape, 1, x.dtype);\n    }\n  }\n\n  zerosLike<R extends Rank>(x: Tensor<R>): Tensor<R> {\n    const values = util.getArrayFromDType(\n                       x.dtype, util.sizeFromShape(x.shape)) as TypedArray;\n    return this.makeOutput(values, x.shape, x.dtype);\n  }\n\n  linspace(start: number, stop: number, num: number): Tensor1D {\n    return backend_util.linspaceImpl(start, stop, num);\n  }\n\n  private scatter<R extends Rank>(\n      indices: Tensor, updates: Tensor, shape: ShapeMap[R], outputSize: number,\n      sliceSize: number, numUpdates: number, sliceRank: number,\n      strides: number[], defaultValue: Scalar,\n      sumDupeIndices: boolean): Tensor<R> {\n    const flattenShape = [outputSize / sliceSize, sliceSize];\n\n    const indicesData = this.readSync(indices.dataId) as TypedArray;\n    const updatesData = this.readSync(updates.dataId) as TypedArray;\n\n    if (outputSize === 0) {\n      return tf.tensor([], shape, updates.dtype);\n    }\n\n    const buffer = new TensorBuffer(flattenShape, updates.dtype as 'float32');\n    buffer.values.fill((this.readSync(defaultValue.dataId) as TypedArray)[0]);\n\n    for (let i = 0; i < numUpdates; i++) {\n      const index = [];\n      let flattenIndex = 0;\n      for (let j = 0; j < sliceRank; j++) {\n        const dim = indicesData[i * sliceRank + j];\n        index.push(dim);\n        flattenIndex += dim * strides[j];\n      }\n\n      if (flattenIndex < 0 || flattenIndex >= outputSize / sliceSize) {\n        throw new Error(\n            `Invalid indices: ${index} does not index into ${shape}`);\n      }\n\n      for (let k = 0; k < sliceSize; k++) {\n        if (sumDupeIndices) {\n          buffer.values[flattenIndex * sliceSize + k] +=\n              updatesData[i * sliceSize + k];\n        } else {\n          buffer.values[flattenIndex * sliceSize + k] = updates.rank === 0 ?\n              updatesData[0] :\n              updatesData[i * sliceSize + k];\n        }\n      }\n    }\n    return buffer.toTensor().reshape(shape);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Abs, AbsInputs, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function simpleAbsImpl(vals: TypedArray): Float32Array {\n  const resultValues = new Float32Array(vals.length);\n  for (let i = 0; i < vals.length; ++i) {\n    resultValues[i] = Math.abs(vals[i]);\n  }\n  return resultValues;\n}\n\nexport const abs = (args: {inputs: AbsInputs, backend: MathBackendCPU}) => {\n  const {x} = args.inputs;\n  const cpuBackend = args.backend;\n  let resultValues = new Float32Array(util.sizeFromShape(x.shape));\n  if (x.dtype !== 'complex64') {\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    resultValues = simpleAbsImpl(values);\n  } else {\n    const complexVals = cpuBackend.data.get(x.dataId);\n    const real = complexVals.complexTensorInfos.real;\n    const imag = complexVals.complexTensorInfos.imag;\n    const realVals = cpuBackend.data.get(real.dataId).values as Float32Array;\n    const imagVals = cpuBackend.data.get(imag.dataId).values as Float32Array;\n    for (let i = 0; i < realVals.length; i++) {\n      const real = realVals[i];\n      const imag = imagVals[i];\n      resultValues[i] = Math.hypot(real, imag);\n    }\n  }\n  return cpuBackend.makeOutput(resultValues, x.shape, 'float32');\n};\n\nexport const absConfig: KernelConfig = {\n  kernelName: Abs,\n  backendName: 'cpu',\n  kernelFunc: abs as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleBinaryKernelImpl, SimpleBinaryOperation} from './binary_types';\n\n/**\n * Template that creates implementation for binary ops. Supports broadcast.\n */\nexport function createSimpleBinaryKernelImpl(op: SimpleBinaryOperation):\n    SimpleBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aVals: TypedArray,\n          bVals: TypedArray, dtype: DataType): [TypedArray, number[]] => {\n    const newShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n\n    const resultRank = newShape.length;\n    const resultStrides = util.computeStrides(newShape);\n    const resultSize = util.sizeFromShape(newShape);\n\n    const result =\n        util.getTypedArrayFromDType(dtype as NumericDataType, resultSize);\n\n    const aRank = aShape.length;\n    const bRank = bShape.length;\n\n    const aStrides = util.computeStrides(aShape);\n    const bStrides = util.computeStrides(bShape);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, newShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, newShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < result.length; ++i) {\n        result[i] = op(aVals[i % aVals.length], bVals[i % bVals.length]);\n      }\n    } else {\n      for (let i = 0; i < result.length; ++i) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        result[i] = op(aVals[aIndex], bVals[bIndex]);\n      }\n    }\n\n    return [result, newShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Complex, ComplexInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function complex(args: {inputs: ComplexInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {real, imag} = inputs;\n\n  const realVals = backend.data.get(real.dataId).values as TypedArray;\n  const imagVals = backend.data.get(imag.dataId).values as TypedArray;\n\n  const complexInfo = backend.makeTensorInfo(real.shape, 'complex64');\n\n  const complex = backend.data.get(complexInfo.dataId);\n\n  // The complex tensor owns the underlying real and imag tensorInfos, only the\n  // complex tensor tracks refCount, when complexData is disposed the\n  // underlying tensorData will be disposed.\n  complex.complexTensorInfos = {\n    real: backend.makeTensorInfo(real.shape, 'float32', realVals),\n    imag: backend.makeTensorInfo(imag.shape, 'float32', imagVals)\n  };\n\n  return complexInfo;\n}\n\nexport const complexConfig: KernelConfig = {\n  kernelName: Complex,\n  backendName: 'cpu',\n  kernelFunc: complex as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Identity, IdentityInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function identity(\n    args: {inputs: IdentityInputs, backend: MathBackendCPU}): TensorInfo {\n  const {inputs, backend} = args;\n  const {x} = inputs;\n\n  backend.incRef(x.dataId);\n\n  return {dataId: x.dataId, shape: x.shape, dtype: x.dtype};\n}\n\nexport const identityConfig: KernelConfig = {\n  kernelName: Identity,\n  backendName: 'cpu',\n  kernelFunc: identity as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Real, RealInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function real(args: {inputs: RealInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const real = backend.data.get(input.dataId).complexTensorInfos.real;\n  const realVal = backend.data.get(real.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the real value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(real.shape, real.dtype, realVal);\n}\n\nexport const realConfig: KernelConfig = {\n  kernelName: Real,\n  backendName: 'cpu',\n  kernelFunc: real as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport {Cast, CastAttrs, CastInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nimport {complex} from './Complex';\nimport {identity} from './Identity';\nimport {real} from './Real';\n\nexport function cast(\n    args: {inputs: CastInputs, backend: MathBackendCPU, attrs: CastAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {dtype} = attrs;\n\n  // Casting to complex64.\n  if (dtype === 'complex64') {\n    if (x.dtype === 'complex64') {\n      return identity({inputs: {x}, backend});\n    }\n\n    // TODO(lina128): Import kernel function once zeros is modularized.\n    const zerosTensor = tf.zeros(x.shape);\n    const floatX = cast({inputs: {x}, backend, attrs: {dtype: 'float32'}});\n\n    const result =\n        complex({inputs: {real: floatX, imag: zerosTensor}, backend});\n\n    zerosTensor.dispose();\n    backend.disposeIntermediateTensorInfo(floatX);\n\n    return result;\n  }\n\n  // Casting from complex64\n  if (x.dtype === 'complex64') {\n    const realPart = real({inputs: {input: x}, backend});\n    const result = cast({inputs: {x: realPart}, backend, attrs: {dtype}});\n\n    backend.disposeIntermediateTensorInfo(realPart);\n\n    return result;\n  }\n\n  if (!util.hasEncodingLoss(x.dtype, dtype)) {\n    // We don't change the underlying data, since we cast to higher\n    // precision.\n    const result = identity({inputs: {x}, backend});\n    return {dataId: result.dataId, shape: result.shape, dtype};\n  }\n\n  if (dtype === 'int32') {\n    const values = backend.data.get(x.dataId).values as TypedArray;\n    const resultValues = Int32Array.from(values);\n    return backend.makeTensorInfo(x.shape, 'int32', resultValues);\n  }\n\n  if (dtype === 'bool') {\n    // This is essentially the result of notEqual(x, 0). We avoid using\n    // kernel notEqual to avoid circular dependency, i.e. binary_utils ->\n    // cast -> notEqual -> binary_utils.\n    const xVals = backend.data.get(x.dataId).values as TypedArray;\n    const zero = util.toTypedArray([0], x.dtype);\n\n    const [resultData, resultShape] = createSimpleBinaryKernelImpl(\n        (a, b) => (a !== b) ? 1 : 0)(x.shape, [], xVals, zero, 'bool');\n\n    return backend.makeTensorInfo(resultShape, 'bool', resultData);\n  }\n\n  throw new Error(`Error in Cast: failed to cast ${x.dtype} to ${dtype}`);\n}\n\nexport const castConfig: KernelConfig = {\n  kernelName: Cast,\n  backendName: 'cpu',\n  kernelFunc: cast as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, BinaryInputs, DataType, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {cast} from '../kernels/Cast';\nimport {complex} from '../kernels/Complex';\n\nimport {ComplexBinaryKernelImpl, ComplexBinaryOperation, SimpleBinaryKernelImpl} from './binary_types';\n\n/**\n * Template that creates a `KernelFunc` for binary ops.\n * @param name Kernel name.\n * @param binaryKernelImpl A `SimpleBinaryKernelImpl` for the kernel.\n * @param binaryKernelComplexImpl Optional. If exists, represents a\n *     `ComplexBinaryKernelImpl` for the kernel, will be used when input dtype\n *     is `complex64`.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the first input. This is mainly used in\n *     comparison kernels, such as Equal, Less, Greater, etc.\n */\nexport function binaryKernelFunc(\n    name: string, simpleImpl: SimpleBinaryKernelImpl,\n    complexImpl?: ComplexBinaryKernelImpl, dtype?: DataType): KernelFunc {\n  if (complexImpl == null) {\n    return ({inputs, backend}) => {\n      const {a, b} = inputs as BinaryInputs;\n      const cpuBackend = backend as MathBackendCPU;\n\n      assertNotComplex([a, b], name);\n\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    };\n  }\n\n  return ({inputs, backend}) => {\n    const {a, b} = inputs as BinaryInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    if (a.dtype === 'complex64' || b.dtype === 'complex64') {\n      const $aComplex = cast(\n          {inputs: {x: a}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $aComplexVals = cpuBackend.data.get($aComplex.dataId);\n\n      const aReal = $aComplexVals.complexTensorInfos.real;\n      const aImag = $aComplexVals.complexTensorInfos.imag;\n\n      const aRealVals =\n          cpuBackend.data.get(aReal.dataId).values as Float32Array;\n      const aImagVals =\n          cpuBackend.data.get(aImag.dataId).values as Float32Array;\n\n      const $bComplex = cast(\n          {inputs: {x: b}, backend: cpuBackend, attrs: {dtype: 'complex64'}});\n\n      const $bComplexVals = cpuBackend.data.get($bComplex.dataId);\n\n      const bReal = $bComplexVals.complexTensorInfos.real;\n      const bImag = $bComplexVals.complexTensorInfos.imag;\n\n      const bRealVals =\n          cpuBackend.data.get(bReal.dataId).values as Float32Array;\n      const bImagVals =\n          cpuBackend.data.get(bImag.dataId).values as Float32Array;\n\n      const [resultRealData, resultImagData, resultShape] = complexImpl(\n          a.shape, b.shape, aRealVals, aImagVals, bRealVals, bImagVals);\n\n      const resultReal =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultRealData);\n\n      const resultImag =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', resultImagData);\n\n      const result = complex(\n          {inputs: {real: resultReal, imag: resultImag}, backend: cpuBackend});\n\n      cpuBackend.disposeIntermediateTensorInfo($aComplex);\n      cpuBackend.disposeIntermediateTensorInfo($bComplex);\n      cpuBackend.disposeIntermediateTensorInfo(resultReal);\n      cpuBackend.disposeIntermediateTensorInfo(resultImag);\n\n      return result;\n    } else {\n      const aVals = cpuBackend.data.get(a.dataId).values as TypedArray;\n      const bVals = cpuBackend.data.get(b.dataId).values as TypedArray;\n\n      const $dtype = dtype || a.dtype;\n\n      const [resultData, resultShape] =\n          simpleImpl(a.shape, b.shape, aVals, bVals, $dtype);\n\n      return cpuBackend.makeTensorInfo(resultShape, $dtype, resultData);\n    }\n  };\n}\n\n/**\n * Template that creates the complex type implementation for binary ops.\n * Supports broadcast.\n */\nexport function createComplexBinaryKernelImpl(op: ComplexBinaryOperation):\n    ComplexBinaryKernelImpl {\n  return (aShape: number[], bShape: number[], aRealVals: Float32Array,\n          aImagVals: Float32Array, bRealVals: Float32Array,\n          bImagVals: Float32Array): [TypedArray, TypedArray, number[]] => {\n    const resultShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n    const resultSize = util.sizeFromShape(resultShape);\n    const resultRank = resultShape.length;\n    const resultStrides = util.computeStrides(resultShape);\n\n    const resultRealVals = util.getTypedArrayFromDType('float32', resultSize);\n    const resultImagVals = util.getTypedArrayFromDType('float32', resultSize);\n\n    const aBroadcastDims = backend_util.getBroadcastDims(aShape, resultShape);\n    const bBroadcastDims = backend_util.getBroadcastDims(bShape, resultShape);\n\n    const aVals = backend_util.mergeRealAndImagArrays(aRealVals, aImagVals);\n    const bVals = backend_util.mergeRealAndImagArrays(bRealVals, bImagVals);\n\n    const aRank = aShape.length;\n    const aStrides = util.computeStrides(aShape);\n\n    const bRank = bShape.length;\n    const bStrides = util.computeStrides(bShape);\n\n    if (aBroadcastDims.length + bBroadcastDims.length === 0) {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const aIdx = i % aVals.length;\n        const bIdx = i % bVals.length;\n\n        const result =\n            op(aVals[aIdx * 2], aVals[aIdx * 2 + 1], bVals[bIdx * 2],\n               bVals[bIdx * 2 + 1]);\n\n        resultRealVals[i] = result.real;\n        resultImagVals[i] = result.imag;\n      }\n    } else {\n      for (let i = 0; i < resultRealVals.length; i++) {\n        const loc = util.indexToLoc(i, resultRank, resultStrides);\n\n        const aLoc = loc.slice(-aRank);\n        aBroadcastDims.forEach(d => aLoc[d] = 0);\n        const aIndex = util.locToIndex(aLoc, aRank, aStrides);\n\n        const bLoc = loc.slice(-bRank);\n        bBroadcastDims.forEach(d => bLoc[d] = 0);\n        const bIndex = util.locToIndex(bLoc, bRank, bStrides);\n\n        const opResult =\n            op(aVals[aIndex * 2], aVals[aIndex * 2 + 1], bVals[bIndex * 2],\n               bVals[bIndex * 2 + 1]);\n\n        resultRealVals[i] = opResult.real;\n        resultImagVals[i] = opResult.imag;\n      }\n    }\n    return [resultRealVals, resultImagVals, resultShape];\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Add, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const addImpl = createSimpleBinaryKernelImpl(((a, b) => a + b));\nexport const addComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal + bReal, imag: aImag + bImag};\n    }));\n\nexport const add = binaryKernelFunc(Add, addImpl, addComplexImpl);\n\nexport const addConfig: KernelConfig = {\n  kernelName: Add,\n  backendName: 'cpu',\n  kernelFunc: add\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NumericDataType, util} from '@tensorflow/tfjs-core';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates implementation for unary op.\n */\nexport function createSimpleUnaryImpl(op: SimpleUnaryOperation):\n    SimpleUnaryImpl {\n  return (values, dtype, attrs) => {\n    const newValues =\n        util.getTypedArrayFromDType(dtype as NumericDataType, values.length);\n    for (let i = 0; i < values.length; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return newValues;\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelFunc, TypedArray, UnaryInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {SimpleUnaryImpl, SimpleUnaryOperation} from './unary_types';\n\n/**\n * Template that creates a `KernelFunc` for unary ops.\n * @param name Kernel name.\n * @param op A `SimpleUnaryOperation` for the kernel.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFunc(\n    name: string, op: SimpleUnaryOperation, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xSize = util.sizeFromShape(x.shape);\n    const $dtype = dtype || x.dtype;\n    const newValues = util.getArrayFromDType($dtype, xSize);\n    for (let i = 0; i < xSize; ++i) {\n      newValues[i] = op(values[i], attrs);\n    }\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n\n/**\n * Template that creates a `KernelFunc` for unary ops from the given\n * `SimpleUnaryImpl`..\n * @param name Kernel name.\n * @param unaryImpl A `SimpleUnaryImpl` that implements the op.\n * @param dtype Optional. If set, the result has this dtype. Otherwise, the\n *     result has the same dtype as the input. This is mainly used in certain\n *     kernels that return bool type, such as isFinite, isInf, etc.\n */\nexport function unaryKernelFuncFromImpl(\n    name: string, unaryImpl: SimpleUnaryImpl, dtype?: DataType): KernelFunc {\n  return ({inputs, attrs, backend}) => {\n    const {x} = inputs as UnaryInputs;\n    assertNotComplex(x, name);\n    if (x.dtype === 'string' || dtype === 'string') {\n      throw new Error('unaryKernelFunc does not support string input/output');\n    }\n\n    const cpuBackend = backend as MathBackendCPU;\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const $dtype = dtype || x.dtype;\n    const newValues = unaryImpl(values, $dtype, attrs);\n    return cpuBackend.makeTensorInfo(x.shape, $dtype, newValues);\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Ceil, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const ceilImpl = createSimpleUnaryImpl((xi) => Math.ceil(xi));\nexport const ceil = unaryKernelFuncFromImpl(Ceil, ceilImpl);\n\nexport const ceilConfig: KernelConfig = {\n  kernelName: Ceil,\n  backendName: 'cpu',\n  kernelFunc: ceil,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Exp, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expImpl = createSimpleUnaryImpl((xi) => Math.exp(xi));\nexport const exp = unaryKernelFuncFromImpl(Exp, expImpl);\n\nexport const expConfig: KernelConfig = {\n  kernelName: Exp,\n  backendName: 'cpu',\n  kernelFunc: exp,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Expm1, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const expm1Impl = createSimpleUnaryImpl((xi) => Math.expm1(xi));\nexport const expm1 = unaryKernelFuncFromImpl(Expm1, expm1Impl);\n\nexport const expm1Config: KernelConfig = {\n  kernelName: Expm1,\n  backendName: 'cpu',\n  kernelFunc: expm1,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Floor, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const floorImpl = createSimpleUnaryImpl((xi) => Math.floor(xi));\nexport const floor = unaryKernelFuncFromImpl(Floor, floorImpl);\n\nexport const floorConfig: KernelConfig = {\n  kernelName: Floor,\n  backendName: 'cpu',\n  kernelFunc: floor,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const logImpl = createSimpleUnaryImpl((xi) => Math.log(xi));\nexport const log = unaryKernelFuncFromImpl(Log, logImpl);\n\nexport const logConfig: KernelConfig = {\n  kernelName: Log,\n  backendName: 'cpu',\n  kernelFunc: log,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function maxImpl(\n    aVals: TypedArray, reduceSize: number, outShape: number[],\n    dtype: DataType): TypedArray {\n  const vals = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(outShape));\n\n  for (let i = 0; i < vals.length; ++i) {\n    const offset = i * reduceSize;\n    let max = aVals[offset];\n    for (let j = 0; j < reduceSize; ++j) {\n      const value = aVals[offset + j];\n      if (value > max) {\n        max = value;\n      }\n    }\n    vals[i] = max;\n  }\n  return vals;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Multiply} from '@tensorflow/tfjs-core';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const multiplyImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue * bValue));\nexport const multiplyComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {\n        real: aReal * bReal - aImag * bImag,\n        imag: aReal * bImag + aImag * bReal\n      };\n    }));\n\nexport const multiply =\n    binaryKernelFunc(Multiply, multiplyImpl, multiplyComplexImpl);\n\nexport const multiplyConfig: KernelConfig = {\n  kernelName: Multiply,\n  backendName: 'cpu',\n  kernelFunc: multiply\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NotEqual} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const notEqualImpl =\n    createSimpleBinaryKernelImpl(((a, b) => (a !== b) ? 1 : 0));\nexport const notEqual =\n    binaryKernelFunc(NotEqual, notEqualImpl, null /* complexOp */, 'bool');\n\nexport const notEqualConfig: KernelConfig = {\n  kernelName: NotEqual,\n  backendName: 'cpu',\n  kernelFunc: notEqual\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Rsqrt} from '@tensorflow/tfjs-core';\n\nimport {createSimpleUnaryImpl} from '../utils/unary_impl';\nimport {unaryKernelFuncFromImpl} from '../utils/unary_utils';\n\nexport const rsqrtImpl = createSimpleUnaryImpl((xi) => 1 / Math.sqrt(xi));\nexport const rsqrt = unaryKernelFuncFromImpl(Rsqrt, rsqrtImpl);\n\nexport const rsqrtConfig: KernelConfig = {\n  kernelName: Rsqrt,\n  backendName: 'cpu',\n  kernelFunc: rsqrt,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, KernelConfig, KernelFunc, NumericDataType, Slice, slice_util, SliceAttrs, SliceInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function sliceImpl(\n    vals: TypedArray, begin: number[], size: number[], shape: number[],\n    dtype: DataType): TypedArray {\n  const isContinous = slice_util.isSliceContinous(shape, begin, size);\n  const length = util.sizeFromShape(size);\n  const xStrides = util.computeStrides(shape);\n\n  if (isContinous) {\n    const flatOffset = slice_util.computeFlatOffset(begin, xStrides);\n    return vals.subarray(flatOffset, flatOffset + length);\n  }\n\n  const outVals = util.getTypedArrayFromDType(dtype as NumericDataType, length);\n  for (let i = 0; i < length; ++i) {\n    const rank = size.length;\n    const strides = util.computeStrides(size);\n    const loc = util.indexToLoc(i, rank, strides);\n    const xLoc = loc.map((idx: number, j) => idx + begin[j]);\n    const xIndex = util.locToIndex(xLoc, shape.length, xStrides);\n    outVals[i] = vals[xIndex];\n  }\n  return outVals;\n}\n\nexport function slice(\n    args: {inputs: SliceInputs, backend: MathBackendCPU, attrs: SliceAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {begin, size} = attrs;\n\n  assertNotComplex(x, 'slice');\n\n  const [$begin, $size] = slice_util.parseSliceParams(x, begin, size);\n  slice_util.assertParamsValid(x, $begin, $size);\n\n  const vals = backend.data.get(x.dataId).values as TypedArray;\n  const outVals = sliceImpl(vals, $begin, $size, x.shape, x.dtype);\n  return backend.makeTensorInfo($size, x.dtype, outVals);\n}\n\nexport const sliceConfig: KernelConfig = {\n  kernelName: Slice,\n  backendName: 'cpu',\n  kernelFunc: slice as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, SquaredDifference} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const squaredDifferenceImpl = createSimpleBinaryKernelImpl(((a, b) => {\n  const diff = a - b;\n  return diff * diff;\n}));\nexport const squaredDifference =\n    binaryKernelFunc(SquaredDifference, squaredDifferenceImpl);\n\nexport const squaredDifferenceConfig: KernelConfig = {\n  kernelName: SquaredDifference,\n  backendName: 'cpu',\n  kernelFunc: squaredDifference\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sub} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc, createComplexBinaryKernelImpl} from '../utils/kernel_utils';\n\nexport const subImpl =\n    createSimpleBinaryKernelImpl(((aValue, bValue) => aValue - bValue));\nexport const subComplexImpl =\n    createComplexBinaryKernelImpl(((aReal, aImag, bReal, bImag) => {\n      return {real: aReal - bReal, imag: aImag - bImag};\n    }));\nexport const sub = binaryKernelFunc(Sub, subImpl, subComplexImpl);\n\nexport const subConfig: KernelConfig = {\n  kernelName: Sub,\n  backendName: 'cpu',\n  kernelFunc: sub\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {util} from '@tensorflow/tfjs-core';\n\nexport function transposeImpl(\n    xVals: TypedArray, xShape: number[], dtype: DataType, perm: number[],\n    newShape: number[]): TypedArray {\n  const xRank = xShape.length;\n  const xSize = util.sizeFromShape(xShape);\n  const xStrides = util.computeStrides(xShape);\n  const newStrides = util.computeStrides(newShape);\n\n  const result = util.getTypedArrayFromDType(\n      dtype as NumericDataType, util.sizeFromShape(newShape));\n\n  for (let i = 0; i < xSize; ++i) {\n    const loc = util.indexToLoc(i, xRank, xStrides);\n\n    // Permute location.\n    const newLoc: number[] = new Array(loc.length);\n    for (let i = 0; i < newLoc.length; i++) {\n      newLoc[i] = loc[perm[i]];\n    }\n\n    const newIndex = util.locToIndex(newLoc, xRank, newStrides);\n    result[newIndex] = xVals[i];\n  }\n  return result;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BackendValues, DataType, TensorBuffer, TypedArray, util} from '@tensorflow/tfjs-core';\n\nexport function uniqueImpl(\n    values: BackendValues, axis: number, shape: number[], dtype: DataType): {\n  outputValues: BackendValues,\n  outputShape: number[],\n  indices: BackendValues\n} {\n  // Normalize and validate axis.\n  const $axis = util.parseAxisParam(axis, shape)[0];\n\n  // Calculate the new shape that is suitable for extracting data along the\n  // given axis.\n  //\n  // The rank is 3.\n  // The size of the 1st dimension is the size of all the axes < the given axis.\n  // The size of the 2nd dimension is the same as the size of the given axis.\n  // The size of the 3rd dimension is the size of all the axes > the given axis.\n  //\n  // For example, for a 4D tensor with shape=[2, 3, 5, 4] and axis=2, the\n  // newShape would be: [2*3, 5, 4].\n  //\n  // Note that this is not the final output shape. This will be the shape for an\n  // intermediate TensorBuffer (see inputBuffer below) to allow us to extract\n  // values along the given axis. To demonstrate how it works, consider the\n  // following example:\n  //\n  // Input: a 3D tensor, with shape [1, 2, 3]\n  // [\n  //   [\n  //      [1,2,3],\n  //      [4,5,6]\n  //   ]\n  // ]\n  // Axis: 2 (the last axis).\n  // Along axis 2, we expect to extract 3 tensors: [1,4], [2,5], [3,6].\n  //\n  // For this example, newShape would be: [2, 3, 1], where 2 is calculated from\n  // 1*2. The re-shaped data would look like:\n  //\n  // [\n  //   [\n  //     [1], [2], [3]\n  //   ],\n  //   [\n  //     [4], [5], [6]\n  //   ]\n  // ]\n  //\n  // Then, we can construct a 3-level nested loop by the following dimension\n  // order to extract the values along the axis (dimension1):\n  // i: dimension1       // 0,1,2 (newShape[1])\n  //   m: dimension0     // 0,1   (newShape[0])\n  //     n: dimension2   // 0     (newShape[2])\n  //\n  //                       m, i, n\n  //                      ---------\n  // Iteration 0: data at [0, 0, 0] => \"1\"\n  // Iteration 1: data at [1, 0, 0] => \"4\"\n  // We got [1,4].\n  // Iteration 2: data at [0, 1, 0] => \"2\"\n  // Iteration 3: data at [1, 1, 0] => \"5\"\n  // We got [2,5].\n  // Iteration 4: data at [0, 2, 0] => \"3\"\n  // Iteration 5: data at [1, 2, 0] => \"6\"\n  // We got [3,6].\n  const newShape = [1, shape[0], 1];\n  for (let i = 0; i < $axis; i++) {\n    newShape[0] *= shape[i];\n  }\n  newShape[1] = shape[$axis];\n  for (let i = $axis + 1; i < shape.length; i++) {\n    newShape[2] *= shape[i];\n  }\n\n  // A map from unique elements (their string representations) to their values\n  // in \"indices\" (below).\n  const uniqueElements: {[key: string]: number} = {};\n  // The indices of each unique element in the original tensor along the given\n  // axis. It is 1D and has the same size as the given axis.\n  const indices = new Int32Array(shape[$axis]);\n  // Create a buffer so we can easily extract value at a given location.\n  const inputBuffer = new TensorBuffer(newShape, dtype, values as TypedArray);\n  // The indices along the given axis that have unique elements. This is a\n  // de-duped version of \"indices\" above.\n  const uniqueIndices: number[] = [];\n  const is1DTensor = newShape[0] === 1 && newShape[2] === 1;\n  for (let i = 0; i < shape[$axis]; i++) {\n    // Extract values along the axis.\n    let element: string;\n    if (is1DTensor) {\n      // Fast path for 1D tensor input.\n      element = values[i].toString();\n    } else {\n      const axisValues = [];\n      for (let m = 0; m < newShape[0]; m++) {\n        for (let n = 0; n < newShape[2]; n++) {\n          axisValues.push(inputBuffer.get(m, i, n));\n        }\n      }\n      element = axisValues.join(',');\n    }\n\n    // Dedup and update various indices.\n    if (uniqueElements[element] !== undefined) {\n      indices[i] = uniqueElements[element];\n    } else {\n      const uniqueIndex = Object.keys(uniqueElements).length;\n      uniqueElements[element] = uniqueIndex;\n      indices[i] = uniqueIndex;\n      uniqueIndices.push(i);\n    }\n  }\n\n  // Now we know where each of the unique elements are located along the axis\n  // (uniqueIndices). Extract them from input buffer and store them in the\n  // output buffer.\n  const outputTmpShape = newShape.slice();\n  outputTmpShape[1] = Object.keys(uniqueElements).length;\n  const outputBuffer = new TensorBuffer(outputTmpShape, dtype);\n  uniqueIndices.forEach((uniqueElementIndex, i) => {\n    for (let m = 0; m < newShape[0]; m++) {\n      for (let n = 0; n < newShape[2]; n++) {\n        outputBuffer.set(inputBuffer.get(m, uniqueElementIndex, n), m, i, n);\n      }\n    }\n  });\n\n  // The output shape can be calculated from the input shape with the size of\n  // the given axis replaced by the number of unique elements along that axis.\n  const outputShape = shape.slice();\n  outputShape[$axis] = outputTmpShape[1];\n\n  return {\n    outputValues: outputBuffer.values as BackendValues,\n    outputShape,\n    indices,\n  };\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\n/*\n * base.ts contains all the exports from tfjs-backend-cpu\n * without auto-kernel registration\n */\nimport {registerBackend} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from './backend_cpu';\nimport * as shared from './shared';\n\nexport {MathBackendCPU} from './backend_cpu';\nexport {version as version_cpu} from './version';\nexport {shared};\n\n// Side effects for default initialization of MathBackendCPU\nregisterBackend('cpu', () => new MathBackendCPU(), 1 /* priority */);\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Elu, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const elu =\n    unaryKernelFunc(Elu, (xi) => xi >= 0 ? xi : (Math.exp(xi) - 1));\n\nexport const eluConfig: KernelConfig = {\n  kernelName: Elu,\n  backendName: 'cpu',\n  kernelFunc: elu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Prelu, PreluInputs, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\n\nconst preluImpl = createSimpleBinaryKernelImpl(\n    (xValue: number, aValue: number) => xValue < 0 ? aValue * xValue : xValue);\n\nexport function prelu(args: {inputs: PreluInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {x, alpha} = inputs;\n\n  assertNotComplex([x, alpha], 'prelu');\n\n  const aVals = backend.data.get(x.dataId).values as TypedArray;\n  const bVals = backend.data.get(alpha.dataId).values as TypedArray;\n\n  const [resultData, resultShape] =\n      preluImpl(x.shape, alpha.shape, aVals, bVals, x.dtype);\n\n  return backend.makeTensorInfo(resultShape, x.dtype, resultData);\n}\n\nexport const preluConfig: KernelConfig = {\n  kernelName: Prelu,\n  backendName: 'cpu',\n  kernelFunc: prelu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu = unaryKernelFunc(Relu, (xi) => Math.max(0, xi));\n\nexport const reluConfig: KernelConfig = {\n  kernelName: Relu,\n  backendName: 'cpu',\n  kernelFunc: relu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Relu6} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const relu6 =\n    unaryKernelFunc(Relu6, (xi) => Math.min(Math.max(0, xi), 6));\n\nexport const relu6Config: KernelConfig = {\n  kernelName: Relu6,\n  backendName: 'cpu',\n  kernelFunc: relu6,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, backend_util, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {elu} from '../kernels/Elu';\nimport {identity} from '../kernels/Identity';\nimport {prelu} from '../kernels/Prelu';\nimport {relu} from '../kernels/Relu';\nimport {relu6} from '../kernels/Relu6';\n\nexport function applyActivation(\n    backend: MathBackendCPU, x: TensorInfo, activation: backend_util.Activation,\n    preluActivationWeights?: TensorInfo): TensorInfo {\n  if (activation === 'linear') {\n    return identity({inputs: {x}, backend});\n  } else if (activation === 'relu') {\n    return relu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'elu') {\n    return elu({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'relu6') {\n    return relu6({inputs: {x}, backend}) as TensorInfo;\n  } else if (activation === 'prelu') {\n    return prelu({inputs: {x, alpha: preluActivationWeights}, backend});\n  }\n  throw new Error(\n      `Activation ${activation} has not been implemented for the CPU backend.`);\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, Reshape, ReshapeAttrs, ReshapeInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function reshape(\n    args:\n        {inputs: ReshapeInputs, backend: MathBackendCPU, attrs: ReshapeAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {shape} = attrs;\n\n  const xSize = util.sizeFromShape(x.shape);\n  const $shape = util.inferFromImplicitShape(shape, xSize);\n  const $xSize = util.sizeFromShape($shape);\n\n  util.assert(\n      xSize === $xSize,\n      () => `The new shape (${$shape}) has ${$xSize} elements and the old ` +\n          `shape (${x.shape}) has ${xSize} elements. The new shape and old ` +\n          `shape must have the same number of elements.`);\n\n  backend.incRef(x.dataId);\n\n  const xData = backend.data.get(x.dataId);\n\n  if (xData.complexTensorInfos != null) {\n    const real = xData.complexTensorInfos.real;\n    const imag = xData.complexTensorInfos.imag;\n\n    real.shape = $shape;\n    imag.shape = $shape;\n  }\n\n  return {dataId: x.dataId, shape: $shape, dtype: x.dtype};\n}\n\nexport const reshapeConfig: KernelConfig = {\n  kernelName: Reshape,\n  backendName: 'cpu',\n  kernelFunc: reshape as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, buffer, KernelConfig, KernelFunc, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {reshape} from './Reshape';\n\nexport function batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  attrs: BatchMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  assertNotComplex([a, b], 'matMul');\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const batchDimsCompatible =\n      batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n\n  util.assert(\n      aRank >= 2 && bRank >= 2 && batchDimsCompatible,\n      () => `Error in matMul: the input batch dimensions must either be the ` +\n          `same or at least one input batch dimension must be 1. Got input ` +\n          `batch dimensions of (${outerDimsA}) and (${outerDimsB}).`);\n\n  const outShapeOuterDims =\n      batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const a3dValues = backend.data.get(a3d.dataId).values as TypedArray;\n  const b3dValues = backend.data.get(b3d.dataId).values as TypedArray;\n\n  const a3dStrides = util.computeStrides(a3d.shape);\n  const b3dStrides = util.computeStrides(b3d.shape);\n\n  const [aBatch, aOuterStep, aInnerStep] = transposeA ?\n      [a3dStrides[0], 1, a3dStrides[1]] :\n      [a3dStrides[0], a3dStrides[1], 1];\n  const [bInnerStep, bOuterStep, bBatch] = transposeB ?\n      [1, b3dStrides[1], b3dStrides[0]] :\n      [b3dStrides[1], 1, b3dStrides[0]];\n\n  const size = leftDim * rightDim;\n  const result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n\n  const resVals = result.values as TypedArray;\n  const blockSize = backend.blockSize;\n\n  for (let bi = 0; bi < batchDim; bi++) {\n    for (let i0 = 0; i0 < leftDim; i0 += blockSize) {\n      for (let j0 = 0; j0 < rightDim; j0 += blockSize) {\n        for (let k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          // for when blockSize doesn't evenly divide the input\n          const iBlock = Math.min(i0 + blockSize, leftDim);\n          const jBlock = Math.min(j0 + blockSize, rightDim);\n          const kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (let i = i0; i < iBlock; i++) {\n            for (let j = j0; j < jBlock; j++) {\n              let sum = 0.0;\n\n              for (let k = k0; k < kBlock; k++) {\n                const batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                const batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                const aVal =\n                    a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                const bVal =\n                    b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                sum += aVal * bVal;\n              }\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d);\n\n  // set correct shape on output.\n  return backend.makeTensorInfo(\n      outShape, result.dtype, result.values as TypedArray);\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {_FusedMatMul, _FusedMatMulAttrs, _FusedMatMulInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\n\nimport {add} from './Add';\nimport {batchMatMul} from './BatchMatMul';\n\nexport function _fusedMatMul(args: {\n  inputs: _FusedMatMulInputs,\n  attrs: _FusedMatMulAttrs,\n  backend: MathBackendCPU\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b, bias, preluActivationWeights} = inputs;\n  const {transposeA, transposeB, activation} = attrs;\n\n  let current;\n  let addRes;\n  let activationRes;\n\n  const intermediates: TensorInfo[] = [];\n\n  const matMulRes =\n      batchMatMul({inputs: {a, b}, attrs: {transposeA, transposeB}, backend});\n  current = matMulRes;\n\n  if (bias) {\n    addRes = add({inputs: {a: current, b: bias}, backend}) as TensorInfo;\n    intermediates.push(current);\n    current = addRes;\n  }\n  if (activation) {\n    activationRes =\n        applyActivation(backend, current, activation, preluActivationWeights);\n    intermediates.push(current);\n    current = activationRes;\n  }\n\n  for (const i of intermediates) {\n    backend.disposeIntermediateTensorInfo(i);\n  }\n\n  return current;\n}\n\nexport const _fusedMatMulConfig: KernelConfig = {\n  kernelName: _FusedMatMul,\n  backendName: 'cpu',\n  kernelFunc: _fusedMatMul as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acos = unaryKernelFunc(Acos, (xi) => Math.acos(xi));\n\nexport const acosConfig: KernelConfig = {\n  kernelName: Acos,\n  backendName: 'cpu',\n  kernelFunc: acos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Acosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const acosh = unaryKernelFunc(Acosh, (xi) => Math.acosh(xi));\n\nexport const acoshConfig: KernelConfig = {\n  kernelName: Acosh,\n  backendName: 'cpu',\n  kernelFunc: acosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asin, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asin = unaryKernelFunc(Asin, (xi) => Math.asin(xi));\n\nexport const asinConfig: KernelConfig = {\n  kernelName: Asin,\n  backendName: 'cpu',\n  kernelFunc: asin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Asinh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const asinh = unaryKernelFunc(Asinh, (xi) => Math.asinh(xi));\n\nexport const asinhConfig: KernelConfig = {\n  kernelName: Asinh,\n  backendName: 'cpu',\n  kernelFunc: asinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atan = unaryKernelFunc(Atan, (xi) => Math.atan(xi));\n\nexport const atanConfig: KernelConfig = {\n  kernelName: Atan,\n  backendName: 'cpu',\n  kernelFunc: atan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Atanh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const atanh = unaryKernelFunc(Atanh, (xi) => Math.atanh(xi));\n\nexport const atanhConfig: KernelConfig = {\n  kernelName: Atanh,\n  backendName: 'cpu',\n  kernelFunc: atanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, buffer, DataType, Rank, TensorBuffer, TypedArray} from '@tensorflow/tfjs-core';\n\nexport function pool(\n    xValues: TypedArray, xShape: number[], dtype: DataType, strides: number[],\n    convInfo: backend_util.Conv2DInfo,\n    poolType: 'max'|'avg'): TensorBuffer<Rank, DataType> {\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const initialValue =\n      (poolType === 'max' ? Number.NEGATIVE_INFINITY :\n                            Number.POSITIVE_INFINITY);\n\n  const output = buffer(convInfo.outShape, dtype);\n  const outputVals = output.values;\n\n  const outputBatchStrides =\n      convInfo.outShape[1] * convInfo.outShape[2] * convInfo.outShape[3];\n  const outputRowStrides = convInfo.outShape[2] * convInfo.outShape[3];\n  const outputColStrides = convInfo.outShape[3];\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const outputBatchOffset = b * outputBatchStrides;\n    const inputBatchOffset = b * strides[0];\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        const outputRowOffset = outputBatchOffset + yR * outputRowStrides;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          const xCMin = Math.max(0, xCCorner);\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let minMaxValue = initialValue;\n          let avgValue = 0;\n          let count = 0;\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const xROffset = inputBatchOffset + xR * strides[1];\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const xCOffset = xROffset + xC * strides[2];\n              const pixel = xValues[xCOffset + d];\n              if ((poolType === 'max' && pixel > minMaxValue)) {\n                minMaxValue = pixel;\n              } else if (poolType === 'avg') {\n                avgValue += pixel;\n                count++;\n              }\n            }\n            if (isNaN(minMaxValue)) {\n              break;\n            }\n          }\n          const outputOffset = outputRowOffset + yC * outputColStrides + d;\n          outputVals[outputOffset] =\n              poolType === 'avg' ? avgValue / count : minMaxValue;\n        }\n      }\n    }\n  }\n  return output;\n}\n\nexport function maxPoolPositions(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    convInfo: backend_util.Conv2DInfo, flattenPositions = false,\n    includeBatchInIndex = false): TensorBuffer<Rank, 'int32'> {\n  const maxPositions = buffer(convInfo.outShape, 'int32');\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padTop = convInfo.padInfo.top;\n  const padLeft = convInfo.padInfo.left;\n\n  const xBuf = buffer(xShape, dtype, xValues);\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n        const xRCorner = yR * strideHeight - padTop;\n        let xRMin = xRCorner;\n        while (xRMin < 0) {\n          xRMin += dilationHeight;\n        }\n        // const xRMin = Math.max(0, xRCorner);\n        const xRMax =\n            Math.min(convInfo.inHeight, effectiveFilterHeight + xRCorner);\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const xCCorner = yC * strideWidth - padLeft;\n          let xCMin = xCCorner;\n          while (xCMin < 0) {\n            xCMin += dilationWidth;\n          }\n          const xCMax =\n              Math.min(convInfo.inWidth, effectiveFilterWidth + xCCorner);\n          let maxValue = Number.NEGATIVE_INFINITY;\n          let maxPosition = -1;\n\n          for (let xR = xRMin; xR < xRMax; xR += dilationHeight) {\n            const wR = xR - xRCorner;\n            for (let xC = xCMin; xC < xCMax; xC += dilationWidth) {\n              const wC = xC - xCCorner;\n              const pixel = xBuf.get(b, xR, xC, d);\n              if (pixel > maxValue) {\n                maxValue = pixel as number;\n                if (flattenPositions) {\n                  maxPosition = includeBatchInIndex ?\n                      ((b * convInfo.inHeight + xR) * convInfo.inWidth + xC) *\n                              convInfo.inChannels +\n                          d :\n                      (xR * convInfo.inWidth + xC) * convInfo.inChannels + d;\n                } else {\n                  maxPosition = wR * effectiveFilterWidth + wC;\n                }\n              }\n            }\n          }\n          maxPositions.set(maxPosition, b, yR, yC, d);\n        }\n      }\n    }\n  }\n  return maxPositions;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPool, AvgPoolAttrs, AvgPoolInputs, backend_util, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function avgPool(\n    args:\n        {inputs: AvgPoolInputs, backend: MathBackendCPU, attrs: AvgPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'avgPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in avgPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'avg');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const avgPoolConfig: KernelConfig = {\n  kernelName: AvgPool,\n  backendName: 'cpu',\n  kernelFunc: avgPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {AvgPoolBackprop, AvgPoolBackpropAttrs, AvgPoolBackpropInputs, backend_util, buffer, KernelConfig, KernelFunc, Rank, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function avgPoolBackprop(args: {\n  inputs: AvgPoolBackpropInputs,\n  backend: MathBackendCPU,\n  attrs: AvgPoolBackpropAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input} = inputs;\n  const x = input;\n  assertNotComplex([dy, input], 'avgPoolBackprop');\n  const {filterSize, strides, pad} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const avgMultiplier = 1 / (filterHeight * filterWidth);\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel;\n            }\n          }\n          dx.set(dotProd * avgMultiplier, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const avgPoolBackpropConfig: KernelConfig = {\n  kernelName: AvgPoolBackprop,\n  backendName: 'cpu',\n  kernelFunc: avgPoolBackprop as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedBatchNorm, FusedBatchNormAttrs, FusedBatchNormInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function batchNorm(args: {\n  inputs: FusedBatchNormInputs,\n  backend: MathBackendCPU,\n  attrs: FusedBatchNormAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, scale, offset, mean, variance} = inputs;\n\n  util.assert(\n      mean.shape.length === variance.shape.length,\n      () => 'Batch normalization gradient requires mean and variance to have ' +\n          'equal ranks.');\n  util.assert(\n      offset == null || mean.shape.length === offset.shape.length,\n      () => 'Batch normalization gradient requires mean and offset to have ' +\n          'equal ranks.');\n  util.assert(\n      scale == null || mean.shape.length === scale.shape.length,\n      () => 'Batch normalization gradient requires mean and scale to have ' +\n          'equal ranks.');\n\n  assertNotComplex([x, mean, variance, scale, offset], 'batchNorm');\n\n  let {varianceEpsilon} = attrs;\n  if (varianceEpsilon == null) {\n    varianceEpsilon = 0.001;\n  }\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const mVals = backend.data.get(mean.dataId).values as TypedArray;\n  const varVals = backend.data.get(variance.dataId).values as TypedArray;\n  const sVals = scale ? backend.data.get(scale.dataId).values as TypedArray :\n                        new Float32Array([1]);\n  const offVals = offset ?\n      backend.data.get(offset.dataId).values as TypedArray :\n      new Float32Array([0]);\n  const outVals = new Float32Array(xVals.length);\n\n  const offValsLength = offVals.length;\n  const sValsLength = sVals.length;\n  const varValsLength = varVals.length;\n  const mValsLength = mVals.length;\n\n  let offi = 0;\n  let mi = 0;\n  let si = 0;\n  let vi = 0;\n  for (let i = 0; i < xVals.length; ++i) {\n    outVals[i] = offVals[offi++] +\n        (xVals[i] - mVals[mi++]) * sVals[si++] /\n            Math.sqrt(varVals[vi++] + varianceEpsilon);\n    if (offi >= offValsLength) {\n      offi = 0;\n    }\n    if (mi >= mValsLength) {\n      mi = 0;\n    }\n    if (si >= sValsLength) {\n      si = 0;\n    }\n    if (vi >= varValsLength) {\n      vi = 0;\n    }\n  }\n  return backend.makeTensorInfo(x.shape, x.dtype, outVals);\n}\n\nexport const batchNormConfig: KernelConfig = {\n  kernelName: FusedBatchNorm,\n  backendName: 'cpu',\n  kernelFunc: batchNorm as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {ClipByValue, ClipByValueAttrs, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const clip = unaryKernelFunc(ClipByValue, (xi, attrs) => {\n  const clipAttrs = attrs as {} as ClipByValueAttrs;\n  if (xi > clipAttrs.clipValueMax) {\n    return clipAttrs.clipValueMax;\n  }\n  return xi < clipAttrs.clipValueMin ? clipAttrs.clipValueMin : xi;\n});\n\nexport const clipConfig: KernelConfig = {\n  kernelName: ClipByValue,\n  backendName: 'cpu',\n  kernelFunc: clip,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Imag, ImagInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function imag(args: {inputs: ImagInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const imag = backend.data.get(input.dataId).complexTensorInfos.imag;\n  const imagVal = backend.data.get(imag.dataId).values;\n\n  // When complex tensor is disposed, its underlying parts will be disposed too.\n  // Make new tensor out of the imag value of the complex. This makes sure the\n  // value is still accessible even if complex tensor is disposed.\n  return backend.makeTensorInfo(imag.shape, imag.dtype, imagVal);\n}\n\nexport const imagConfig: KernelConfig = {\n  kernelName: Imag,\n  backendName: 'cpu',\n  kernelFunc: imag as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Concat, ConcatAttrs, ConcatInputs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nimport {complex} from './Complex';\nimport {imag} from './Imag';\nimport {real} from './Real';\nimport {reshape} from './Reshape';\n\nexport function concat(\n    args: {inputs: ConcatInputs, backend: MathBackendCPU, attrs: ConcatAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {axis} = attrs;\n\n  const $axis = util.parseAxisParam(axis, inputs[0].shape)[0];\n  let outShape = backend_util.computeOutShape(inputs.map(t => t.shape), $axis);\n\n  if (util.sizeFromShape(outShape) === 0) {\n    return backend.makeTensorInfo(outShape, inputs[0].dtype, []);\n  }\n\n  // Keep only non-empty tensors (ignore tensors with 0 in their shape).\n  const $inputs = inputs.filter(t => util.sizeFromShape(t.shape) > 0);\n  if ($inputs.length === 1) {\n    return $inputs[0];\n  }\n\n  const shapes = $inputs.map(t => t.shape);\n  backend_util.assertParamsConsistent(shapes, $axis);\n\n  if ($inputs[0].dtype === 'complex64') {\n    const reals = $inputs.map((t) => real({inputs: {input: t}, backend}));\n    const imags = $inputs.map((t) => imag({inputs: {input: t}, backend}));\n\n    const realConcated = concat({inputs: reals, backend, attrs: {axis: $axis}});\n    const imagConcated = concat({inputs: imags, backend, attrs: {axis: $axis}});\n\n    const result =\n        complex({inputs: {real: realConcated, imag: imagConcated}, backend});\n\n    reals.forEach(r => backend.disposeIntermediateTensorInfo(r));\n    imags.forEach(i => backend.disposeIntermediateTensorInfo(i));\n    backend.disposeIntermediateTensorInfo(realConcated);\n    backend.disposeIntermediateTensorInfo(imagConcated);\n\n    return result;\n  }\n\n  // Any concat of n-dimensional tensors across any axis can be reduced to\n  // a concatenation of two-dimensional tensors across the axis 1 by first\n  // partitioning the axes of the original tensors into those less than the\n  // axis to be concatenated and the rest. Then reshape the tensors\n  // into a two-dimensional tensor by collapsing these two sets of axes and\n  // concatenate the resulting matrices across the axis 1, finally reshaping\n  // the result to have the proper shape.\n  const inputs2D = $inputs.map(t => {\n    const innerSize = util.sizeFromShape(t.shape.slice($axis));\n    const shape = [-1, innerSize];\n    return reshape({inputs: {x: t}, backend, attrs: {shape}});\n  });\n\n  // Concats 2d tensors along axis=1.\n  outShape =\n      backend_util.computeOutShape(inputs2D.map(t => t.shape), 1 /* axis */);\n\n  const outVals = util.getTypedArrayFromDType(\n      $inputs[0].dtype as 'float32', util.sizeFromShape(outShape));\n\n  if (inputs2D[0].shape[0] === 1) {\n    // Use built-in TypedArray.set() method for speed.\n    let offset = 0;\n    inputs2D.forEach(t => {\n      const val = backend.data.get(t.dataId).values as TypedArray;\n      const size = util.sizeFromShape(t.shape);\n\n      outVals.set(val, offset);\n      offset += size;\n    });\n  } else {\n    let colOffset = 0;\n\n    inputs2D.forEach(t => {\n      const tVals = backend.data.get(t.dataId).values as TypedArray;\n\n      let tIdx = 0;\n\n      for (let row = 0; row < t.shape[0]; ++row) {\n        const resIdx = row * outShape[1] + colOffset;\n        for (let col = 0; col < t.shape[1]; ++col) {\n          outVals[resIdx + col] = tVals[tIdx++];\n        }\n      }\n\n      colOffset += t.shape[1];\n    });\n  }\n\n  const finalOutShape =\n      backend_util.computeOutShape($inputs.map(t => t.shape), $axis);\n\n  const outInfo =\n      backend.makeTensorInfo(finalOutShape, inputs[0].dtype, outVals);\n\n  inputs2D.forEach(t => backend.disposeIntermediateTensorInfo(t));\n\n  return outInfo;\n}\n\nexport const concatConfig: KernelConfig = {\n  kernelName: Concat,\n  backendName: 'cpu',\n  kernelFunc: concat as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2D, Conv2DAttrs, Conv2DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2D(\n    args: {inputs: Conv2DInputs, backend: MathBackendCPU, attrs: Conv2DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'conv2d');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, dilations, pad,\n      dimRoundingMode, false /* depthwise */, $dataFormat);\n\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const padLeft = convInfo.padInfo.left;\n  const padTop = convInfo.padInfo.top;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const xBatchStride = xStrides[0];\n  const xRowStride = isChannelsLast ? xStrides[1] : xStrides[2];\n  const xColStride = isChannelsLast ? xStrides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : xStrides[1];\n  const yBatchStride = y.strides[0];\n  const yRowStride = isChannelsLast ? y.strides[1] : y.strides[2];\n  const yColStride = isChannelsLast ? y.strides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : y.strides[1];\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xBatchStride;\n    const yOffset1 = b * yBatchStride;\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * yRowStride;\n      const xRCorner = yR * convInfo.strideHeight - padTop;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xRowStride;\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * yColStride;\n          const xCCorner = yC * convInfo.strideWidth - padLeft;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * xColStride;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1 * xChannelStride];\n              for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                yVals[yOffset3 + d2 * yChannelStride] +=\n                    xVal * wVals[wOffset3 + d2];\n              }\n              wOffset3 += convInfo.outChannels;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, yVals);\n}\n\nexport const conv2DConfig: KernelConfig = {\n  kernelName: Conv2D,\n  backendName: 'cpu',\n  kernelFunc: conv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropFilter, Conv2DBackpropFilterAttrs, Conv2DBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropFilter(args: {\n  inputs: Conv2DBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, dataFormat, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv2dBackpropFilter');\n\n  const $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad, dimRoundingMode, false /* depthwise */,\n      $dataFormat);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n  const isChannelsLast = convInfo.dataFormat === 'channelsLast';\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n        for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n          let dotProd = 0;\n          for (let b = 0; b < convInfo.batchSize; ++b) {\n            for (let yR = yRMin; yR < yRMax; ++yR) {\n              const xR = wR + yR * strideHeight - topPad;\n              for (let yC = yCMin; yC < yCMax; ++yC) {\n                const xC = wC + yC * strideWidth - leftPad;\n                if (isChannelsLast) {\n                  dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                      (dyBuf.get(b, yR, yC, d2) as number);\n                } else {\n                  dotProd += (xBuf.get(b, d1, xR, xC) as number) *\n                      (dyBuf.get(b, d2, yR, yC) as number);\n                }\n              }\n            }\n          }\n          dW.set(dotProd, wR, wC, d1, d2);\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const conv2DBackpropFilterConfig: KernelConfig = {\n  kernelName: Conv2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropFilter as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv2DBackpropInput, Conv2DBackpropInputAttrs, Conv2DBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv2DBackpropInput(args: {\n  inputs: Conv2DBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: Conv2DBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {inputShape, strides, pad, dataFormat, dimRoundingMode} = attrs;\n\n  assertNotComplex([dy, filter], 'conv2dBackpropInput');\n\n  const filterStrides = util.computeStrides(filter.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  let $dataFormat = backend_util.convertConv2DDataFormat(dataFormat);\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      1 /* dilations */, pad, dimRoundingMode, false, $dataFormat);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  $dataFormat = convInfo.dataFormat;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  const isChannelsLast = $dataFormat === 'channelsLast';\n  const xBatchStride = dx.strides[0];\n  const xRowStride = isChannelsLast ? dx.strides[1] : dx.strides[2];\n  const xColStride = isChannelsLast ? dx.strides[2] : 1;\n  const xChannelStride = isChannelsLast ? 1 : dx.strides[1];\n  const yBatchStride = dyStrides[0];\n  const yRowStride = isChannelsLast ? dyStrides[1] : dyStrides[2];\n  const yColStride = isChannelsLast ? dyStrides[2] : 1;\n  const yChannelStride = isChannelsLast ? 1 : dyStrides[1];\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset =\n                  yBatchStride * b + yRowStride * yR + yColStride * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let d2 = 0; d2 < outChannels; ++d2) {\n                const pixel = dyValues[dyOffset + yChannelStride * d2];\n                const weight = fltValues[fltOffset + d2];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          const dxOffset = xBatchStride * b + xRowStride * xR +\n              xColStride * xC + xChannelStride * d1;\n          dxValues[dxOffset] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv2DBackpropInputConfig: KernelConfig = {\n  kernelName: Conv2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: conv2DBackpropInput as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3D, Conv3DAttrs, Conv3DInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3D(\n    args: {inputs: Conv3DInputs, backend: MathBackendCPU, attrs: Conv3DAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations} = attrs;\n\n  assertNotComplex([x, filter], 'conv3d');\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number],\n      filter.shape as [number, number, number, number, number], strides,\n      dilations, pad);\n\n  const {\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    dilationDepth,\n    dilationHeight,\n    dilationWidth,\n    padInfo\n  } = convInfo;\n  const padFront = padInfo.front;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yF = 0; yF < convInfo.outDepth; ++yF) {\n      const yOffset2 = yOffset1 + yF * y.strides[1];\n      const xFCorner = yF * convInfo.strideDepth - padFront;\n      for (let wF = 0; wF < filterDepth; ++wF) {\n        const xF = xFCorner + wF * dilationDepth;\n        if (xF < 0 || xF >= convInfo.inDepth) {\n          continue;\n        }\n        const wOffset1 = wF * filterStrides[0];\n        const xOffset2 = xOffset1 + xF * xStrides[1];\n\n        for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n          const yOffset3 = yOffset2 + yR * y.strides[2];\n          const xRCorner = yR * convInfo.strideHeight - padTop;\n          for (let wR = 0; wR < filterHeight; ++wR) {\n            const xR = xRCorner + wR * dilationHeight;\n            if (xR < 0 || xR >= convInfo.inHeight) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wR * filterStrides[1];\n            const xOffset3 = xOffset2 + xR * xStrides[2];\n            for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n              const yOffset4 = yOffset3 + yC * convInfo.outChannels;\n              const xCCorner = yC * convInfo.strideWidth - padLeft;\n              for (let wC = 0; wC < filterWidth; ++wC) {\n                const xC = xCCorner + wC * dilationWidth;\n                if (xC < 0 || xC >= convInfo.inWidth) {\n                  continue;\n                }\n                const wOffset3 = wOffset2 + wC * filterStrides[2];\n                const xOffset4 = xOffset3 + xC * convInfo.inChannels;\n                let wOffset4 = wOffset3;\n                for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n                  const xVal = xVals[xOffset4 + d1];\n                  for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n                    yVals[yOffset4 + d2] += xVal * wVals[wOffset4 + d2];\n                  }\n                  wOffset4 += convInfo.outChannels;\n                }\n              }\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const conv3DConfig: KernelConfig = {\n  kernelName: Conv3D,\n  backendName: 'cpu',\n  kernelFunc: conv3D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropFilterAttrs, Conv3DBackpropFilterInputs, Conv3DBackpropFilterV2, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropFilterV2(args: {\n  inputs: Conv3DBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, pad, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'conv3dBackpropFilterV2');\n\n  const xStrides = util.computeStrides(x.shape);\n  const dyStrides = util.computeStrides(dy.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      x.shape as [number, number, number, number, number], filterShape, strides,\n      1 /* dilations */, pad);\n\n  const strideDepth = convInfo.strideDepth;\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const filterDepth = convInfo.filterDepth;\n  const filterHeight = convInfo.filterHeight;\n  const filterWidth = convInfo.filterWidth;\n\n  const dw = new TensorBuffer(convInfo.filterShape, 'float32');\n  const dwValues = dw.values;\n  const [dwS0, dwS1, dwS2, dwS3] = dw.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const [xS0, xS1, xS2, xS3] = xStrides;\n\n  const frontPad = convInfo.padInfo.front;\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n\n  for (let wF = 0; wF < filterDepth; ++wF) {\n    const yFMin = Math.max(0, Math.ceil((frontPad - wF) / strideDepth));\n    const yFMax = Math.min(\n        convInfo.outDepth, (convInfo.inDepth + frontPad - wF) / strideDepth);\n    const wOffset1 = wF * dwS0;\n\n    for (let wR = 0; wR < filterHeight; ++wR) {\n      const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n      const yRMax = Math.min(\n          convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n      const wOffset2 = wR * dwS1 + wOffset1;\n\n      for (let wC = 0; wC < filterWidth; ++wC) {\n        const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n        const yCMax = Math.min(\n            convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n        const wOffset3 = wC * dwS2 + wOffset2;\n\n        for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n          const wOffset4 = d1 * dwS3 + wOffset3;\n\n          for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n            let dotProd = 0;\n            for (let b = 0; b < convInfo.batchSize; ++b) {\n              const xOffset1 = b * xS0;\n              const yOffset1 = b * dyS0;\n\n              for (let yF = yFMin; yF < yFMax; ++yF) {\n                const xF = wF + yF * strideDepth - frontPad;\n                const xOffset2 = xF * xS1 + xOffset1;\n                const yOffset2 = yF * dyS1 + yOffset1;\n\n                for (let yR = yRMin; yR < yRMax; ++yR) {\n                  const xR = wR + yR * strideHeight - topPad;\n                  const xOffset3 = xR * xS2 + xOffset2;\n                  const yOffset3 = yR * dyS2 + yOffset2;\n\n                  for (let yC = yCMin; yC < yCMax; ++yC) {\n                    const xC = wC + yC * strideWidth - leftPad;\n                    const xOffset4 = xC * xS3 + xOffset3;\n                    const yOffset4 = yC * dyS3 + yOffset3;\n\n                    dotProd += xValues[xOffset4 + d1] * dyValues[yOffset4 + d2];\n                  }\n                }\n              }\n            }\n            dwValues[wOffset4 + d2] = dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dw.shape, dw.dtype, dw.values);\n}\n\nexport const conv3DBackpropFilterV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropFilterV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropFilterV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Conv3DBackpropInputAttrs, Conv3DBackpropInputInputs, Conv3DBackpropInputV2, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function conv3DBackpropInputV2(args: {\n  inputs: Conv3DBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: Conv3DBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {pad, strides, inputShape} = attrs;\n\n  assertNotComplex([dy], 'conv3dBackpropInputV2');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv3DInfo(\n      inputShape, filter.shape as [number, number, number, number, number],\n      strides, 1 /* dilations */, pad);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2, dxS3] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2, dyS3] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2, fltS3] = filterStrides;\n  const {\n    batchSize,\n    filterDepth,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inDepth,\n    inHeight,\n    inWidth,\n    outChannels,\n    outDepth,\n    outHeight,\n    outWidth,\n    strideDepth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const frontPad = filterDepth - 1 - convInfo.padInfo.front;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      // Frames of depth\n      for (let xF = 0; xF < inDepth; ++xF) {\n        const xFCorner = xF - frontPad;\n        const xFMin = Math.max(0, Math.ceil(xFCorner / strideDepth));\n        const yFMax =\n            Math.min(outDepth, (filterDepth + xFCorner) / strideDepth);\n\n        // Rows as per standard 2d matrix notation\n        for (let xR = 0; xR < inHeight; ++xR) {\n          const xRCorner = xR - topPad;\n          const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n          const yRMax =\n              Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n          // Columns as per standard 2d matrix notation\n          for (let xC = 0; xC < inWidth; ++xC) {\n            const xCCorner = xC - leftPad;\n            const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n            const yCMax =\n                Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n            let dotProd = 0;\n            for (let yF = xFMin; yF < yFMax; ++yF) {\n              const wF = yF * strideDepth - xFCorner;\n\n              for (let yR = xRMin; yR < yRMax; ++yR) {\n                const wR = yR * strideHeight - xRCorner;\n\n                for (let yC = xCMin; yC < yCMax; ++yC) {\n                  const wC = yC * strideWidth - xCCorner;\n                  const dyOffset = dyS0 * b + dyS1 * yF + dyS2 * yR + dyS3 * yC;\n                  const fltOffset = fltS0 * (filterDepth - 1 - wF) +\n                      fltS1 * (filterHeight - 1 - wR) +\n                      fltS2 * (filterWidth - 1 - wC) + fltS3 * d1;\n\n                  for (let d2 = 0; d2 < outChannels; ++d2) {\n                    const pixel = dyValues[dyOffset + d2];\n                    const weight = fltValues[fltOffset + d2];\n                    dotProd += pixel * weight;\n                  }\n                }\n              }\n            }\n            dxValues[dxS0 * b + dxS1 * xF + dxS2 * xR + dxS3 * xC + d1] =\n                dotProd;\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const conv3DBackpropInputV2Config: KernelConfig = {\n  kernelName: Conv3DBackpropInputV2,\n  backendName: 'cpu',\n  kernelFunc: conv3DBackpropInputV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cos, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cos = unaryKernelFunc(Cos, (xi) => Math.cos(xi));\n\nexport const cosConfig: KernelConfig = {\n  kernelName: Cos,\n  backendName: 'cpu',\n  kernelFunc: cos,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Cosh, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const cosh = unaryKernelFunc(Cosh, (xi) => Math.cosh(xi));\n\nexport const coshConfig: KernelConfig = {\n  kernelName: Cosh,\n  backendName: 'cpu',\n  kernelFunc: cosh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNative, DepthwiseConv2dNativeAttrs, DepthwiseConv2dNativeInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNative(args: {\n  inputs: DepthwiseConv2dNativeInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter} = inputs;\n  const {strides, pad, dilations, dimRoundingMode} = attrs;\n\n  assertNotComplex([x, filter], 'depthwiseConv2DNative');\n\n  const xStrides = util.computeStrides(x.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  let $dilations = dilations;\n  if ($dilations == null) {\n    $dilations = [1, 1];\n  }\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, $dilations),\n      () => 'Error in depthwiseConv2d: Either strides or dilations must be ' +\n          `1. Got strides ${strides} and dilations '${$dilations}'`);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number],\n      filter.shape as [number, number, number, number], strides, $dilations,\n      pad, dimRoundingMode, true /* depthwise */);\n\n  const {filterHeight, filterWidth, dilationHeight, dilationWidth, padInfo} =\n      convInfo;\n  const padLeft = padInfo.left;\n  const padTop = padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n  const y = new TensorBuffer(convInfo.outShape, x.dtype as 'float32');\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const wVals = backend.data.get(filter.dataId).values as TypedArray;\n  const yVals = y.values;\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    const xOffset1 = b * xStrides[0];\n    const yOffset1 = b * y.strides[0];\n    for (let yR = 0; yR < convInfo.outHeight; ++yR) {\n      const yOffset2 = yOffset1 + yR * y.strides[1];\n      const xRCorner = yR * convInfo.strideHeight - padLeft;\n      for (let wR = 0; wR < filterHeight; ++wR) {\n        const xR = xRCorner + wR * dilationHeight;\n        if (xR < 0 || xR >= convInfo.inHeight) {\n          continue;\n        }\n        const wOffset1 = wR * filterStrides[0];\n        const xOffset2 = xOffset1 + xR * xStrides[1];\n        for (let yC = 0; yC < convInfo.outWidth; ++yC) {\n          const yOffset3 = yOffset2 + yC * y.strides[2];\n          const xCCorner = yC * convInfo.strideWidth - padTop;\n          for (let wC = 0; wC < filterWidth; ++wC) {\n            const xC = xCCorner + wC * dilationWidth;\n            if (xC < 0 || xC >= convInfo.inWidth) {\n              continue;\n            }\n            const wOffset2 = wOffset1 + wC * filterStrides[1];\n            const xOffset3 = xOffset2 + xC * convInfo.inChannels;\n            let yOffset4 = yOffset3;\n            let wOffset3 = wOffset2;\n            for (let d1 = 0; d1 < convInfo.inChannels; ++d1) {\n              const xVal = xVals[xOffset3 + d1];\n              for (let q = 0; q < chMul; ++q) {\n                yVals[yOffset4 + q] += xVal * wVals[wOffset3 + q];\n              }\n              yOffset4 += chMul;\n              wOffset3 += chMul;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(y.shape, y.dtype, y.values);\n}\n\nexport const depthwiseConv2dNativeConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNative,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNative as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropFilter, DepthwiseConv2dNativeBackpropFilterAttrs, DepthwiseConv2dNativeBackpropFilterInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropFilter(args: {\n  inputs: DepthwiseConv2dNativeBackpropFilterInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropFilterAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, dy} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, filterShape} = attrs;\n\n  assertNotComplex([x, dy], 'depthwiseConv2dNativeBackpropFilter');\n\n  const convInfo = backend_util.computeConv2DInfo(\n      x.shape as [number, number, number, number], filterShape, strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const {strideHeight, strideWidth, filterHeight, filterWidth} = convInfo;\n\n  const dW = new TensorBuffer(convInfo.filterShape, 'float32');\n\n  const leftPad = convInfo.padInfo.left;\n  const topPad = convInfo.padInfo.top;\n  const chMul = convInfo.outChannels / convInfo.inChannels;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xBuf = new TensorBuffer(x.shape, x.dtype, xVals);\n  const dyVals = backend.data.get(dy.dataId).values as TypedArray;\n  const dyBuf = new TensorBuffer(dy.shape, dy.dtype, dyVals);\n  for (let wR = 0; wR < filterHeight; ++wR) {\n    const yRMin = Math.max(0, Math.ceil((topPad - wR) / strideHeight));\n    const yRMax = Math.min(\n        convInfo.outHeight, (convInfo.inHeight + topPad - wR) / strideHeight);\n\n    for (let wC = 0; wC < filterWidth; ++wC) {\n      const yCMin = Math.max(0, Math.ceil((leftPad - wC) / strideWidth));\n      const yCMax = Math.min(\n          convInfo.outWidth, (convInfo.inWidth + leftPad - wC) / strideWidth);\n\n      for (let d2 = 0; d2 < convInfo.outChannels; ++d2) {\n        const d1 = Math.trunc(d2 / chMul);\n        const dm = d2 % chMul;\n\n        let dotProd = 0;\n        for (let b = 0; b < convInfo.batchSize; ++b) {\n          for (let yR = yRMin; yR < yRMax; ++yR) {\n            const xR = wR + yR * strideHeight - topPad;\n            for (let yC = yCMin; yC < yCMax; ++yC) {\n              const xC = wC + yC * strideWidth - leftPad;\n              dotProd += (xBuf.get(b, xR, xC, d1) as number) *\n                  (dyBuf.get(b, yR, yC, d2) as number);\n            }\n          }\n        }\n        dW.set(dotProd, wR, wC, d1, dm);\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dW.shape, dW.dtype, dW.values);\n}\n\nexport const depthwiseConv2dNativeBackpropFilterConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropFilter as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, DepthwiseConv2dNativeBackpropInput, DepthwiseConv2dNativeBackpropInputAttrs, DepthwiseConv2dNativeBackpropInputInputs, KernelConfig, KernelFunc, TensorBuffer, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function depthwiseConv2dNativeBackpropInput(args: {\n  inputs: DepthwiseConv2dNativeBackpropInputInputs,\n  backend: MathBackendCPU,\n  attrs: DepthwiseConv2dNativeBackpropInputAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, filter} = inputs;\n  const {strides, dilations, pad, dimRoundingMode, inputShape} = attrs;\n\n  assertNotComplex([dy, filter], 'depthwiseConv2DNativeBackpropInput');\n\n  const dyStrides = util.computeStrides(dy.shape);\n  const filterStrides = util.computeStrides(filter.shape);\n\n  const convInfo = backend_util.computeConv2DInfo(\n      inputShape, filter.shape as [number, number, number, number], strides,\n      dilations, pad, dimRoundingMode, true /* depthwise */);\n\n  const dx = new TensorBuffer(convInfo.inShape, 'float32');\n  const dxValues = dx.values;\n  const [dxS0, dxS1, dxS2] = dx.strides;\n  const dyValues = backend.data.get(dy.dataId).values as TypedArray;\n  const [dyS0, dyS1, dyS2] = dyStrides;\n  const fltValues = backend.data.get(filter.dataId).values as TypedArray;\n  const [fltS0, fltS1, fltS2] = filterStrides;\n  const {\n    batchSize,\n    filterHeight,\n    filterWidth,\n    inChannels,\n    inHeight,\n    inWidth,\n    outChannels,\n    outHeight,\n    outWidth,\n    strideHeight,\n    strideWidth\n  } = convInfo;\n  const topPad = filterHeight - 1 - convInfo.padInfo.top;\n  const leftPad = filterWidth - 1 - convInfo.padInfo.left;\n  const chMul = outChannels / inChannels;\n\n  for (let b = 0; b < batchSize; ++b) {\n    for (let d1 = 0; d1 < inChannels; ++d1) {\n      for (let xR = 0; xR < inHeight; ++xR) {\n        const xRCorner = xR - topPad;\n        const xRMin = Math.max(0, Math.ceil(xRCorner / strideHeight));\n        const yRMax =\n            Math.min(outHeight, (filterHeight + xRCorner) / strideHeight);\n\n        for (let xC = 0; xC < inWidth; ++xC) {\n          const xCCorner = xC - leftPad;\n          const xCMin = Math.max(0, Math.ceil(xCCorner / strideWidth));\n          const yCMax =\n              Math.min(outWidth, (filterWidth + xCCorner) / strideWidth);\n\n          let dotProd = 0;\n          for (let yR = xRMin; yR < yRMax; ++yR) {\n            const wR = yR * strideHeight - xRCorner;\n\n            for (let yC = xCMin; yC < yCMax; ++yC) {\n              const wC = yC * strideWidth - xCCorner;\n              const dyOffset = dyS0 * b + dyS1 * yR + dyS2 * yC;\n              const fltOffset = fltS0 * (filterHeight - 1 - wR) +\n                  fltS1 * (filterWidth - 1 - wC) + fltS2 * d1;\n\n              for (let dm = 0; dm < chMul; ++dm) {\n                const d2 = d1 * chMul + dm;\n                const pixel = dyValues[dyOffset + d2];\n                const weight = fltValues[fltOffset + dm];\n                dotProd += pixel * weight;\n              }\n            }\n          }\n          dxValues[dxS0 * b + dxS1 * xR + dxS2 * xC + d1] = dotProd;\n        }\n      }\n    }\n  }\n\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const depthwiseConv2dNativeBackpropInputConfig: KernelConfig = {\n  kernelName: DepthwiseConv2dNativeBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: depthwiseConv2dNativeBackpropInput as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2D, Dilation2DAttrs, Dilation2DInputs, KernelConfig, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dConfig: KernelConfig = {\n  kernelName: Dilation2D,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter} = inputs as Dilation2DInputs;\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const xRank = x.shape.length;\n\n    const filterVals = cpuBackend.data.get(filter.dataId).values as TypedArray;\n    const filterRank = filter.shape.length;\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    const outSize = util.sizeFromShape(outShape);\n    const outRank = outShape.length;\n    const outputVals = util.getArrayFromDType(x.dtype, outSize);\n\n    // Upsampling the input by fill in `dilation size - 1` values between each\n    // input value.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const xIndex = util.locToIndex(\n                        [b, hIn, wIn, d], xRank, util.computeStrides(x.shape));\n                    const filterIndex = util.locToIndex(\n                        [h, w, d], filterRank,\n                        util.computeStrides(filter.shape));\n                    const val = xVals[xIndex] + filterVals[filterIndex];\n                    if (val > curVal) {\n                      curVal = val;\n                    }\n                  }\n                }\n              }\n            }\n            const outputIndex = util.locToIndex(\n                [b, hOut, wOut, d], outRank, util.computeStrides(outShape));\n            outputVals[outputIndex] = curVal;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(outputVals, x.dtype), outShape, x.dtype);\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropFilter, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropFilterConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropFilter,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropFilter}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed filter gradients has the same dimensions as the filter:\n    // [filterHeight, filterWidth, depth]\n    const gradients = util.makeZerosNestedTypedArray(\n                          filter.shape, filter.dtype) as number[][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hMax = 0;\n            let wMax = 0;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hMax = h;\n                      wMax = w;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[hMax][wMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), filter.shape, filter.dtype);\n\n    return {dataId, shape: filter.shape, dtype: filter.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Dilation2DAttrs, Dilation2DBackpropInput, Tensor3D, Tensor4D, TypedArray, util} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const dilation2dBackpropInputConfig: KernelConfig = {\n  kernelName: Dilation2DBackpropInput,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {x, filter, dy} =\n        inputs as {x: Tensor4D, filter: Tensor3D, dy: Tensor4D};\n    const {strides, pad, dilations} = attrs as {} as Dilation2DAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const $x =\n        util.toNestedArray(\n            x.shape, cpuBackend.data.get(x.dataId).values as TypedArray) as\n        number[][][][];\n\n    const $filter = util.toNestedArray(\n                        filter.shape,\n                        cpuBackend.data.get(filter.dataId).values as\n                            TypedArray) as number[][][];\n\n    const {\n      batchSize,\n      inHeight,\n      inWidth,\n      inChannels,\n      outHeight,\n      outWidth,\n      padInfo,\n      strideHeight,\n      strideWidth,\n      filterHeight,\n      filterWidth,\n      dilationHeight,\n      dilationWidth,\n      outShape\n    } =\n        backend_util.computeDilation2DInfo(\n            x.shape as [number, number, number, number],\n            filter.shape as [number, number, number], strides, pad,\n            'NHWC' /* dataFormat */, dilations);\n\n    util.assert(\n        dy.rank === outShape.length,\n        () => `Error in ${Dilation2DBackpropInput}, dy ` +\n            `must have the same rank as output ${outShape.length}, but got ` +\n            `${dy.rank}`);\n\n    const $dy =\n        util.toNestedArray(\n            outShape, cpuBackend.data.get(dy.dataId).values as TypedArray) as\n        number[][][][];\n\n    // The computed gradients has the same dimensions as the input:\n    // [batch, inputHeight, inputCols, inChannel]\n    const gradients =\n        util.makeZerosNestedTypedArray(x.shape, x.dtype) as number[][][][];\n\n    // In the case of multiple argmax branches, we only back-propagate along the\n    // last branch, i.e., the one with largest value of `h * filter_cols + w`,\n    // similarly to the max-pooling backward routines.\n    // This implementation follows the TF c++ implementation:\n    // https://github.com/tensorflow/tensorflow/blob/d9a3a849edc198e90172bc58eb293de457f9d986/tensorflow/core/kernels/dilation_ops.cc\n    for (let b = 0; b < batchSize; ++b) {\n      for (let hOut = 0; hOut < outHeight; ++hOut) {\n        const hBeg = hOut * strideHeight - padInfo.top;\n        for (let wOut = 0; wOut < outWidth; ++wOut) {\n          const wBeg = wOut * strideWidth - padInfo.left;\n          for (let d = 0; d < inChannels; ++d) {\n            let curVal = Number.MIN_SAFE_INTEGER;\n            let hInMax = (hBeg < 0) ? 0 : hBeg;\n            let wInMax = (wBeg < 0) ? 0 : wBeg;\n            for (let h = 0; h < filterHeight; ++h) {\n              const hIn = hBeg + h * dilationHeight;\n              if (hIn >= 0 && hIn < inHeight) {\n                for (let w = 0; w < filterWidth; ++w) {\n                  const wIn = wBeg + w * dilationWidth;\n                  if (wIn >= 0 && wIn < inWidth) {\n                    const val = $x[b][hIn][wIn][d] + $filter[h][w][d];\n                    if (val > curVal) {\n                      curVal = val;\n                      hInMax = hIn;\n                      wInMax = wIn;\n                    }\n                  }\n                }\n              }\n            }\n            gradients[b][hInMax][wInMax][d] += $dy[b][hOut][wOut][d];\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(\n        util.toTypedArray(gradients, x.dtype), x.shape, x.dtype);\n\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Div, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {createSimpleBinaryKernelImpl} from '../utils/binary_impl';\nimport {binaryKernelFunc} from '../utils/kernel_utils';\n\nexport const divImpl =\n    createSimpleBinaryKernelImpl((a: number, b: number) => a / b);\nexport const div = binaryKernelFunc(Div, divImpl);\n\nexport const divConfig: KernelConfig = {\n  kernelName: Div,\n  backendName: 'cpu',\n  kernelFunc: div\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Erf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst p = backend_util.ERF_P;\nconst a1 = backend_util.ERF_A1;\nconst a2 = backend_util.ERF_A2;\nconst a3 = backend_util.ERF_A3;\nconst a4 = backend_util.ERF_A4;\nconst a5 = backend_util.ERF_A5;\n\nexport const erf = unaryKernelFunc(\n    Erf,\n    (xi) => {\n      const sign = Math.sign(xi);\n      const v = Math.abs(xi);\n      const t = 1.0 / (1.0 + p * v);\n      return sign *\n          (1.0 -\n           (((((a5 * t + a4) * t) + a3) * t + a2) * t + a1) * t *\n               Math.exp(-v * v));\n    },\n);\n\nexport const erfConfig: KernelConfig = {\n  kernelName: Erf,\n  backendName: 'cpu',\n  kernelFunc: erf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, Tensor, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {add} from '../kernels/Add';\nimport {complex} from '../kernels/Complex';\nimport {concat} from '../kernels/Concat';\nimport {divConfig} from '../kernels/Div';\nimport {identity} from '../kernels/Identity';\nimport {imag} from '../kernels/Imag';\nimport {multiply} from '../kernels/Multiply';\nimport {real} from '../kernels/Real';\nimport {slice} from '../kernels/Slice';\nimport {sub} from '../kernels/Sub';\n\n/**\n * Calculate FFT of inner most elements of batch tensor.\n */\nexport function fftBatch(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): TensorInfo {\n  const inputShape = input.shape;\n  const batch = inputShape[0];\n  const innerDim = inputShape[1];\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const real2D = inputVals.complexTensorInfos.real;\n  const imag2D = inputVals.complexTensorInfos.imag;\n\n  // Collects real and imaginary values separately.\n  const resultShape = [batch, innerDim];\n  const resultSize = util.sizeFromShape(resultShape);\n  const resultReal = util.getTypedArrayFromDType('float32', resultSize);\n  const resultImag = util.getTypedArrayFromDType('float32', resultSize);\n\n  for (let b = 0; b < batch; b++) {\n    // TODO: Support slice ops for complex type.\n    const r = slice({\n      inputs: {x: real2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n    const i = slice({\n      inputs: {x: imag2D},\n      backend: cpuBackend,\n      attrs: {begin: [b, 0], size: [1, innerDim]}\n    });\n\n    const input = complex({inputs: {real: r, imag: i}, backend: cpuBackend});\n\n    // Run FFT by batch element.\n    const {real, imag} = fftImpl(input, inverse, cpuBackend);\n    const res = backend_util.mergeRealAndImagArrays(real, imag);\n\n    for (let d = 0; d < innerDim; d++) {\n      const c = backend_util.getComplexWithIndex(res, d);\n      resultReal[b * innerDim + d] = c.real;\n      resultImag[b * innerDim + d] = c.imag;\n    }\n\n    cpuBackend.disposeIntermediateTensorInfo(r);\n    cpuBackend.disposeIntermediateTensorInfo(i);\n    cpuBackend.disposeIntermediateTensorInfo(input);\n  }\n\n  const $realInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultReal);\n  const $imagInfo: TensorInfo =\n      cpuBackend.makeTensorInfo(resultShape, 'float32', resultImag);\n\n  const result = complex(\n      {inputs: {real: $realInfo, imag: $imagInfo}, backend: cpuBackend});\n\n  cpuBackend.disposeIntermediateTensorInfo($realInfo);\n  cpuBackend.disposeIntermediateTensorInfo($imagInfo);\n\n  return result;\n}\n\nexport function fftImpl(\n    input: TensorInfo, inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  const inputSize = util.sizeFromShape(input.shape);\n\n  const inputVals = cpuBackend.data.get(input.dataId);\n\n  const realVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.real.dataId).values as\n      Float32Array;\n\n  const imagVals =\n      cpuBackend.data.get(inputVals.complexTensorInfos.imag.dataId).values as\n      Float32Array;\n\n  if (isExponentOf2(inputSize)) {\n    const result =\n        fftRadix2(realVals, imagVals, inputSize, inverse, cpuBackend);\n\n    const resultShape = [input.shape[0], input.shape[1]];\n\n    if (inverse) {\n      const realInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.real);\n      const imagInfo: TensorInfo =\n          cpuBackend.makeTensorInfo(resultShape, 'float32', result.imag);\n\n      const sizeInfo: TensorInfo = cpuBackend.makeTensorInfo(\n          [], 'float32',\n          util.createScalarValue(inputSize as {} as 'float32', 'float32'));\n      const sizeInfoCopy =\n          identity({inputs: {x: sizeInfo}, backend: cpuBackend});\n\n      const divRealInfo =\n          divConfig.kernelFunc(\n              {inputs: {a: realInfo, b: sizeInfo}, backend: cpuBackend}) as\n          TensorInfo;\n      const divImagInfo =\n          divConfig.kernelFunc(\n              {inputs: {a: imagInfo, b: sizeInfoCopy}, backend: cpuBackend}) as\n          TensorInfo;\n\n      const divRealVals =\n          cpuBackend.data.get(divRealInfo.dataId).values as Float32Array;\n      const divImagVals =\n          cpuBackend.data.get(divImagInfo.dataId).values as Float32Array;\n\n      cpuBackend.disposeIntermediateTensorInfo(realInfo);\n      cpuBackend.disposeIntermediateTensorInfo(imagInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfo);\n      cpuBackend.disposeIntermediateTensorInfo(sizeInfoCopy);\n      cpuBackend.disposeIntermediateTensorInfo(divRealInfo);\n      cpuBackend.disposeIntermediateTensorInfo(divImagInfo);\n\n      return {real: divRealVals, imag: divImagVals};\n    }\n\n    return result;\n  } else {\n    const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n    const rawOutput =\n        fourierTransformByMatmul(data, inputSize, inverse) as Float32Array;\n\n    return backend_util.splitRealAndImagArrays(rawOutput);\n  }\n}\n\nfunction isExponentOf2(size: number): boolean {\n  return (size & size - 1) === 0;\n}\n\n// FFT using Cooley-Tukey algorithm on radix 2 dimensional input.\nfunction fftRadix2(\n    realVals: Float32Array, imagVals: Float32Array, size: number,\n    inverse: boolean,\n    cpuBackend: MathBackendCPU): {real: Float32Array, imag: Float32Array} {\n  if (size === 1) {\n    return {real: realVals, imag: imagVals};\n  }\n\n  const data = backend_util.mergeRealAndImagArrays(realVals, imagVals);\n\n  const half = size / 2;\n\n  const evenComplex = backend_util.complexWithEvenIndex(data);\n\n  const evenRealVals = evenComplex.real;\n  const evenImagVals = evenComplex.imag;\n\n  const evenShape = [evenRealVals.length];\n\n  const evenRealInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenRealVals);\n  const evenImagInfo =\n      cpuBackend.makeTensorInfo(evenShape, 'float32', evenImagVals);\n\n  const evenTensorInfo = complex(\n      {inputs: {real: evenRealInfo, imag: evenImagInfo}, backend: cpuBackend});\n\n  const oddComplex = backend_util.complexWithOddIndex(data);\n\n  const oddRealVals = oddComplex.real;\n  const oddImagVals = oddComplex.imag;\n\n  const oddShape = [oddRealVals.length];\n\n  const oddRealInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddRealVals);\n  const oddImagInfo =\n      cpuBackend.makeTensorInfo(oddShape, 'float32', oddImagVals);\n\n  const oddTensorInfo = complex(\n      {inputs: {real: oddRealInfo, imag: oddImagInfo}, backend: cpuBackend});\n\n  // Recursive call for half part of original input.\n  const $evenComplex =\n      fftRadix2(evenRealVals, evenImagVals, half, inverse, cpuBackend);\n\n  const $evenRealVals = $evenComplex.real;\n  const $evenImagVals = $evenComplex.imag;\n\n  const $evenShape = [$evenRealVals.length];\n\n  const $evenRealInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenRealVals);\n  const $evenImagInfo =\n      cpuBackend.makeTensorInfo($evenShape, 'float32', $evenImagVals);\n\n  const $evenTensorInfo = complex({\n    inputs: {real: $evenRealInfo, imag: $evenImagInfo},\n    backend: cpuBackend\n  });\n\n  const $oddComplex =\n      fftRadix2(oddRealVals, oddImagVals, half, inverse, cpuBackend);\n\n  const $oddRealVals = $oddComplex.real;\n  const $oddImagVals = $oddComplex.imag;\n\n  const $oddShape = [$oddRealVals.length];\n\n  const $oddRealInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddRealVals);\n  const $oddImagInfo =\n      cpuBackend.makeTensorInfo($oddShape, 'float32', $oddImagVals);\n\n  const $oddTensorInfo = complex(\n      {inputs: {real: $oddRealInfo, imag: $oddImagInfo}, backend: cpuBackend});\n\n  const e = backend_util.exponents(size, inverse);\n  const eShape = [e.real.length];\n\n  const eRealInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.real);\n  const eImagInfo = cpuBackend.makeTensorInfo(eShape, 'float32', e.imag);\n\n  const complexInfo = complex(\n      {inputs: {real: eRealInfo, imag: eImagInfo}, backend: cpuBackend});\n\n  const exponentInfo =\n      multiply(\n          {inputs: {a: complexInfo, b: $oddTensorInfo}, backend: cpuBackend}) as\n      TensorInfo;\n\n  const addPart = add({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n  const subPart = sub({\n                    inputs: {a: $evenTensorInfo, b: exponentInfo},\n                    backend: cpuBackend\n                  }) as TensorInfo;\n\n  const addPartReal = real({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartReal = real({inputs: {input: subPart}, backend: cpuBackend});\n\n  const addPartImag = imag({inputs: {input: addPart}, backend: cpuBackend});\n  const subPartImag = imag({inputs: {input: subPart}, backend: cpuBackend});\n\n  const $real = concat({\n    inputs: [addPartReal as Tensor, subPartReal as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n  const $imag = concat({\n    inputs: [addPartImag as Tensor, subPartImag as Tensor],\n    backend: cpuBackend,\n    attrs: {axis: 0}\n  });\n\n  const $realVals = cpuBackend.data.get($real.dataId).values as Float32Array;\n  const $imagVals = cpuBackend.data.get($imag.dataId).values as Float32Array;\n\n  cpuBackend.disposeIntermediateTensorInfo(evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($evenTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo($oddTensorInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eRealInfo);\n  cpuBackend.disposeIntermediateTensorInfo(eImagInfo);\n  cpuBackend.disposeIntermediateTensorInfo(complexInfo);\n  cpuBackend.disposeIntermediateTensorInfo(exponentInfo);\n  cpuBackend.disposeIntermediateTensorInfo(addPart);\n  cpuBackend.disposeIntermediateTensorInfo(subPart);\n  cpuBackend.disposeIntermediateTensorInfo(addPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(addPartImag);\n  cpuBackend.disposeIntermediateTensorInfo(subPartReal);\n  cpuBackend.disposeIntermediateTensorInfo(subPartImag);\n  cpuBackend.disposeIntermediateTensorInfo($real);\n  cpuBackend.disposeIntermediateTensorInfo($imag);\n\n  return {real: $realVals, imag: $imagVals};\n}\n\n// Calculate fourier transform by multplying sinusoid matrix.\nfunction fourierTransformByMatmul(\n    data: TypedArray, size: number, inverse: boolean): TypedArray {\n  const ret = new Float32Array(size * 2);\n  // TODO: Use matmul instead once it supports complex64 type.\n  for (let r = 0; r < size; r++) {\n    let real = 0.0;\n    let imag = 0.0;\n    for (let c = 0; c < size; c++) {\n      const e = backend_util.exponent(r * c, size, inverse);\n      const term = backend_util.getComplexWithIndex(data as Float32Array, c);\n      real += term.real * e.real - term.imag * e.imag;\n      imag += term.real * e.imag + term.imag * e.real;\n    }\n    if (inverse) {\n      real /= size;\n      imag /= size;\n    }\n    backend_util.assignToTypedArray(ret, real, imag, r);\n  }\n  return ret;\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FFT, FFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function fft(args: {inputs: FFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, false, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const fftConfig: KernelConfig = {\n  kernelName: FFT,\n  backendName: 'cpu',\n  kernelFunc: fft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {DataType, DataValues, Fill, FillAttrs, KernelConfig, KernelFunc, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport function fill(args: {backend: MathBackendCPU, attrs: FillAttrs}):\n    TensorInfo {\n  const {backend, attrs} = args;\n  const {shape, value, dtype} = attrs;\n\n  const $dtype = dtype || util.inferDtype(value);\n  const values = util.getArrayFromDType($dtype, util.sizeFromShape(shape));\n  fillValues(values, value, $dtype);\n\n  return backend.makeTensorInfo(shape, $dtype, values);\n}\n\nexport const fillConfig: KernelConfig = {\n  kernelName: Fill,\n  backendName: 'cpu',\n  kernelFunc: fill as {} as KernelFunc\n};\n\nfunction fillValues(\n    values: DataValues, value: string|number, dtype: DataType): void {\n  if (dtype === 'string') {\n    (values as string[]).fill(value as string);\n  } else {\n    (values as TypedArray).fill(value as number);\n  }\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {FlipLeftRight, FlipLeftRightInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const flipLeftRightConfig: KernelConfig = {\n  kernelName: FlipLeftRight,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as FlipLeftRightInputs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n\n            const coordX = Math.round(imageWidth - x);\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n\n            let outputValue = imageVals[outIdx];\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth) {\n              // set the output to the image value at the coordinate position.\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n            output[outIdx] = outputValue;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedConv2D, FusedConv2DAttrs, FusedConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {conv2D} from './Conv2D';\n\nexport function fusedConv2D(args: {\n  inputs: FusedConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode, activation} =\n      attrs;\n\n  let result = conv2D({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const resultOld = result;\n    result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  if (activation) {\n    const resultOld = result;\n    result =\n        applyActivation(backend, result, activation, preluActivationWeights);\n    backend.disposeIntermediateTensorInfo(resultOld);\n  }\n\n  return result;\n}\n\nexport const fusedConv2DConfig: KernelConfig = {\n  kernelName: FusedConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedConv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {FusedDepthwiseConv2D, FusedDepthwiseConv2DAttrs, FusedDepthwiseConv2DInputs, KernelConfig, KernelFunc, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {applyActivation} from '../utils/fused_utils';\nimport {add} from './Add';\nimport {depthwiseConv2dNative} from './DepthwiseConv2dNative';\n\nexport function fusedDepthwiseConv2D(args: {\n  inputs: FusedDepthwiseConv2DInputs,\n  backend: MathBackendCPU,\n  attrs: FusedDepthwiseConv2DAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, filter, bias, preluActivationWeights} = inputs;\n  const {strides, pad, dataFormat, dilations, dimRoundingMode, activation} =\n      attrs;\n\n  let result = depthwiseConv2dNative({\n    inputs: {x, filter},\n    backend,\n    attrs: {strides, pad, dataFormat, dilations, dimRoundingMode}\n  });\n\n  if (bias) {\n    const oldResult = result;\n    result = add({inputs: {a: result, b: bias}, backend}) as TensorInfo;\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n  if (activation) {\n    const oldResult = result;\n    result =\n        applyActivation(backend, result, activation, preluActivationWeights);\n    backend.disposeIntermediateTensorInfo(oldResult);\n  }\n\n  return result;\n}\n\nexport const fusedDepthwiseConv2DConfig: KernelConfig = {\n  kernelName: FusedDepthwiseConv2D,\n  backendName: 'cpu',\n  kernelFunc: fusedDepthwiseConv2D as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IFFT, IFFTInputs, KernelConfig, KernelFunc, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {fftBatch} from '../utils/fft_utils';\nimport {reshape} from './Reshape';\n\nexport function ifft(args: {inputs: IFFTInputs, backend: MathBackendCPU}):\n    TensorInfo {\n  const {inputs, backend} = args;\n  const {input} = inputs;\n\n  const inputSize = util.sizeFromShape(input.shape);\n\n  // Collapse all outer dimensions to a single batch dimension.\n  const innerDimensionSize = input.shape[input.shape.length - 1];\n  const batch = inputSize / innerDimensionSize;\n\n  const input2D = reshape({\n    inputs: {x: input},\n    backend,\n    attrs: {shape: [batch, innerDimensionSize]}\n  });\n\n  const result = fftBatch(input2D, true, backend);\n\n  const resultReshaped =\n      reshape({inputs: {x: result}, backend, attrs: {shape: input.shape}});\n\n  backend.disposeIntermediateTensorInfo(input2D);\n  backend.disposeIntermediateTensorInfo(result);\n\n  return resultReshaped;\n}\n\nexport const ifftConfig: KernelConfig = {\n  kernelName: IFFT,\n  backendName: 'cpu',\n  kernelFunc: ifft as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsFinite, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isFinite =\n    unaryKernelFunc(IsFinite, (xi) => Number.isFinite(xi) ? 1 : 0, 'bool');\n\nexport const isFiniteConfig: KernelConfig = {\n  kernelName: IsFinite,\n  backendName: 'cpu',\n  kernelFunc: isFinite,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsInf, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isInf =\n    unaryKernelFunc(IsInf, (xi) => Math.abs(xi) === Infinity ? 1 : 0, 'bool');\n\nexport const isInfConfig: KernelConfig = {\n  kernelName: IsInf,\n  backendName: 'cpu',\n  kernelFunc: isInf,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {IsNan, KernelConfig} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const isNaN =\n    unaryKernelFunc(IsNan, (xi) => Number.isNaN(xi) ? 1 : 0, 'bool');\n\nexport const isNaNConfig: KernelConfig = {\n  kernelName: IsNan,\n  backendName: 'cpu',\n  kernelFunc: isNaN,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Log1p} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const log1p = unaryKernelFunc(Log1p, (xi) => Math.log1p(xi));\n\nexport const log1pConfig: KernelConfig = {\n  kernelName: Log1p,\n  backendName: 'cpu',\n  kernelFunc: log1p,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, LogicalNot} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const logicalNot =\n    unaryKernelFunc(LogicalNot, (xi) => xi ? 0 : 1, 'bool');\n\nexport const logicalNotConfig: KernelConfig = {\n  kernelName: LogicalNot,\n  backendName: 'cpu',\n  kernelFunc: logicalNot,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Max, MaxAttrs, MaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig} from '@tensorflow/tfjs-core';\nimport {TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxImpl} from './Max_impl';\nimport {transposeImpl} from './Transpose_impl';\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxInputs;\n    const {reductionIndices, keepDims} = attrs as {} as MaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    let xShape = x.shape;\n    const xRank = xShape.length;\n\n    const origAxes = util.parseAxisParam(reductionIndices, xShape);\n    let axes = origAxes;\n    const permutedAxes = backend_util.getAxesPermutation(axes, xRank);\n    let xVals = cpuBackend.data.get(x.dataId).values as TypedArray;\n    if (permutedAxes != null) {\n      const newShape: number[] = new Array(xRank);\n      for (let i = 0; i < newShape.length; i++) {\n        newShape[i] = xShape[permutedAxes[i]];\n      }\n\n      xVals = transposeImpl(xVals, xShape, x.dtype, permutedAxes, newShape);\n      axes = backend_util.getInnerMostAxes(axes.length, xRank);\n\n      xShape = newShape;\n    }\n\n    assertNotComplex(x, 'max');\n    backend_util.assertAxesAreInnerMostDims('max', axes, xRank);\n    const [maxOutShape, reduceShape] =\n        backend_util.computeOutAndReduceShapes(xShape, axes);\n\n    const reduceSize = util.sizeFromShape(reduceShape);\n\n    const result = maxImpl(xVals, reduceSize, maxOutShape, x.dtype);\n    const dataId = cpuBackend.write(result, maxOutShape, x.dtype);\n\n    let outShape = maxOutShape;\n    if (keepDims) {\n      // reshape\n      const newShape = backend_util.expandShapeToKeepDim(maxOutShape, origAxes);\n      outShape = newShape;\n    }\n\n    return {dataId, shape: outShape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, KernelConfig, KernelFunc, MaxPool, MaxPoolAttrs, MaxPoolInputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {pool} from '../utils/pool_utils';\nimport {identity} from './Identity';\n\nexport function maxPool(\n    args:\n        {inputs: MaxPoolInputs, backend: MathBackendCPU, attrs: MaxPoolAttrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  assertNotComplex(x, 'maxPool');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n  const dilations = 1;\n\n  util.assert(\n      backend_util.eitherStridesOrDilationsAreOne(strides, dilations),\n      () => 'Error in maxPool: Either strides or dilations must be 1. ' +\n          `Got strides ${strides} and dilations '${dilations}'`);\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      dilations, pad, dimRoundingMode);\n  let res: TensorInfo;\n\n  if (convInfo.filterWidth === 1 && convInfo.filterHeight === 1 &&\n      util.arraysEqual(convInfo.inShape, convInfo.outShape)) {\n    res = identity({inputs: {x}, backend});\n  } else {\n    const xValues = backend.data.get(x.dataId).values as TypedArray;\n    const strides = util.computeStrides(x.shape);\n    const buffer = pool(xValues, x.shape, x.dtype, strides, convInfo, 'max');\n    res = backend.makeTensorInfo(\n        convInfo.outShape, x.dtype, buffer.values as TypedArray);\n  }\n  return res;\n}\n\nexport const maxPoolConfig: KernelConfig = {\n  kernelName: MaxPool,\n  backendName: 'cpu',\n  kernelFunc: maxPool as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, buffer, KernelConfig, KernelFunc, MaxPoolBackprop, MaxPoolBackpropAttrs, MaxPoolBackpropInputs, Rank, TensorInfo, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\nimport {maxPoolPositions} from '../utils/pool_utils';\n\nexport function maxPoolBackprop(args: {\n  inputs: MaxPoolBackpropInputs,\n  backend: MathBackendCPU,\n  attrs: MaxPoolBackpropAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {dy, input, output} = inputs;\n  const x = input;\n  assertNotComplex([input, output], 'maxPoolBackprop');\n  const {filterSize, strides, pad, dimRoundingMode} = attrs;\n\n  const convInfo = backend_util.computePool2DInfo(\n      x.shape as [number, number, number, number], filterSize, strides,\n      1 /* dilations */, pad, dimRoundingMode);\n  const xValues = backend.data.get(x.dataId).values as TypedArray;\n  const maxPosBuf = buffer(\n      convInfo.outShape, x.dtype,\n      maxPoolPositions(xValues, x.shape, x.dtype, convInfo).values);\n  const strideHeight = convInfo.strideHeight;\n  const strideWidth = convInfo.strideWidth;\n  const dilationHeight = convInfo.dilationHeight;\n  const dilationWidth = convInfo.dilationWidth;\n  const effectiveFilterHeight = convInfo.effectiveFilterHeight;\n  const effectiveFilterWidth = convInfo.effectiveFilterWidth;\n  const padLeft = effectiveFilterWidth - 1 - convInfo.padInfo.left;\n  const padTop = effectiveFilterHeight - 1 - convInfo.padInfo.top;\n  const dx =\n      buffer<Rank.R4>(x.shape as [number, number, number, number], 'float32');\n\n  const dyData = backend.data.get(dy.dataId).values as Float32Array;\n  const dyBuf = buffer<Rank.R4>(\n      dy.shape as [number, number, number, number], 'float32', dyData);\n\n  for (let b = 0; b < convInfo.batchSize; ++b) {\n    for (let d = 0; d < convInfo.inChannels; ++d) {\n      for (let dxR = 0; dxR < convInfo.inHeight; ++dxR) {\n        for (let dxC = 0; dxC < convInfo.inWidth; ++dxC) {\n          // Shader code begins.\n          const dyRCorner = dxR - padTop;\n          const dyCCorner = dxC - padLeft;\n          let dotProd = 0;\n          for (let wR = 0; wR < effectiveFilterHeight; wR += dilationHeight) {\n            const dyR = (dyRCorner + wR) / strideHeight;\n            if (dyR < 0 || dyR >= convInfo.outHeight ||\n                Math.floor(dyR) !== dyR) {\n              continue;\n            }\n            for (let wC = 0; wC < effectiveFilterWidth; wC += dilationWidth) {\n              const dyC = (dyCCorner + wC) / strideWidth;\n              if (dyC < 0 || dyC >= convInfo.outWidth ||\n                  Math.floor(dyC) !== dyC) {\n                continue;\n              }\n              const maxPos = effectiveFilterHeight * effectiveFilterWidth - 1 -\n                  (maxPosBuf.get(b, dyR, dyC, d) as number);\n              const curPos = wR * effectiveFilterWidth + wC;\n\n              const mask = maxPos === curPos ? 1 : 0;\n              if (mask === 0) {\n                continue;\n              }\n\n              const pixel = dyBuf.get(b, dyR, dyC, d);\n              dotProd += pixel * mask;\n            }\n          }\n          dx.set(dotProd, b, dxR, dxC, d);\n        }\n      }\n    }\n  }\n  return backend.makeTensorInfo(dx.shape, dx.dtype, dx.values);\n}\n\nexport const maxPoolBackpropConfig: KernelConfig = {\n  kernelName: MaxPoolBackprop,\n  backendName: 'cpu',\n  kernelFunc: maxPoolBackprop as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {MaxPoolWithArgmax, MaxPoolWithArgmaxAttrs, MaxPoolWithArgmaxInputs} from '@tensorflow/tfjs-core';\nimport {backend_util, KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {maxPoolWithArgmaxImpl} from './MaxPoolWithArgmax_impl';\n\nexport const maxPoolWithArgmaxConfig: KernelConfig = {\n  kernelName: MaxPoolWithArgmax,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {x} = inputs as MaxPoolWithArgmaxInputs;\n    const {filterSize, strides, pad, includeBatchInIndex} =\n        attrs as {} as MaxPoolWithArgmaxAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'MaxPoolWithArgmax');\n\n    const values = cpuBackend.data.get(x.dataId).values as TypedArray;\n    const convInfo = backend_util.computePool2DInfo(\n        x.shape as [number, number, number, number], filterSize, strides,\n        [1, 1], pad);\n    const [pooled, indexes] = maxPoolWithArgmaxImpl(\n        values, x.shape, x.dtype, includeBatchInIndex, convInfo);\n\n    const pooledDataId =\n        cpuBackend.write(pooled as Float32Array, convInfo.outShape, x.dtype);\n    const indexesDataId =\n        cpuBackend.write(indexes as Int32Array, convInfo.outShape, x.dtype);\n    return [\n      {dataId: pooledDataId, shape: convInfo.outShape, dtype: x.dtype},\n      {dataId: indexesDataId, shape: convInfo.outShape, dtype: 'int32'}\n    ];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport {backend_util, DataType, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {maxPoolPositions, pool} from '../utils/pool_utils';\nexport function maxPoolWithArgmaxImpl(\n    xValues: TypedArray, xShape: number[], dtype: DataType,\n    includeBatchInIndex: boolean, convInfo: backend_util.Conv2DInfo) {\n  const strides = util.computeStrides(xShape);\n  const maxPools = pool(xValues, xShape, dtype, strides, convInfo, 'max');\n  const maxPositions = maxPoolPositions(\n      xValues, xShape, dtype, convInfo, true, includeBatchInIndex);\n\n  return [maxPools.values, maxPositions.values];\n}\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, MirrorPad, MirrorPadAttrs, MirrorPadInputs, NumericDataType, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function mirrorPad(args: {\n  inputs: MirrorPadInputs,\n  backend: MathBackendCPU,\n  attrs: MirrorPadAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, mode} = attrs;\n\n  assertNotComplex(x, 'mirrorPad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n  const end = paddings.map((p, i) => p[0] + x.shape[i]);\n  const offset = mode === 'reflect' ? 0 : 1;\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  for (let i = 0; i < resultSize; i++) {\n    let coords = util.indexToLoc(i, resultRank, resultStrides);\n    for (let i = 0; i < resultRank; i++) {\n      if (coords[i] < start[i]) {\n        coords[i] = start[i] * 2 - coords[i] - offset;\n      } else if (coords[i] >= end[i]) {\n        coords[i] = (end[i] - 1) * 2 - coords[i] + offset;\n      }\n    }\n    coords = coords.map((c, i) => c - start[i]);\n\n    const inIndex = util.locToIndex(coords, xRank, xStrides);\n\n    resVals[i] = xVals[inIndex];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const mirrorPadConfig: KernelConfig = {\n  kernelName: MirrorPad,\n  backendName: 'cpu',\n  kernelFunc: mirrorPad as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV4, NonMaxSuppressionV4Attrs, NonMaxSuppressionV4Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV4Impl = kernel_impls.nonMaxSuppressionV4Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV4Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV4,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV4Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, padToMaxOutputSize} =\n        attrs as unknown as NonMaxSuppressionV4Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionPadded');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const {selectedIndices, validOutputs} = nonMaxSuppressionV4Impl(\n        boxesVals, scoresVals, maxOutputSize, iouThreshold, scoreThreshold,\n        padToMaxOutputSize);\n\n    return [selectedIndices, validOutputs];\n  }\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {NonMaxSuppressionV5, NonMaxSuppressionV5Attrs, NonMaxSuppressionV5Inputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig, TypedArray} from '@tensorflow/tfjs-core';\nimport {kernel_impls} from '@tensorflow/tfjs-core';\nconst nonMaxSuppressionV5Impl = kernel_impls.nonMaxSuppressionV5Impl;\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const nonMaxSuppressionV5Config: KernelConfig = {\n  kernelName: NonMaxSuppressionV5,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend, attrs}) => {\n    const {boxes, scores} = inputs as NonMaxSuppressionV5Inputs;\n    const {maxOutputSize, iouThreshold, scoreThreshold, softNmsSigma} =\n        attrs as unknown as NonMaxSuppressionV5Attrs;\n\n    const cpuBackend = backend as MathBackendCPU;\n\n    assertNotComplex(boxes, 'NonMaxSuppressionWithScore');\n\n    const boxesVals = cpuBackend.data.get(boxes.dataId).values as TypedArray;\n    const scoresVals = cpuBackend.data.get(scores.dataId).values as TypedArray;\n\n    const maxOutputSizeVal = maxOutputSize;\n    const iouThresholdVal = iouThreshold;\n    const scoreThresholdVal = scoreThreshold;\n    const softNmsSigmaVal = softNmsSigma;\n\n    const {selectedIndices, selectedScores} = nonMaxSuppressionV5Impl(\n        boxesVals, scoresVals, maxOutputSizeVal, iouThresholdVal,\n        scoreThresholdVal, softNmsSigmaVal);\n\n    return [selectedIndices, selectedScores];\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, NumericDataType, PadV2, PadV2Attrs, PadV2Inputs, TensorInfo, TypedArray, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport function padV2(\n    args: {inputs: PadV2Inputs, backend: MathBackendCPU, attrs: PadV2Attrs}):\n    TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {paddings, constantValue} = attrs;\n\n  assertNotComplex(x, 'pad');\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  const start = paddings.map(p => p[0]);\n\n  const xVals = backend.data.get(x.dataId).values as TypedArray;\n  const xSize = util.sizeFromShape(x.shape);\n  const xRank = x.shape.length;\n  const xStrides = util.computeStrides(x.shape);\n\n  const resultSize = util.sizeFromShape(outShape);\n  const resultRank = outShape.length;\n  const resultStrides = util.computeStrides(outShape);\n  const resVals =\n      util.getTypedArrayFromDType(x.dtype as NumericDataType, resultSize);\n\n  if (constantValue !== 0) {\n    resVals.fill(constantValue);\n  }\n\n  for (let i = 0; i < xSize; i++) {\n    const coords = util.indexToLoc(i, xRank, xStrides);\n    const outCoords = coords.map((c, i) => c + start[i]);\n    const outIndex = util.locToIndex(outCoords, resultRank, resultStrides);\n\n    resVals[outIndex] = xVals[i];\n  }\n\n  const outId = backend.write(resVals, outShape, x.dtype);\n\n  return {dataId: outId, shape: outShape, dtype: x.dtype};\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'cpu',\n  kernelFunc: padV2 as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Reciprocal} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const reciprocal = unaryKernelFunc(Reciprocal, (xi) => 1 / xi);\n\nexport const reciprocalConfig: KernelConfig = {\n  kernelName: Reciprocal,\n  backendName: 'cpu',\n  kernelFunc: reciprocal,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, NumericDataType, TypedArray} from '@tensorflow/tfjs-core';\nimport {backend_util, RotateWithOffset, RotateWithOffsetAttrs, RotateWithOffsetInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\n\nexport const rotateWithOffsetConfig: KernelConfig = {\n  kernelName: RotateWithOffset,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, attrs, backend}) => {\n    const {image} = inputs as RotateWithOffsetInputs;\n    const {radians, fillValue, center} = attrs as {} as RotateWithOffsetAttrs;\n    const cpuBackend = backend as MathBackendCPU;\n\n    const output = util.getTypedArrayFromDType(\n        image.dtype as NumericDataType, util.sizeFromShape(image.shape));\n    const [batch, imageHeight, imageWidth, numChannels] = image.shape;\n\n    const [centerX, centerY] =\n        backend_util.getImageCenter(center, imageHeight, imageWidth);\n    const fullOpacityValue = 255;\n\n    const sinFactor = Math.sin(radians);\n    const cosFactor = Math.cos(radians);\n    const imageVals = cpuBackend.data.get(image.dataId).values as TypedArray;\n\n    for (let batchIdx = 0; batchIdx < batch; batchIdx++) {\n      const batchOffset = batchIdx * imageWidth * imageHeight * numChannels;\n\n      for (let row = 0; row < imageHeight; row++) {\n        const rowOffset = row * (imageWidth * numChannels);\n\n        for (let col = 0; col < imageWidth; col++) {\n          const colOffset = col * numChannels;\n\n          for (let channel = 0; channel < numChannels; channel++) {\n            const coords = [batch, row, col, channel];\n\n            const x = coords[2];\n            const y = coords[1];\n\n            // coordX/coordY are the result of rotating and translating x/y.\n            let coordX = (x - centerX) * cosFactor - (y - centerY) * sinFactor;\n            let coordY = (x - centerX) * sinFactor + (y - centerY) * cosFactor;\n            coordX = Math.round(coordX + centerX);\n            coordY = Math.round(coordY + centerY);\n\n            let outputValue = fillValue;\n            if (typeof fillValue !== 'number') {\n              if (channel === 3) {\n                outputValue = fullOpacityValue;\n              } else {\n                outputValue = fillValue[channel];\n              }\n            }\n\n            // If the coordinate position falls within the image boundaries...\n            if (coordX >= 0 && coordX < imageWidth && coordY >= 0 &&\n                coordY < imageHeight) {\n              // set the output to the image value at the coordinate position.\n              const rotatedRowOffset = coordY * (imageWidth * numChannels);\n              const rotatedColOffset = coordX * numChannels;\n              const imageIdx =\n                  batchOffset + rotatedRowOffset + rotatedColOffset + channel;\n              outputValue = imageVals[imageIdx];\n            }\n\n            const outIdx = batchOffset + rowOffset + colOffset + channel;\n            output[outIdx] = outputValue as number;\n          }\n        }\n      }\n    }\n\n    const dataId = cpuBackend.write(output, image.shape, image.dtype);\n    return {dataId, shape: image.shape, dtype: image.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Round} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const round = unaryKernelFunc(Round, (xi) => {\n  // The algorithm is based on banker's rounding.\n  const base = Math.floor(xi);\n  if (xi - base < 0.5) {\n    return Math.floor(xi);\n  } else if (xi - base > 0.5) {\n    return Math.ceil(xi);\n  } else {\n    if (base % 2.0 === 0.0) {\n      return base;\n    } else {\n      return base + 1.0;\n    }\n  }\n});\n\nexport const roundConfig: KernelConfig = {\n  kernelName: Round,\n  backendName: 'cpu',\n  kernelFunc: round,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, Selu} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nconst scaleAlpha = backend_util.SELU_SCALEALPHA;\nconst scale = backend_util.SELU_SCALE;\n\nexport const selu = unaryKernelFunc(Selu, (xi) => {\n  if (xi >= 0) {\n    return scale * xi;\n  } else {\n    return scaleAlpha * (Math.exp(xi) - 1);\n  }\n});\n\nexport const seluConfig: KernelConfig = {\n  kernelName: Selu,\n  backendName: 'cpu',\n  kernelFunc: selu,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sigmoid} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sigmoid =\n    unaryKernelFunc(Sigmoid, (xi) => 1 / (1 + Math.exp(-xi)));\n\nexport const sigmoidConfig: KernelConfig = {\n  kernelName: Sigmoid,\n  backendName: 'cpu',\n  kernelFunc: sigmoid,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sign} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sign = unaryKernelFunc(Sign, (xi) => {\n  if (xi < 0) {\n    return -1;\n  } else if (xi > 0) {\n    return 1;\n  } else {\n    return 0;\n  }\n});\n\nexport const signConfig: KernelConfig = {\n  kernelName: Sign,\n  backendName: 'cpu',\n  kernelFunc: sign,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sin} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sin = unaryKernelFunc(Sin, (xi) => Math.sin(xi));\n\nexport const sinConfig: KernelConfig = {\n  kernelName: Sin,\n  backendName: 'cpu',\n  kernelFunc: sin,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sinh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sinh = unaryKernelFunc(Sinh, (xi) => Math.sinh(xi));\n\nexport const sinhConfig: KernelConfig = {\n  kernelName: Sinh,\n  backendName: 'cpu',\n  kernelFunc: sinh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Softplus} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\n// mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\nconst epsilon = 1.1920928955078125e-7;\nconst threshold = Math.log(epsilon) + 2.0;\n\nexport const softplus = unaryKernelFunc(Softplus, (xi) => {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  const tooLarge = xi > -threshold;\n\n  // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n  const tooSmall = xi < threshold;\n\n  const expX = Math.exp(xi);\n  let result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n  return result;\n});\n\nexport const softplusConfig: KernelConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplus,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Transpose, TransposeAttrs, TransposeInputs, TypedArray} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {transposeImpl} from './Transpose_impl';\n\nexport function transpose(args: {\n  inputs: TransposeInputs,\n  attrs: TransposeAttrs,\n  backend: MathBackendCPU\n}): TensorInfo {\n  const {inputs, attrs, backend} = args;\n  const {x} = inputs;\n  const {perm} = attrs;\n\n  assertNotComplex(x, 'transpose');\n\n  const xRank = x.shape.length;\n\n  const newShape: number[] = new Array(xRank);\n  for (let i = 0; i < newShape.length; i++) {\n    newShape[i] = x.shape[perm[i]];\n  }\n\n  const values = backend.data.get(x.dataId).values as TypedArray;\n  const result = transposeImpl(values, x.shape, x.dtype, perm, newShape);\n\n  const dataId = backend.write(result, newShape, x.dtype);\n  return {dataId, shape: newShape, dtype: x.dtype};\n}\n\nexport const transposeConfig: KernelConfig = {\n  kernelName: Transpose,\n  backendName: 'cpu',\n  kernelFunc: transpose as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, ReshapeAttrs, ReshapeInputs, SpaceToBatchND, SpaceToBatchNDAttrs, SpaceToBatchNDInputs, TensorInfo, TransposeAttrs, TransposeInputs, util} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {padV2Config} from './PadV2';\nimport {reshape} from './Reshape';\nimport {transpose} from './Transpose';\n\nexport function spaceToBatchND(args: {\n  inputs: SpaceToBatchNDInputs,\n  backend: MathBackendCPU,\n  attrs: SpaceToBatchNDAttrs\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x} = inputs;\n  const {blockShape, paddings} = attrs;\n\n  assertNotComplex([x], 'spaceToBatchND');\n\n  const prod = util.sizeFromShape(blockShape);\n\n  const completePaddings: Array<[number, number]> = [[0, 0]];\n  completePaddings.push(...(paddings as Array<[number, number]>));\n\n  for (let i = 1 + blockShape.length; i < x.shape.length; ++i) {\n    completePaddings.push([0, 0]);\n  }\n\n  const paddedX = padV2Config.kernelFunc({\n    inputs: {x},\n    backend,\n    attrs: {paddings: completePaddings, constantValue: 0}\n  }) as TensorInfo;\n\n  const reshapedPaddedShape =\n      backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n\n  const permutedReshapedPaddedPermutation = backend_util.getPermuted(\n      reshapedPaddedShape.length, blockShape.length, false);\n\n  const flattenShape =\n      backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n\n  const reshapeInputs: ReshapeInputs = {x: paddedX};\n  const reshapeAttrs: ReshapeAttrs = {shape: reshapedPaddedShape};\n  const paddedXReshaped =\n      reshape({inputs: reshapeInputs, backend, attrs: reshapeAttrs});\n\n  const transposeInputs: TransposeInputs = {x: paddedXReshaped};\n  const transposeAttrs:\n      TransposeAttrs = {perm: permutedReshapedPaddedPermutation};\n  const paddedXT =\n      transpose({inputs: transposeInputs, backend, attrs: transposeAttrs});\n\n  const resultReshapeInputs: ReshapeInputs = {x: paddedXT};\n  const resultReshapeAttrs: ReshapeAttrs = {shape: flattenShape};\n  const result = reshape(\n      {inputs: resultReshapeInputs, backend, attrs: resultReshapeAttrs});\n\n  backend.disposeIntermediateTensorInfo(paddedX);\n  backend.disposeIntermediateTensorInfo(paddedXReshaped);\n  backend.disposeIntermediateTensorInfo(paddedXT);\n\n  return result;\n}\n\nexport const spaceToBatchNDConfig: KernelConfig = {\n  kernelName: SpaceToBatchND,\n  backendName: 'cpu',\n  kernelFunc: spaceToBatchND as {} as KernelFunc\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Sqrt} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const sqrt = unaryKernelFunc(Sqrt, (xi) => Math.sqrt(xi));\n\nexport const sqrtConfig: KernelConfig = {\n  kernelName: Sqrt,\n  backendName: 'cpu',\n  kernelFunc: sqrt,\n};\n","/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {Square, SquareInputs} from '@tensorflow/tfjs-core';\nimport {KernelConfig} from '@tensorflow/tfjs-core';\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nexport const squareConfig: KernelConfig = {\n  kernelName: Square,\n  backendName: 'cpu',\n  kernelFunc: ({inputs, backend}) => {\n    const {x} = inputs as SquareInputs;\n    const cpuBackend = backend as MathBackendCPU;\n    assertNotComplex(x, 'square');\n\n    const values = cpuBackend.data.get(x.dataId).values as Float32Array;\n    const newValues = new Float32Array(values.length);\n    for (let i = 0; i < values.length; ++i) {\n      const value = values[i];\n      newValues[i] = value * value;\n    }\n    const dataId = cpuBackend.write(newValues, x.shape, x.dtype);\n    return {dataId, shape: x.shape, dtype: x.dtype};\n  }\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Step, StepAttrs} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const step = unaryKernelFunc(Step, (xi, attrs) => {\n  const stepAttrs = attrs as {} as StepAttrs;\n  if (isNaN(xi)) {\n    return NaN;\n  } else {\n    return xi > 0 ? 1 : stepAttrs.alpha;\n  }\n});\n\nexport const stepConfig: KernelConfig = {\n  kernelName: Step,\n  backendName: 'cpu',\n  kernelFunc: step,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tan} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tan = unaryKernelFunc(Tan, (xi) => Math.tan(xi));\n\nexport const tanConfig: KernelConfig = {\n  kernelName: Tan,\n  backendName: 'cpu',\n  kernelFunc: tan,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, Tanh} from '@tensorflow/tfjs-core';\n\nimport {unaryKernelFunc} from '../utils/unary_utils';\n\nexport const tanh = unaryKernelFunc(Tanh, (xi) => Math.tanh(xi));\n\nexport const tanhConfig: KernelConfig = {\n  kernelName: Tanh,\n  backendName: 'cpu',\n  kernelFunc: tanh,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, TensorInfo, Unique, UniqueAttrs, UniqueInputs} from '@tensorflow/tfjs-core';\n\nimport {MathBackendCPU} from '../backend_cpu';\nimport {assertNotComplex} from '../cpu_util';\n\nimport {uniqueImpl} from './Unique_impl';\n\nexport function unique(\n    args: {inputs: UniqueInputs, attrs: UniqueAttrs, backend: MathBackendCPU}):\n    TensorInfo[] {\n  const {inputs, attrs, backend} = args;\n  const {axis} = attrs;\n  const {x} = inputs;\n  assertNotComplex(x, 'unique');\n\n  const values = backend.data.get(x.dataId).values;\n  const {outputValues, outputShape, indices} =\n      uniqueImpl(values, axis, x.shape, x.dtype);\n  return [\n    backend.makeTensorInfo(outputShape, x.dtype, outputValues),\n    backend.makeTensorInfo([indices.length], 'int32', indices),\n  ];\n}\n\nexport const uniqueConfig: KernelConfig = {\n  kernelName: Unique,\n  backendName: 'cpu',\n  kernelFunc: unique as {} as KernelFunc,\n};\n","/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// We explicitly import the modular kernels so they get registered in the\n// global registry when we compile the library. A modular build would replace\n// the contents of this file and import only the kernels that are needed.\nimport {KernelConfig, registerKernel} from '@tensorflow/tfjs-core';\n\nimport {_fusedMatMulConfig} from './kernels/_FusedMatMul';\nimport {absConfig} from './kernels/Abs';\nimport {acosConfig} from './kernels/Acos';\nimport {acoshConfig} from './kernels/Acosh';\nimport {addConfig} from './kernels/Add';\nimport {asinConfig} from './kernels/Asin';\nimport {asinhConfig} from './kernels/Asinh';\nimport {atanConfig} from './kernels/Atan';\nimport {atanhConfig} from './kernels/Atanh';\nimport {avgPoolConfig} from './kernels/AvgPool';\nimport {avgPoolBackpropConfig} from './kernels/AvgPoolBackprop';\nimport {batchMatMulConfig} from './kernels/BatchMatMul';\nimport {batchNormConfig} from './kernels/BatchNorm';\nimport {castConfig} from './kernels/Cast';\nimport {ceilConfig} from './kernels/Ceil';\nimport {clipConfig} from './kernels/Clip';\nimport {complexConfig} from './kernels/Complex';\nimport {concatConfig} from './kernels/Concat';\nimport {conv2DConfig} from './kernels/Conv2D';\nimport {conv2DBackpropFilterConfig} from './kernels/Conv2DBackpropFilter';\nimport {conv2DBackpropInputConfig} from './kernels/Conv2DBackpropInput';\nimport {conv3DConfig} from './kernels/Conv3D';\nimport {conv3DBackpropFilterV2Config} from './kernels/Conv3DBackpropFilterV2';\nimport {conv3DBackpropInputV2Config} from './kernels/Conv3DBackpropInputV2';\nimport {cosConfig} from './kernels/Cos';\nimport {coshConfig} from './kernels/Cosh';\nimport {depthwiseConv2dNativeConfig} from './kernels/DepthwiseConv2dNative';\nimport {depthwiseConv2dNativeBackpropFilterConfig} from './kernels/DepthwiseConv2dNativeBackpropFilter';\nimport {depthwiseConv2dNativeBackpropInputConfig} from './kernels/DepthwiseConv2dNativeBackpropInput';\nimport {dilation2dConfig} from './kernels/Dilation2D';\nimport {dilation2dBackpropFilterConfig} from './kernels/Dilation2DBackpropFilter';\nimport {dilation2dBackpropInputConfig} from './kernels/Dilation2DBackpropInput';\nimport {divConfig} from './kernels/Div';\nimport {eluConfig} from './kernels/Elu';\nimport {erfConfig} from './kernels/Erf';\nimport {expConfig} from './kernels/Exp';\nimport {expm1Config} from './kernels/Expm1';\nimport {fftConfig} from './kernels/FFT';\nimport {fillConfig} from './kernels/Fill';\nimport {flipLeftRightConfig} from './kernels/FlipLeftRight';\nimport {floorConfig} from './kernels/Floor';\nimport {fusedConv2DConfig} from './kernels/FusedConv2D';\nimport {fusedDepthwiseConv2DConfig} from './kernels/FusedDepthwiseConv2D';\nimport {identityConfig} from './kernels/Identity';\nimport {ifftConfig} from './kernels/IFFT';\nimport {imagConfig} from './kernels/Imag';\nimport {isFiniteConfig} from './kernels/IsFinite';\nimport {isInfConfig} from './kernels/IsInf';\nimport {isNaNConfig} from './kernels/IsNaN';\nimport {logConfig} from './kernels/Log';\nimport {log1pConfig} from './kernels/Log1p';\nimport {logicalNotConfig} from './kernels/LogicalNot';\nimport {maxConfig} from './kernels/Max';\nimport {maxPoolConfig} from './kernels/MaxPool';\nimport {maxPoolBackpropConfig} from './kernels/MaxPoolBackprop';\nimport {maxPoolWithArgmaxConfig} from './kernels/MaxPoolWithArgmax';\nimport {mirrorPadConfig} from './kernels/MirrorPad';\nimport {multiplyConfig} from './kernels/Multiply';\nimport {nonMaxSuppressionV4Config} from './kernels/NonMaxSuppressionV4';\nimport {nonMaxSuppressionV5Config} from './kernels/NonMaxSuppressionV5';\nimport {notEqualConfig} from './kernels/NotEqual';\nimport {padV2Config} from './kernels/PadV2';\nimport {preluConfig} from './kernels/Prelu';\nimport {realConfig} from './kernels/Real';\nimport {reciprocalConfig} from './kernels/Reciprocal';\nimport {reluConfig} from './kernels/Relu';\nimport {relu6Config} from './kernels/Relu6';\nimport {reshapeConfig} from './kernels/Reshape';\nimport {rotateWithOffsetConfig} from './kernels/RotateWithOffset';\nimport {roundConfig} from './kernels/Round';\nimport {rsqrtConfig} from './kernels/Rsqrt';\nimport {seluConfig} from './kernels/Selu';\nimport {sigmoidConfig} from './kernels/Sigmoid';\nimport {signConfig} from './kernels/Sign';\nimport {sinConfig} from './kernels/Sin';\nimport {sinhConfig} from './kernels/Sinh';\nimport {sliceConfig} from './kernels/Slice';\nimport {softplusConfig} from './kernels/Softplus';\nimport {spaceToBatchNDConfig} from './kernels/SpaceToBatchND';\nimport {sqrtConfig} from './kernels/Sqrt';\nimport {squareConfig} from './kernels/Square';\nimport {squaredDifferenceConfig} from './kernels/SquaredDifference';\nimport {stepConfig} from './kernels/Step';\nimport {subConfig} from './kernels/Sub';\nimport {tanConfig} from './kernels/Tan';\nimport {tanhConfig} from './kernels/Tanh';\nimport {transposeConfig} from './kernels/Transpose';\nimport {uniqueConfig} from './kernels/Unique';\n\n// List all kernel configs here\nconst kernelConfigs: KernelConfig[] = [\n  _fusedMatMulConfig,\n  absConfig,\n  acosConfig,\n  acoshConfig,\n  addConfig,\n  asinConfig,\n  asinhConfig,\n  atanConfig,\n  atanhConfig,\n  avgPoolConfig,\n  avgPoolBackpropConfig,\n  batchMatMulConfig,\n  batchNormConfig,\n  castConfig,\n  ceilConfig,\n  clipConfig,\n  complexConfig,\n  concatConfig,\n  conv2DBackpropFilterConfig,\n  conv2DBackpropInputConfig,\n  conv2DConfig,\n  conv3DBackpropFilterV2Config,\n  conv3DBackpropInputV2Config,\n  conv3DConfig,\n  cosConfig,\n  coshConfig,\n  depthwiseConv2dNativeConfig,\n  depthwiseConv2dNativeBackpropFilterConfig,\n  depthwiseConv2dNativeBackpropInputConfig,\n  dilation2dConfig,\n  dilation2dBackpropInputConfig,\n  dilation2dBackpropFilterConfig,\n  divConfig,\n  eluConfig,\n  erfConfig,\n  expConfig,\n  expm1Config,\n  fftConfig,\n  fillConfig,\n  flipLeftRightConfig,\n  floorConfig,\n  fusedConv2DConfig,\n  fusedDepthwiseConv2DConfig,\n  identityConfig,\n  ifftConfig,\n  imagConfig,\n  isFiniteConfig,\n  isInfConfig,\n  isNaNConfig,\n  logConfig,\n  log1pConfig,\n  logicalNotConfig,\n  maxPoolConfig,\n  maxPoolBackpropConfig,\n  maxPoolWithArgmaxConfig,\n  maxConfig,\n  mirrorPadConfig,\n  multiplyConfig,\n  nonMaxSuppressionV4Config,\n  nonMaxSuppressionV5Config,\n  notEqualConfig,\n  padV2Config,\n  preluConfig,\n  realConfig,\n  reciprocalConfig,\n  reluConfig,\n  relu6Config,\n  reshapeConfig,\n  rotateWithOffsetConfig,\n  roundConfig,\n  rsqrtConfig,\n  seluConfig,\n  sigmoidConfig,\n  signConfig,\n  sinConfig,\n  sinhConfig,\n  sliceConfig,\n  softplusConfig,\n  spaceToBatchNDConfig,\n  sqrtConfig,\n  squareConfig,\n  squaredDifferenceConfig,\n  stepConfig,\n  subConfig,\n  tanConfig,\n  tanhConfig,\n  transposeConfig,\n  uniqueConfig,\n];\n\nfor (const kernelConfig of kernelConfigs) {\n  registerKernel(kernelConfig);\n}\n","/** @license See the LICENSE file. */\n\n// This code is auto-generated, do not modify this file!\nconst version = '2.7.0';\nexport {version};\n"],"names":["assertNotComplex","tensor","opName","Array","isArray","forEach","t","util","assert","dtype","nonMaxSuppressionV3Impl","kernel_impls","split","tile","topkImpl","whereImpl","MathBackendCPU","KernelBackend","[object Object]","super","this","data","DataStorage","engine","values","shape","firstUse","env","get","backend_util","warn","dataId","set","refCount","outId","length","isString","encodedValues","map","d","encodeString","write","has","numDataIds","readSync","complexTensorInfos","realValues","real","imagValues","imag","mergeRealAndImagArrays","decodedData","decodeString","Error","tf.buffer","makeTensorFromDataId","disposeData","delete","tensorInfo","tensorData","f","start","now","kernelMs","unreliable","reasons","x","begin","end","strides","outShape","slice_util","computeOutShape","some","axis","tf.tensor","buffer","xBuf","bufferSync","i","size","loc","indexToLoc","newLoc","j","toTensor","xVals","vals","num","rank","outIndex","fill","slice","res","tf.slice","reshape","outLoc","inLoc","ax","tf.mul","tf.scalar","tensors","result","resultVals","currVals","logits","dim","axes","parseAxisParam","maxLogit","max","expandedShape","expandShapeToKeepDim","a","tf.sub","b","tf.exp","sumExp","sum","tf.div","broadcastedBinaryOp","aValue","bValue","Math","pow","floor","assertAxesAreInnerMostDims","reduceShape","computeOutAndReduceShapes","resultDtype","upcastType","tf.zeros","reduceSize","sizeFromShape","aVals","offset","prod","segmentIds","numSegments","numIters","expandDims","segmentId","tf.equal","asType","mul","push","tf.stack","min","minIndex","value","maxIndex","exclusive","reverse","finalDim","indexAdjuster","idx","prevIdx","aVal","bVal","condition","aValues","bValues","newValues","index","condVals","k","sorted","rem","all","anyVal","diff","dy","y","resultValues","Float32Array","dyValues","v","makeOutput","atan2","reps","indices","newShape","indicesValues","originalLoc","originalIndex","locToIndex","blockShape","crops","reduce","reshaped","getReshaped","permuted","getPermuted","reshapedPermuted","getReshapedPermuted","sliceBeginCoords","getSliceBeginCoords","sliceSize","getSliceSize","tf.transpose","convInfo","poolType","strideDepth","strideHeight","strideWidth","dilationDepth","dilationHeight","dilationWidth","effectiveFilterDepth","effectiveFilterHeight","effectiveFilterWidth","padFront","padInfo","front","padTop","top","padLeft","left","initialValue","Number","NEGATIVE_INFINITY","POSITIVE_INFINITY","xValues","output","outputVals","outputBatchStrides","outputDepthStrides","outputRowStrides","outputColStrides","batch","batchSize","outputBatchOffset","inputBatchOffset","channel","inChannels","yDepth","outDepth","xDepthCorner","xDepthMin","xDepthMax","inDepth","outputDepthOffset","yRow","outHeight","xRowCorner","xRowMin","xRowMax","inHeight","outputRowOffset","yCol","outWidth","xColCorner","xColMin","xColMax","inWidth","outputColOffset","minMaxValue","avgValue","count","xDepth","xDepthOffset","xRow","xRowOffset","xCol","pixel","isNaN","pool3d","toFloat","filterDepth","filterHeight","filterWidth","dx","avgMultiplier","dyBuf","dxDepth","dxRow","dxCol","dyDepthCorner","dyRowCorner","dyColCorner","dotProd","wDepth","dyDepth","wRow","dyRow","wCol","dyCol","maxPositions","maxValue","maxPosition","maxPool3dPositions","maxPosBuf","mask","newHeight","newWidth","alignCorners","oldHeight","oldWidth","numChannels","effectiveInputSize","effectiveOutputSize","outputIdx","effectiveRowSizeRatio","effectiveColSizeRatio","r","sourceFracRow","sourceRowFloor","rowFrac","sourceRowCeil","ceil","topRowOffset","botRowOffset","c","sourceFracCol","sourceColFloor","colFrac","sourceColCeil","topLeftOffest","botLeftOffset","topRightOffset","botRightOffest","topLeft","bottomLeft","newValue","xHeight","xWidth","depth","yHeight","yWidth","effectiveXSize","effectiveYSize","heightScale","widthScale","bOffset","dxR","topDxRIndex","bottomDxRIndex","topDxROffset","bottomDxROffset","dxRLerp","inverseDxRLerp","dxC","leftDxCIndex","rightDxCIndex","dxCLerp","inverseDxCLerp","topLeftRCOffset","topRightRCOffset","bottomLeftRCOffset","bottomRightRCOffset","inverseDxRLerpTimesInverseDxCLerp","inverseDxRLerpTimesDxCLerp","dxRLerpTimesInverseDxCLerp","dxRLerpTimesDxCLerp","dyVal","tf.tensor4d","outputOffset","batchOffset","rowOffset","round","colOffset","newVal","invHeightScale","invWidthScale","winHeight","winWidth","startRLerp","startDyR","startCLerp","startDyC","accum","dyRIndex","dyR","dyROffset","dyCIndex","dyC","dyCOffset","depthRadius","bias","alpha","beta","channels","maxD","sumAcrossChannels","currentChannel","beginSumOffset","endSumOffset","z","val","inputImage","outputImage","inputImageValues","outputImageValues","depthBegin","depthEnd","norm","dyi","normalized","numSamples","seed","probabilities","tf.softmax","numEvents","resVals","probVals","cdf","event","random","seedrandom.alea","toString","outOffset","sampleId","onValue","offValue","indicesVal","tf.tensor2d","boxes","scores","maxOutputSize","iouThreshold","scoreThreshold","boxesVals","scoresVals","blockSize","dataFormat","inputHeight","inputWidth","inputDepth","outputHeight","outputWidth","outputDepth","h","inH","offsetH","w","inW","offsetD","inputIdx","op","assertAndGetBroadcastShape","bVals","aBroadcastDims","getBroadcastDims","bBroadcastDims","aBuf","bBuf","aLoc","aIndex","bLoc","bIndex","sizeSplits","epsilon","images","boxIndex","cropSize","method","extrapolationValue","imageHeight","imageWidth","numBoxes","cropHeight","cropWidth","boxVals","boxIndVals","imageVals","inStride","outStride","startInd","y1","x1","y2","x2","bInd","yInd","ind","topInd","bottomInd","yLerp","xInd","leftInd","rightInd","xLerp","topRight","bottom","closestX","closestY","inInd","outInd","sparseIndices","sparseValues","outputShape","defaultValue","sliceRank","numUpdates","outputSize","calculateShapes","scatter","indicesShape","resultShape","numSlices","prepareAndValidate","TensorBuffer","indicesData","xData","flattenIndex","updates","tf.fill","getArrayFromDType","stop","linspaceImpl","sumDupeIndices","flattenShape","updatesData","simpleAbsImpl","abs","absConfig","kernelName","Abs","backendName","kernelFunc","args","inputs","cpuBackend","backend","complexVals","realVals","imagVals","hypot","createSimpleBinaryKernelImpl","aShape","bShape","resultRank","resultStrides","computeStrides","resultSize","getTypedArrayFromDType","aRank","bRank","aStrides","bStrides","complex","complexInfo","makeTensorInfo","complexConfig","Complex","identity","incRef","identityConfig","Identity","input","realVal","realConfig","Real","cast","attrs","zerosTensor","floatX","dispose","disposeIntermediateTensorInfo","realPart","hasEncodingLoss","Int32Array","from","zero","toTypedArray","resultData","castConfig","Cast","binaryKernelFunc","name","simpleImpl","complexImpl","$dtype","$aComplex","$aComplexVals","aReal","aImag","aRealVals","aImagVals","$bComplex","$bComplexVals","bReal","bImag","bRealVals","bImagVals","resultRealData","resultImagData","resultReal","resultImag","createComplexBinaryKernelImpl","resultRealVals","resultImagVals","aIdx","bIdx","opResult","addImpl","addComplexImpl","add","Add","addConfig","createSimpleUnaryImpl","unaryKernelFunc","xSize","unaryKernelFuncFromImpl","unaryImpl","ceilImpl","xi","Ceil","ceilConfig","expImpl","exp","Exp","expConfig","expm1Impl","expm1","Expm1","expm1Config","floorImpl","Floor","floorConfig","logImpl","log","Log","logConfig","maxImpl","multiplyImpl","multiplyComplexImpl","multiply","Multiply","multiplyConfig","notEqualImpl","notEqual","NotEqual","notEqualConfig","rsqrtImpl","sqrt","rsqrt","Rsqrt","rsqrtConfig","sliceImpl","isContinous","isSliceContinous","xStrides","flatOffset","computeFlatOffset","subarray","outVals","xLoc","xIndex","$begin","$size","parseSliceParams","assertParamsValid","sliceConfig","Slice","squaredDifferenceImpl","squaredDifference","SquaredDifference","squaredDifferenceConfig","subImpl","subComplexImpl","sub","Sub","subConfig","transposeImpl","xShape","perm","xRank","newStrides","uniqueImpl","$axis","uniqueElements","inputBuffer","uniqueIndices","is1DTensor","element","axisValues","m","n","join","undefined","uniqueIndex","Object","keys","outputTmpShape","outputBuffer","uniqueElementIndex","outputValues","elu","Elu","eluConfig","preluImpl","xValue","prelu","preluConfig","Prelu","relu","Relu","reluConfig","relu6","Relu6","relu6Config","applyActivation","activation","preluActivationWeights","$shape","inferFromImplicitShape","$xSize","reshapeConfig","Reshape","batchMatMul","transposeA","transposeB","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","outerDimsB","batchDimA","batchDimB","batchDimsCompatible","concat","b3dShape","a3d","b3d","sharedDim","leftDim","rightDim","batchDim","a3dValues","b3dValues","a3dStrides","b3dStrides","aBatch","aOuterStep","aInnerStep","bInnerStep","bOuterStep","bBatch","bi","i0","j0","k0","iBlock","jBlock","kBlock","batchOffsetA","batchOffsetB","batchMatMulConfig","BatchMatMul","_fusedMatMulConfig","_FusedMatMul","current","addRes","activationRes","intermediates","acos","Acos","acosConfig","acosh","Acosh","acoshConfig","asin","Asin","asinConfig","asinh","Asinh","asinhConfig","atan","Atan","atanConfig","atanh","Atanh","atanhConfig","pool","yR","xRCorner","xRMin","xRMax","yC","xCCorner","xCMin","xCMax","xR","xROffset","xC","maxPoolPositions","flattenPositions","includeBatchInIndex","wR","wC","avgPoolConfig","AvgPool","filterSize","pad","dimRoundingMode","eitherStridesOrDilationsAreOne","computePool2DInfo","arraysEqual","inShape","avgPoolBackpropConfig","AvgPoolBackprop","dyData","dyRCorner","dyCCorner","batchNormConfig","FusedBatchNorm","scale","mean","variance","varianceEpsilon","mVals","varVals","sVals","offVals","offValsLength","sValsLength","varValsLength","mValsLength","offi","mi","si","vi","clip","ClipByValue","clipAttrs","clipValueMax","clipValueMin","clipConfig","imagVal","imagConfig","Imag","$inputs","filter","shapes","assertParamsConsistent","reals","imags","realConcated","imagConcated","inputs2D","innerSize","tVals","tIdx","row","resIdx","col","finalOutShape","outInfo","concatConfig","Concat","conv2D","dilations","$dataFormat","convertConv2DDataFormat","computeConv2DInfo","isChannelsLast","filterStrides","xBatchStride","xRowStride","xColStride","xChannelStride","yBatchStride","yRowStride","yColStride","yChannelStride","wVals","yVals","xOffset1","yOffset1","yOffset2","wOffset1","xOffset2","yOffset3","xOffset3","wOffset3","d1","xVal","d2","outChannels","conv2DConfig","Conv2D","conv2DBackpropFilterConfig","Conv2DBackpropFilter","filterShape","dW","leftPad","topPad","dyVals","yRMin","yRMax","yCMin","yCMax","conv2DBackpropInputConfig","Conv2DBackpropInput","inputShape","dyStrides","dxValues","fltValues","fltS0","fltS1","fltS2","dyOffset","fltOffset","conv3DConfig","Conv3D","computeConv3DInfo","yF","xFCorner","wF","xF","wOffset2","yOffset4","xOffset4","wOffset4","conv3DBackpropFilterV2Config","Conv3DBackpropFilterV2","dw","dwValues","dwS0","dwS1","dwS2","dwS3","dyS0","dyS1","dyS2","dyS3","xS0","xS1","xS2","xS3","frontPad","yFMin","yFMax","conv3DBackpropInputV2Config","Conv3DBackpropInputV2","dxS0","dxS1","dxS2","dxS3","fltS3","xFMin","cos","Cos","cosConfig","cosh","Cosh","coshConfig","depthwiseConv2dNative","$dilations","chMul","q","depthwiseConv2dNativeConfig","DepthwiseConv2dNative","depthwiseConv2dNativeBackpropFilterConfig","DepthwiseConv2dNativeBackpropFilter","trunc","dm","depthwiseConv2dNativeBackpropInputConfig","DepthwiseConv2dNativeBackpropInput","dilation2dConfig","Dilation2D","filterVals","filterRank","computeDilation2DInfo","outSize","outRank","hOut","hBeg","wOut","wBeg","curVal","MIN_SAFE_INTEGER","hIn","wIn","filterIndex","dilation2dBackpropFilterConfig","Dilation2DBackpropFilter","$x","toNestedArray","$filter","$dy","gradients","makeZerosNestedTypedArray","hMax","wMax","dilation2dBackpropInputConfig","Dilation2DBackpropInput","hInMax","wInMax","divImpl","div","Div","divConfig","p","ERF_P","a1","ERF_A1","a2","ERF_A2","a3","ERF_A3","a4","ERF_A4","a5","ERF_A5","erf","Erf","sign","erfConfig","fftBatch","inverse","innerDim","inputVals","real2D","imag2D","fftImpl","getComplexWithIndex","$realInfo","$imagInfo","inputSize","fftRadix2","half","evenComplex","complexWithEvenIndex","evenRealVals","evenImagVals","evenShape","evenRealInfo","evenImagInfo","evenTensorInfo","oddComplex","complexWithOddIndex","oddRealVals","oddImagVals","oddShape","oddRealInfo","oddImagInfo","oddTensorInfo","$evenComplex","$evenRealVals","$evenImagVals","$evenShape","$evenRealInfo","$evenImagInfo","$evenTensorInfo","$oddComplex","$oddRealVals","$oddImagVals","$oddShape","$oddRealInfo","$oddImagInfo","$oddTensorInfo","e","exponents","eShape","eRealInfo","eImagInfo","exponentInfo","addPart","subPart","addPartReal","subPartReal","addPartImag","subPartImag","$real","$imag","$realVals","$imagVals","realInfo","imagInfo","sizeInfo","createScalarValue","sizeInfoCopy","divRealInfo","divImagInfo","divRealVals","divImagVals","rawOutput","ret","exponent","term","assignToTypedArray","fourierTransformByMatmul","splitRealAndImagArrays","fftConfig","FFT","innerDimensionSize","input2D","resultReshaped","fillConfig","Fill","inferDtype","fillValues","flipLeftRightConfig","FlipLeftRight","image","batchIdx","coordX","outIdx","outputValue","fusedConv2DConfig","FusedConv2D","resultOld","fusedDepthwiseConv2DConfig","FusedDepthwiseConv2D","oldResult","ifftConfig","IFFT","isFinite","IsFinite","isFiniteConfig","isInf","IsInf","Infinity","isInfConfig","IsNan","isNaNConfig","log1p","Log1p","log1pConfig","logicalNot","LogicalNot","logicalNotConfig","maxConfig","Max","reductionIndices","keepDims","origAxes","permutedAxes","getAxesPermutation","getInnerMostAxes","maxOutShape","maxPoolConfig","MaxPool","maxPoolBackpropConfig","MaxPoolBackprop","maxPoolWithArgmaxConfig","MaxPoolWithArgmax","pooled","indexes","maxPools","maxPoolWithArgmaxImpl","pooledDataId","indexesDataId","mirrorPadConfig","MirrorPad","paddings","mode","coords","inIndex","nonMaxSuppressionV4Impl","nonMaxSuppressionV4Config","NonMaxSuppressionV4","padToMaxOutputSize","selectedIndices","validOutputs","nonMaxSuppressionV5Impl","nonMaxSuppressionV5Config","NonMaxSuppressionV5","softNmsSigma","maxOutputSizeVal","iouThresholdVal","scoreThresholdVal","softNmsSigmaVal","selectedScores","padV2Config","PadV2","constantValue","outCoords","reciprocal","Reciprocal","reciprocalConfig","rotateWithOffsetConfig","RotateWithOffset","radians","fillValue","center","centerX","centerY","getImageCenter","sinFactor","sin","cosFactor","coordY","Round","base","roundConfig","scaleAlpha","SELU_SCALEALPHA","SELU_SCALE","selu","Selu","seluConfig","sigmoid","Sigmoid","sigmoidConfig","Sign","signConfig","Sin","sinConfig","sinh","Sinh","sinhConfig","threshold","softplus","Softplus","tooLarge","tooSmall","expX","softplusConfig","transpose","transposeConfig","Transpose","spaceToBatchNDConfig","SpaceToBatchND","completePaddings","paddedX","reshapedPaddedShape","permutedReshapedPaddedPermutation","paddedXReshaped","paddedXT","Sqrt","sqrtConfig","squareConfig","Square","step","Step","stepAttrs","NaN","stepConfig","tan","Tan","tanConfig","tanh","Tanh","tanhConfig","uniqueConfig","Unique","kernelConfigs","kernelConfig","registerKernel"],"mappings":";;;;;;;;;;;;;;;;iUAmBgBA,EACZC,EAAiCC,GAC9BC,MAAMC,QAAQH,KACjBA,EAAS,CAACA,IAEZA,EAAOI,QAAQC,IACJ,MAALA,GACFC,OAAKC,OACW,cAAZF,EAAEG,MACF,IAAM,GACFP,8DCTd,MAAMQ,EAA0BC,eAAaD,wBACvCE,EAAQD,eAAaC,MACrBC,EAAOF,eAAaE,KACpBC,EAAWH,eAAaG,SACxBC,EAAYJ,eAAaI,gBAkBlBC,UAAuBC,gBAMlCC,cACEC,QANKC,eAAY,GAGXA,eAAW,EAIjBA,KAAKC,KAAO,IAAIC,cAAYF,KAAMG,YAGpCL,MAAMM,EAAoCC,EAAiBhB,GAErDW,KAAKM,WACPN,KAAKM,UAAW,EACZC,QAAMC,IAAI,YACZC,eAAaC,KACT,4dAYR,MAAMC,EAAS,GAIf,OAFAX,KAAKC,KAAKW,IAAID,EAAQ,CAACP,OAAAA,EAAQf,MAAAA,EAAOwB,SAAU,IAEzCF,EASTb,eACIO,EAAiBhB,EACjBe,GACF,IAAIU,EACJ,GAAc,WAAVzB,GAAgC,MAAVe,GAAkBA,EAAOW,OAAS,GACxD5B,OAAK6B,SAASZ,EAAO,IAAK,CAC5B,MAAMa,EACDb,EAA0Bc,IAAIC,GAAKhC,OAAKiC,aAAaD,IAE1DL,EAAQd,KAAKqB,MAAMJ,EAAeZ,EAAOhB,QAEzCyB,EAAQd,KAAKqB,MAAMjB,EAAsBC,EAAOhB,GAGlD,MAAO,CAACsB,OAAQG,EAAOT,MAAAA,EAAOhB,MAAAA,GAIhCS,OAAOa,GACcX,KAAKC,KAAKO,IAAIG,GACtBE,WAIbf,OAAOa,GACL,GAAIX,KAAKC,KAAKqB,IAAIX,GAAS,CACNX,KAAKC,KAAKO,IAAIG,GACtBE,YAIff,KACIa,EAAgBP,EAAoCC,EACpDhB,GACFW,KAAKC,KAAKW,IAAID,EAAQ,CAACP,OAAAA,EAAQf,MAAAA,EAAOwB,SAAU,IAGlDf,aACE,OAAOE,KAAKC,KAAKsB,aAGnBzB,WAAWa,GACT,OAAOX,KAAKwB,SAASb,GAEvBb,SAASa,GACP,MAAMtB,MAACA,EAAKoC,mBAAEA,GAAsBzB,KAAKC,KAAKO,IAAIG,GAElD,GAAc,cAAVtB,EAAuB,CACzB,MAAMqC,EACF1B,KAAKwB,SAASC,EAAmBE,KAAKhB,QACpCiB,EACF5B,KAAKwB,SAASC,EAAmBI,KAAKlB,QAC1C,OAAOF,eAAaqB,uBAAuBJ,EAAYE,GAGzD,OAAO5B,KAAKC,KAAKO,IAAIG,GAAQP,OAGvBN,WAA2BZ,GACjC,MAAMe,EAAOD,KAAKwB,SAAStC,EAAEyB,QAC7B,IAAIoB,EAAc9B,EAClB,GAAgB,WAAZf,EAAEG,MACJ,IAEE0C,EAAe9B,EAAsBiB,IAAIC,GAAKhC,OAAK6C,aAAab,IAChE,SACA,MAAM,IAAIc,MAAM,oDAGpB,OAAOC,SAAUhD,EAAEmB,MAAOnB,EAAEG,MAAO0C,GAGrCjC,WACIM,EAAoCC,EAAiBhB,GACvD,MAAMsB,EAASX,KAAKqB,MAAMjB,EAAQC,EAAOhB,GACzC,OAAOc,WAASgC,qBAAqBxB,EAAQN,EAAOhB,EAAOW,MAG7DF,YAAYa,GACV,GAAIX,KAAKC,KAAKqB,IAAIX,GAAS,CACzB,MAAMc,mBAACA,GAAsBzB,KAAKC,KAAKO,IAAIG,GAEjB,MAAtBc,IACFzB,KAAKoC,YAAYX,EAAmBE,KAAKhB,QACzCX,KAAKoC,YAAYX,EAAmBI,KAAKlB,SAG3CX,KAAKC,KAAKoC,OAAO1B,IAIrBb,8BAA8BwC,GAC5B,MAAM3B,EAAS2B,EAAW3B,OAE1B,GAAIX,KAAKC,KAAKqB,IAAIX,GAAS,CACzB,MAAM4B,EAAavC,KAAKC,KAAKO,IAAIG,GAEjC4B,EAAW1B,WAEP0B,EAAW1B,SAAW,GACxBb,KAAKoC,YAAYzB,IAKvBb,WAAW0C,GACT,MAAMC,EAAQtD,OAAKuD,MAGnB,OAFAF,IAEO,CAACG,SADSxD,OAAKuD,MAAQD,GAIhC3C,SACE,MAAO,CAEL8C,YAAY,EACZC,QACI,CAAC,uHAKT/C,aACIgD,EAAMC,EAAiBC,EAAeC,GACxCrE,EAAiBkE,EAAG,gBAEpB,MAAMI,EAAWC,aAAWC,gBAAgBL,EAAOC,EAAKC,GAExD,GAAIC,EAASG,KAAKC,GAAiB,IAATA,GACxB,OAAOC,SAAU,GAAIL,GAGvB,MAAMM,EAAStB,SAAUgB,EAAUJ,EAAEzD,OAC/BoE,EAAOzD,KAAK0D,WAAWZ,GAC7B,IAAK,IAAIa,EAAI,EAAGA,EAAIH,EAAOI,KAAMD,IAAK,CACpC,MAAME,EAAML,EAAOM,WAAWH,GAExBI,EAAmB,IAAIhF,MAAM8E,EAAI9C,QACvC,IAAK,IAAIiD,EAAI,EAAGA,EAAID,EAAOhD,OAAQiD,IACjCD,EAAOC,GAAKH,EAAIG,GAAKf,EAAQe,GAAKjB,EAAMiB,GAE1CR,EAAO5C,IAAI6C,EAAKjD,OAAOuD,MAAYF,GAGrC,OAAOL,EAAOS,WAGhBnE,KAAKgD,GACH,MAAMoB,EAAQlE,KAAKwB,SAASsB,EAAEnC,QACxB6C,EAAStB,SAAU,CAACY,EAAEc,KAAMd,EAAEc,MAAOd,EAAEzD,OACvC8E,EAAOX,EAAOpD,OACpB,IAAK,IAAIuD,EAAI,EAAGA,EAAIO,EAAMnD,OAAQ4C,IAChCQ,EAAKR,EAAIb,EAAEc,KAAOD,GAAKO,EAAMP,GAE/B,OAAOH,EAAOS,WAGhBnE,QAAQgD,EAAWQ,GACjB,MAAMc,EAAMtB,EAAEzC,MAAMiD,GACdJ,EAAqB,IAAInE,MAAM+D,EAAEuB,KAAO,GAC9C,IAAIC,EAAW,EACf,IAAK,IAAIX,EAAI,EAAGA,EAAIb,EAAEuB,KAAMV,IACtBA,IAAML,IACRJ,EAASoB,KAAcxB,EAAEzC,MAAMsD,IAInC,MAAMZ,EAAQ,IAAIhE,MAAM+D,EAAEuB,MAAME,KAAK,GAC/BX,EAAOd,EAAEzC,MAAMmE,QACrBZ,EAAKN,GAAQ,EACb,MAAMmB,EAAM,IAAI1F,MAAMqF,GACtB,IAAK,IAAIT,EAAI,EAAGA,EAAIc,EAAI1D,OAAQ4C,IAC9BZ,EAAMO,GAAQK,EACdc,EAAId,GAAKe,QAAS5B,EAAGC,EAAOa,GAAMe,QAAQzB,GAE5C,OAAOuB,EAGT3E,QAA0BgD,EAAMQ,GAC9B1E,EAAiBkE,EAAG,WAEpB,MAAMU,EAAStB,SAAUY,EAAEzC,MAAOyC,EAAEzD,OAC9BoE,EAAOzD,KAAK0D,WAAWZ,GAE7B,IAAK,IAAIa,EAAI,EAAGA,EAAIH,EAAOI,KAAMD,IAAK,CACpC,MAAMiB,EAASpB,EAAOM,WAAWH,GAC3BkB,EAAQD,EAAOJ,QACrBlB,EAAKrE,QAAQ6F,GAAMD,EAAMC,GAAMhC,EAAEzC,MAAMyE,GAAM,EAAID,EAAMC,IACvDtB,EAAO5C,IAAI6C,EAAKjD,OAAOqE,MAAWD,GAGpC,OAAOpB,EAAOS,WAGhBnE,IAAsBgD,GAIpB,OAHAlE,EAAiBkE,EAAG,OAGbiC,MAAOC,UAAW,GAAIlC,GAG/BhD,KAAuBmF,GACrBrG,EAAiBqG,EAAS,QAE1B,MAAMd,EAAOc,EAAQ/D,IAAIhC,GAAKc,KAAKwB,SAAStC,EAAEyB,SACxCuE,EAAShD,SAAU+C,EAAQ,GAAG5E,MAAO4E,EAAQ,GAAG5F,OAChD8F,EAAaD,EAAO9E,OAC1B,IAAK,IAAIuD,EAAI,EAAGA,EAAIsB,EAAQlE,OAAQ4C,IAAK,CACvC,MAAMyB,EAAWjB,EAAKR,GACtB,IAAK,IAAIK,EAAI,EAAGA,EAAImB,EAAWpE,OAAQiD,IACrCmB,EAAWnB,IAAMoB,EAASpB,GAG9B,OAAOkB,EAAOjB,WAGhBnE,QAA0BuF,EAAWC,GACnC,MAAMC,EAAOpG,OAAKqG,eAAe,CAACF,GAAMD,EAAOhF,OAGzCoF,EAAWC,MAAIL,EAAQE,GACvBI,EACFlF,eAAamF,qBAAqBH,EAASpF,MAAOkF,GAGhDM,EAAIC,MAAOT,EAAQI,EAASd,QAAQgB,IACpCI,EAAIC,MAAOH,GACXI,EAASjG,KAAKkG,IAAIH,EAAGR,GAAMZ,QAAQgB,GAIzC,OAAOQ,MAAOJ,EAAGE,GAGnBnG,IAAsB+F,EAAME,GAG1B,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,OAElB/F,KAAKoG,oBACDP,EAAGE,EAAGF,EAAExG,MAAO,CAACgH,EAAQC,IAAWC,KAAKC,IAAIH,EAAQC,IAIjExG,SAAS+F,EAAWE,GAClBnH,EAAiB,CAACiH,EAAGE,GAAI,YAIzB,OAAO/F,KAAKoG,oBAAoBP,EAAGE,EADf,QADT,CAACF,EAAWE,IAAcQ,KAAKE,MAAMZ,EAAIE,IAKtDjG,IAAIgD,EAAWyC,GACb3G,EAAiBkE,EAAG,OAEpBrC,eAAaiG,2BAA2B,MAAOnB,EAAMzC,EAAEuB,MACvD,MAAOnB,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CsB,EAAcC,aAAWhE,EAAEzD,MAAO,SAClC6F,EAAS6B,QAAS7D,EAAU2D,GAC5BG,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAId,EAAM,EACV,IAAK,IAAIlC,EAAI,EAAGA,EAAIgD,IAAchD,EAChCkC,GAAOgB,EAAMC,EAASnD,GAExBG,EAAKR,GAAKuC,EAEZ,OAAOhB,EAGTpF,KAAKgD,EAAWyC,GACd3G,EAAiBkE,EAAG,OAEpB,MAAOI,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CsB,EAAcC,aAAWhE,EAAEzD,MAAO,SAClC6F,EAAS6B,QAAS7D,EAAU2D,GAC5BG,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAII,EAAO,EACX,IAAK,IAAIpD,EAAI,EAAGA,EAAIgD,IAAchD,EAChCoD,GAAQF,EAAMC,EAASnD,GAEzBG,EAAKR,GAAKyD,EAEZ,OAAOlC,EAGTpF,mBACIgD,EAAMuE,EAAsBC,GAC9B1I,EAAiBkE,EAAG,sBAEpB,MAAM2B,EAAM,GAIN8C,EAAWzE,EAAEuB,KAAOgD,EAAWhD,KACrC,IAAK,IAAIV,EAAI,EAAGA,EAAI4D,IAAY5D,EAC9B0D,EAAaA,EAAWG,WAAW7D,EAAI,GAGzC,IAAK,IAAIA,EAAI,EAAGA,EAAI2D,IAAe3D,EAAG,CACpC,MAAM8D,EAAYzC,SAAUrB,EAAG,SAEzBuC,EADOwB,QAASD,EAAWJ,GAAYM,OAAO,WACnCC,IAAI9E,GAAGoD,IAAI,GAC5BzB,EAAIoD,KAAK3B,GAGX,OAAO4B,QAASrD,GAGlB3E,OAAOgD,EAAWQ,GAChB1E,EAAiBkE,EAAG,UAEpB,MAAMyC,EAAO,CAACjC,GACd7C,eAAaiG,2BAA2B,SAAUnB,EAAMzC,EAAEuB,MAC1D,MAAOnB,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CL,EAAS6B,QAAS7D,EAAU,SAC5B8D,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAIe,EAAMb,EAAMC,GACZa,EAAW,EACf,IAAK,IAAIhE,EAAI,EAAGA,EAAIgD,IAAchD,EAAG,CACnC,MAAMiE,EAAQf,EAAMC,EAASnD,GACzBiE,EAAQF,IACVA,EAAME,EACND,EAAWhE,GAGfG,EAAKR,GAAKqE,EAEZ,OAAO9C,EAGTpF,OAAOgD,EAAWQ,GAChB1E,EAAiBkE,EAAG,UAEpB,MAAMyC,EAAO,CAACjC,GACd7C,eAAaiG,2BAA2B,SAAUnB,EAAMzC,EAAEuB,MAC1D,MAAOnB,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CL,EAAS6B,QAAS7D,EAAU,SAC5B8D,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAItB,EAAMwB,EAAMC,GACZe,EAAW,EACf,IAAK,IAAIlE,EAAI,EAAGA,EAAIgD,IAAchD,EAAG,CACnC,MAAMiE,EAAQf,EAAMC,EAASnD,GACzBiE,EAAQvC,IACVA,EAAMuC,EACNC,EAAWlE,GAGfG,EAAKR,GAAKuE,EAEZ,OAAOhD,EAGTpF,OAAOgD,EAAWQ,EAAc6E,EAAoBC,GAIlD,GAFAxJ,EAAiBkE,EAAG,UAEhBQ,IAASR,EAAEuB,KAAO,EACpB,MAAM,IAAIpC,MACN,oDAAoDa,EAAEuB,KAAO,KAC7D,gBAAgBf,KAEtB,MAAMuD,EAAcC,aAAWhE,EAAEzD,MAAO,SAClC6F,EAAS6B,QAASjE,EAAEzC,MAAOwG,GAC3B1C,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QACxB0H,EAAWvF,EAAEzC,MAAMyC,EAAEuB,KAAO,GAC5BiE,EAAgBF,EAClB,CAACzE,EAAWK,IAAcL,EAAI0E,EAAWrE,EAAI,EAC7C,CAACL,EAAWK,IAAcL,EAAIK,EAClC,IAAK,IAAIL,EAAI,EAAGA,EAAIuD,EAAMnG,OAAQ4C,GAAK0E,EACrC,IAAK,IAAIrE,EAAI,EAAGA,EAAIqE,EAAUrE,IAAK,CACjC,MAAMuE,EAAMD,EAAc3E,EAAGK,GAC7B,GAAU,IAANA,EACFG,EAAKoE,GAAOJ,EAAY,EAAIjB,EAAMqB,OAC7B,CACL,MAAMC,EAAUF,EAAc3E,EAAGK,EAAI,GACrCG,EAAKoE,GAAOJ,EAAYjB,EAAMsB,GAAWrE,EAAKqE,GACtBtB,EAAMqB,GAAOpE,EAAKqE,IAIhD,OAAOtD,EAGTpF,MAAM+F,EAAWE,GAGf,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,SAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC3CD,IAASC,EAAQ,EAAI,GAIjC5I,SAAS+F,EAAWE,GAGlB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,YAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC3CD,IAASC,EAAQ,EAAI,GAIjC5I,KAAK+F,EAAWE,GAGd,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,QAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC3CD,EAAOC,EAAQ,EAAI,GAI/B5I,UAAU+F,EAAWE,GAGnB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,aAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC3CD,GAAQC,EAAQ,EAAI,GAIhC5I,QAAQ+F,EAAWE,GAGjB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,WAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC3CD,EAAOC,EAAQ,EAAI,GAI/B5I,aAAa+F,EAAWE,GAGtB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,gBAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC3CD,GAAQC,EAAQ,EAAI,GAIhC5I,WAAW+F,EAAWE,GAGpB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,cAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC5CD,GAAQC,GAInB5I,UAAU+F,EAAWE,GAGnB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,aAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAG,OAAQ,CAAC0C,EAAMC,IAC5CD,GAAQC,GAInB5I,OAAO6I,EAAmB9C,EAAWE,GACnCnH,EAAiB,CAAC+J,EAAW9C,EAAGE,GAAI,UAEpC,MAAM3F,EAASJ,KAAKwB,SAASmH,EAAUhI,QACjCiI,EAAU5I,KAAKwB,SAASqE,EAAElF,QAC1BkI,EAAU7I,KAAKwB,SAASuE,EAAEpF,QAC1BuE,EAAS6B,QAASlB,EAAExF,MAAOyG,aAAWjB,EAAExG,MAAO0G,EAAE1G,QACjDyJ,EAAY9I,KAAKwB,SAAS0D,EAAOvE,QACvC,IAAIoI,EAAQ,EACZ,MAAM5B,EAA4B,IAAnBwB,EAAUtE,MAAcsE,EAAUtE,KAAO,GAAgB,IAAXwB,EAAExB,KAC3D,EACAlF,OAAK8H,cAAcpB,EAAExF,MAAMmE,MAAM,IAErC,IAAK,IAAIb,EAAI,EAAGA,EAAIvD,EAAOW,OAAQ4C,IACjC,IAAK,IAAIK,EAAI,EAAGA,EAAImD,EAAQnD,IACR,IAAd5D,EAAOuD,GACTmF,EAAUC,KAAWH,EAAQjF,GAE7BmF,EAAUC,KAAWF,EAAQlF,GAKnC,OAAOuB,EAGTpF,MAAM6I,GACJ/J,EAAiB,CAAC+J,GAAY,SAE9B,MAAMK,EAAWhJ,KAAKwB,SAASmH,EAAUhI,QACzC,OAAOhB,EAAUgJ,EAAUtI,MAAO2I,GAGpClJ,KAAuBgD,EAAMmG,EAAWC,GACtCtK,EAAiBkE,EAAG,QAEpB,MAAMoB,EAAQlE,KAAKwB,SAASsB,EAAEnC,QAC9B,OAAOjB,EAASwE,EAAOpB,EAAEzC,MAAOyC,EAAEzD,MAA0B4J,EAAGC,GAGjEpJ,IAAIgD,EAAWyC,GACb3G,EAAiBkE,EAAG,OAEpBrC,eAAaiG,2BAA2B,MAAOnB,EAAMzC,EAAEuB,MACvD,MAAOnB,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CL,EAAS6B,QAAS7D,EAAUJ,EAAEzD,OAC9B2H,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAIe,EAAMb,EAAMC,GAChB,IAAK,IAAInD,EAAI,EAAGA,EAAIgD,IAAchD,EAAG,CACnC,MAAMiE,EAAQf,EAAMC,EAASnD,GACzBiE,EAAQF,IACVA,EAAME,GAGV9D,EAAKR,GAAKoE,EAEZ,OAAO7C,EAGTpF,QAAQ+F,EAAWE,GAGjB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,WAElB/F,KAAKoG,oBACRP,EAAGE,EAAGF,EAAExG,MAAO,CAACoJ,EAAMC,IAASnC,KAAKwB,IAAIU,EAAMC,IAGpD5I,IAAI+F,EAAWE,GAGb,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,OAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAGF,EAAExG,MAAO,CAACoJ,EAAMC,KACpD,MAAMS,EAAMV,EAAOC,EACnB,OAAKD,EAAO,GAAKC,EAAO,GAAOD,GAAQ,GAAKC,GAAQ,EAC3CS,GAECA,EAAMT,GAAQA,IAK5B5I,QAAQ+F,EAAWE,GAGjB,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,WAElB/F,KAAKoG,oBACRP,EAAGE,EAAGF,EAAExG,MAAO,CAACoJ,EAAMC,IAASnC,KAAKb,IAAI+C,EAAMC,IAGpD5I,IAAIgD,EAAWyC,GACb3G,EAAiBkE,EAAG,OAEpBrC,eAAaiG,2BAA2B,MAAOnB,EAAMzC,EAAEuB,MACvD,MAAOnB,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CL,EAAS6B,QAAS7D,EAAUJ,EAAEzD,OAC9B2H,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAIoC,EAAMlC,EAAMC,GAChB,IAAK,IAAInD,EAAI,EAAGA,EAAIgD,IAAchD,EAAG,CACnC,MAAMiE,EAAQf,EAAMC,EAASnD,GAC7BoF,EAAMA,GAAOnB,EAEf9D,EAAKR,GAAKyF,EAEZ,OAAOlE,EAGTpF,IAAIgD,EAAWyC,GACb3G,EAAiBkE,EAAG,OAEpBrC,eAAaiG,2BAA2B,MAAOnB,EAAMzC,EAAEuB,MACvD,MAAOnB,EAAUyD,GACblG,eAAamG,0BAA0B9D,EAAEzC,MAAOkF,GAC9CL,EAAS6B,QAAS7D,EAAUJ,EAAEzD,OAC9B2H,EAAa7H,OAAK8H,cAAcN,GAChCxC,EAAOnE,KAAKwB,SAAS0D,EAAOvE,QAE5BuG,EAAQlH,KAAKwB,SAASsB,EAAEnC,QAC9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAIqC,EAASnC,EAAMC,GACnB,IAAK,IAAInD,EAAI,EAAGA,EAAIgD,IAAchD,EAAG,CACnC,MAAMiE,EAAQf,EAAMC,EAASnD,GAC7BqF,EAASA,GAAUpB,EAErB9D,EAAKR,GAAK0F,EAEZ,OAAOnE,EAGTpF,kBAAkB+F,EAAWE,GAG3B,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,qBAElB/F,KAAKoG,oBAAoBP,EAAGE,EAAGF,EAAExG,MAAO,CAACoJ,EAAMC,KACpD,MAAMY,EAAOb,EAAOC,EACpB,OAAOY,EAAOA,IAIlBxJ,OAAyByJ,EAAOC,GAC9B5K,EAAiB,CAAC2K,EAAIC,GAAI,UAE1B,MAAMC,EAAe,IAAIC,aAAaF,EAAE5F,MAClCxD,EAASJ,KAAKwB,SAASgI,EAAE7I,QACzBgJ,EAAW3J,KAAKwB,SAAS+H,EAAG5I,QAClC,IAAK,IAAIgD,EAAI,EAAGA,EAAIvD,EAAOW,SAAU4C,EAAG,CACtC,MAAMiG,EAAIxJ,EAAOuD,GAEf8F,EAAa9F,GADXiG,GAAK,EACWD,EAAShG,GAETgG,EAAShG,IAAMiG,EAAI,GAGzC,OAAO5J,KAAK6J,WAAWJ,EAAcD,EAAEnJ,MAAO,WAGhDP,MAAwB+F,EAAME,GAG5B,OAFAnH,EAAiB,CAACiH,EAAGE,GAAI,SAElB/F,KAAKoG,oBACDP,EAAGE,EAAGF,EAAExG,MAAO,CAACgH,EAAQC,IAAWC,KAAKuD,MAAMzD,EAAQC,IAInExG,KAAuBgD,EAAMiH,GAE3B,OADAnL,EAAiBkE,EAAG,QACbrD,EAAKO,KAAK0D,WAAWZ,GAAIiH,GAGlCjK,OAAyBgD,EAAMkH,EAAmB1G,GAChD1E,EAAiB,CAACkE,EAAGkH,GAAU,UAE/B,MAAMC,EAAqBnH,EAAEzC,MAAMmE,QAC7B0F,EAAgBlK,KAAKwB,SAASwI,EAAQrJ,QAC5CsJ,EAAS3G,GAAQ4G,EAAcnJ,OAC/B,MAAMmE,EAAShD,SAAU+H,EAAUnH,EAAEzD,OAC/BoE,EAAOzD,KAAK0D,WAAWZ,GAE7B,IAAK,IAAIa,EAAI,EAAGA,EAAIuB,EAAOtB,OAAQD,EAAG,CACpC,MAAMI,EAASmB,EAAOpB,WAAWH,GAE3BwG,EAAwBpG,EAAOS,QACrC2F,EAAY7G,GAAQ4G,EAAcnG,EAAOT,IAEzC,MAAM8G,EAAgB3G,EAAK4G,WAAWF,GACtCjF,EAAO9E,OAAOuD,GAAKF,EAAKrD,OAAOgK,GAEjC,OAAOlF,EAAOjB,WAGhBnE,eACIgD,EAAMwH,EAAsBC,GAC9B3L,EAAiB,CAACkE,GAAI,kBAEtB,MAAMsE,EAAOkD,EAAWE,OAAO,CAAC3E,EAAGE,IAAMF,EAAIE,GAEvC0E,EAAWhK,eAAaiK,YAAY5H,EAAEzC,MAAOiK,EAAYlD,GACzDuD,EACFlK,eAAamK,YAAYH,EAAS1J,OAAQuJ,EAAWvJ,QACnD8J,EACFpK,eAAaqK,oBAAoBhI,EAAEzC,MAAOiK,EAAYlD,GACpD2D,EACFtK,eAAauK,oBAAoBT,EAAOD,EAAWvJ,QACjDkK,EACFxK,eAAayK,aAAaL,EAAkBN,EAAOD,EAAWvJ,QAElE,OAAOoK,YAAarI,EAAE6B,QAAQ8F,GAAWE,GAC7BhG,QAAQkG,GACRrG,MAAMuG,EAAkBE,GAG9BnL,OACJgD,EAAasI,EACbC,GACFzM,EAAiBkE,EAAG,UAEpB,MAAMwI,EAAcF,EAASE,YACvBC,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBC,EAAgBL,EAASK,cACzBC,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBC,EAAuBR,EAASQ,qBAChCC,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCC,EAAWX,EAASY,QAAQC,MAC5BC,EAASd,EAASY,QAAQG,IAC1BC,EAAUhB,EAASY,QAAQK,KAE3BC,EACY,QAAbjB,EAAqBkB,OAAOC,kBACPD,OAAOE,kBAE3BC,EAAU1M,KAAKwB,SAASsB,EAAEnC,QAC1BgM,EAASzK,SAAUkJ,EAASlI,SAAUJ,EAAEzD,OACxCuN,EAAaD,EAAOvM,OAEpByM,EAAqBzB,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAChEkI,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GACvC4J,EACF1B,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAC9D6J,EAAmB3B,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAC5D8J,EAAmB5B,EAASlI,SAAS,GAE3C,IAAK,IAAI+J,EAAQ,EAAGA,EAAQ7B,EAAS8B,YAAaD,EAAO,CACvD,MAAME,EAAoBF,EAAQJ,EAC5BO,EAAmBH,EAAQnK,EAAEG,QAAQ,GAC3C,IAAK,IAAIoK,EAAU,EAAGA,EAAUjC,EAASkC,aAAcD,EACrD,IAAK,IAAIE,EAAS,EAAGA,EAASnC,EAASoC,WAAYD,EAAQ,CACzD,MAAME,EAAeF,EAASjC,EAAcS,EAC5C,IAAI2B,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAajC,EAEf,MAAMkC,EACFpH,KAAKwB,IAAIqD,EAASwC,QAAShC,EAAuB6B,GAChDI,EACFV,EAAoBI,EAAST,EACjC,IAAK,IAAIgB,EAAO,EAAGA,EAAO1C,EAAS2C,YAAaD,EAAM,CACpD,MAAME,EAAaF,EAAOvC,EAAeW,EACzC,IAAI+B,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWvC,EAEb,MAAMwC,EACF3H,KAAKwB,IAAIqD,EAAS+C,SAAUtC,EAAwBmC,GAClDI,EAAkBP,EAAoBC,EAAOf,EACnD,IAAK,IAAIsB,EAAO,EAAGA,EAAOjD,EAASkD,WAAYD,EAAM,CACnD,MAAME,EAAaF,EAAO7C,EAAcY,EACxC,IAAIoC,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW7C,EAEb,MAAM8C,EACFlI,KAAKwB,IAAIqD,EAASsD,QAAS5C,EAAuByC,GAEhDI,EAAkBP,EAAkBC,EAAOrB,EACjD,IAAI4B,EAActC,EACduC,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAIC,EAASrB,EAAWqB,EAASpB,EACjCoB,GAAUtD,EAAe,CAC5B,MAAMuD,EAAe5B,EAAmB2B,EAASjM,EAAEG,QAAQ,GAC3D,IAAK,IAAIgM,EAAOhB,EAASgB,EAAOf,EAC3Be,GAAQvD,EAAgB,CAC3B,MAAMwD,EAAaF,EAAeC,EAAOnM,EAAEG,QAAQ,GACnD,IAAK,IAAIkM,EAAOX,EAASW,EAAOV,EAC3BU,GAAQxD,EAAe,CAC1B,MACMyD,EAAQ1C,EADKwC,EAAaC,EAAOrM,EAAEG,QAAQ,GACdoK,GAOnC,GANkB,QAAbhC,GAAsB+D,EAAQR,EACjCA,EAAcQ,EACQ,QAAb/D,IACTwD,GAAYO,EACZN,KAEEO,MAAMT,GACR,MAGJ,GAAIS,MAAMT,GACR,MAGJ,GAAIS,MAAMT,GACR,MAIJhC,EADqB+B,EAAkBtB,GAEtB,QAAbhC,EAAqBwD,EAAWC,EAAQF,KAMtD,OAAOjC,EAAO1I,WAGhBnE,UAAUgD,EAAasI,GAGrB,OAFAxM,EAAiBkE,EAAG,aAEb9C,KAAKsP,OAAOxM,EAAGsI,EAAU,OAAOmE,UAGzCzP,kBACIyJ,EAAczG,EAAasI,GAC7BxM,EAAiB,CAAC2K,EAAIzG,GAAI,qBAE1B,MAAMwI,EAAcF,EAASE,YACvBC,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBgE,EAAcpE,EAASoE,YACvBC,EAAerE,EAASqE,aACxBC,EAActE,EAASsE,YACvBjE,EAAgBL,EAASK,cACzBC,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBC,EAAuBR,EAASQ,qBAChCC,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCC,EAAWH,EAAuB,EAAIR,EAASY,QAAQC,MACvDG,EAAUN,EAAuB,EAAIV,EAASY,QAAQK,KACtDH,EAASL,EAAwB,EAAIT,EAASY,QAAQG,IACtDwD,EAAKzN,SAAmBY,EAAEzC,MAAO,WAEjCuP,EAAgB,GAAKJ,EAAcC,EAAeC,GAElDG,EAAQ7P,KAAK0D,WAAW6F,GAE9B,IAAK,IAAI0D,EAAQ,EAAGA,EAAQ7B,EAAS8B,YAAaD,EAChD,IAAK,IAAII,EAAU,EAAGA,EAAUjC,EAASkC,aAAcD,EACrD,IAAK,IAAIyC,EAAU,EAAGA,EAAU1E,EAASwC,UAAWkC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ3E,EAAS+C,WAAY4B,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ5E,EAASsD,UAAWsB,EAAO,CAErD,MAAMC,EAAgBH,EAAU/D,EAC1BmE,EAAcH,EAAQ7D,EACtBiE,EAAcH,EAAQ5D,EAC5B,IAAIgE,EAAU,EACd,IAAK,IAAIC,EAAS,EAAGA,EAASzE,EACzByE,GAAU5E,EAAe,CAC5B,MAAM6E,GAAWL,EAAgBI,GAAU/E,EAC3C,KAAIgF,EAAU,GAAKA,GAAWlF,EAASoC,UACnCjH,KAAKE,MAAM6J,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO1E,EACrB0E,GAAQ7E,EAAgB,CAC3B,MAAM8E,GAASN,EAAcK,GAAQhF,EACrC,KAAIiF,EAAQ,GAAKA,GAASpF,EAAS2C,WAC/BxH,KAAKE,MAAM+J,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO3E,EACrB2E,GAAQ9E,EAAe,CAC1B,MAAM+E,GAASP,EAAcM,GAAQjF,EACjCkF,EAAQ,GAAKA,GAAStF,EAASkD,UAC/B/H,KAAKE,MAAMiK,KAAWA,IAM1BN,GADIP,EAAMrP,IAAIyM,EAAOqD,EAASE,EAAOE,EAAOrD,MAKlDsC,EAAG/O,IACCwP,EAAUR,EAAe3C,EAAO6C,EAASC,EAAOC,EAChD3C,GAMd,OAAOsC,EAAG1L,WAGZnE,UAAUgD,EAAasI,GAGrB,OAFAxM,EAAiBkE,EAAG,aAEb9C,KAAKsP,OAAOxM,EAAGsI,EAAU,OAAOmE,UAGjCzP,mBAAmBgD,EAAasI,GAEtC,MAAMuF,EAAezO,SAAUkJ,EAASlI,SAAU,SAC5CoI,EAAcF,EAASE,YACvBC,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBC,EAAgBL,EAASK,cACzBC,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBC,EAAuBR,EAASQ,qBAChCC,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCC,EAAWX,EAASY,QAAQC,MAC5BC,EAASd,EAASY,QAAQG,IAC1BC,EAAUhB,EAASY,QAAQK,KAE3B5I,EAAOzD,KAAK0D,WAAWZ,GAC7B,IAAK,IAAImK,EAAQ,EAAGA,EAAQ7B,EAAS8B,YAAaD,EAChD,IAAK,IAAII,EAAU,EAAGA,EAAUjC,EAASkC,aAAcD,EACrD,IAAK,IAAIE,EAAS,EAAGA,EAASnC,EAASoC,WAAYD,EAAQ,CACzD,MAAME,EAAeF,EAASjC,EAAcS,EAC5C,IAAI2B,EAAYD,EAChB,KAAOC,EAAY,GACjBA,GAAajC,EAEf,MAAMkC,EACFpH,KAAKwB,IAAIqD,EAASwC,QAAShC,EAAuB6B,GACtD,IAAK,IAAIK,EAAO,EAAGA,EAAO1C,EAAS2C,YAAaD,EAAM,CACpD,MAAME,EAAaF,EAAOvC,EAAeW,EACzC,IAAI+B,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAWvC,EAEb,MAAMwC,EACF3H,KAAKwB,IAAIqD,EAAS+C,SAAUtC,EAAwBmC,GACxD,IAAK,IAAIK,EAAO,EAAGA,EAAOjD,EAASkD,WAAYD,EAAM,CACnD,MAAME,EAAaF,EAAO7C,EAAcY,EACxC,IAAIoC,EAAUD,EACd,KAAOC,EAAU,GACfA,GAAW7C,EAEb,MAAM8C,EACFlI,KAAKwB,IAAIqD,EAASsD,QAAS5C,EAAuByC,GAGtD,IAAIqC,EAAWrE,OAAOC,kBAClBqE,GAAe,EAEnB,IAAK,IAAI9B,EAASrB,EAAWqB,EAASpB,EACjCoB,GAAUtD,EAAe,CAC5B,MAAM4E,EAAStB,EAAStB,EACxB,IAAK,IAAIwB,EAAOhB,EAASgB,EAAOf,EAC3Be,GAAQvD,EAAgB,CAC3B,MAAM6E,EAAOtB,EAAOjB,EACpB,IAAK,IAAImB,EAAOX,EAASW,EAAOV,EAC3BU,GAAQxD,EAAe,CAC1B,MAAM8E,EAAOtB,EAAOZ,EACda,EAAQ3L,EAAKjD,IAAIyM,EAAO8B,EAAQE,EAAME,EAAM9B,GAC9C+B,GAASwB,IACXA,EAAWxB,EACXyB,EAAcR,EAASxE,EACfC,EACJyE,EAAO1E,EAAwB4E,KAM3CE,EAAa/P,IAAIiQ,EAAa5D,EAAOM,EAAQO,EAAMO,EAAMhB,KAMnE,OAAOsD,EAAa1M,WAGtBnE,kBACIyJ,EAAczG,EAAa0G,EAC3B4B,GACFxM,EAAiB,CAACkE,EAAG0G,GAAI,qBAEzB,MAAMmH,EAAe3Q,KAAK8Q,mBAAmBhO,EAAGsI,GAC1CE,EAAcF,EAASE,YACvBC,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBC,EAAgBL,EAASK,cACzBC,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBC,EAAuBR,EAASQ,qBAChCC,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCC,EAAWH,EAAuB,EAAIR,EAASY,QAAQC,MACvDG,EAAUN,EAAuB,EAAIV,EAASY,QAAQK,KACtDH,EAASL,EAAwB,EAAIT,EAASY,QAAQG,IACtDwD,EAAKzN,SAAmBY,EAAEzC,MAAO,WAEjC0Q,EAAY/Q,KAAK0D,WAAWiN,GAC5Bd,EAAQ7P,KAAK0D,WAAW6F,GAE9B,IAAK,IAAI0D,EAAQ,EAAGA,EAAQ7B,EAAS8B,YAAaD,EAChD,IAAK,IAAII,EAAU,EAAGA,EAAUjC,EAASkC,aAAcD,EACrD,IAAK,IAAIyC,EAAU,EAAGA,EAAU1E,EAASwC,UAAWkC,EAClD,IAAK,IAAIC,EAAQ,EAAGA,EAAQ3E,EAAS+C,WAAY4B,EAC/C,IAAK,IAAIC,EAAQ,EAAGA,EAAQ5E,EAASsD,UAAWsB,EAAO,CAErD,MAAMC,EAAgBH,EAAU/D,EAC1BmE,EAAcH,EAAQ7D,EACtBiE,EAAcH,EAAQ5D,EAC5B,IAAIgE,EAAU,EACd,IAAK,IAAIC,EAAS,EAAGA,EAASzE,EACzByE,GAAU5E,EAAe,CAC5B,MAAM6E,GAAWL,EAAgBI,GAAU/E,EAC3C,KAAIgF,EAAU,GAAKA,GAAWlF,EAASoC,UACnCjH,KAAKE,MAAM6J,KAAaA,GAG5B,IAAK,IAAIC,EAAO,EAAGA,EAAO1E,EACrB0E,GAAQ7E,EAAgB,CAC3B,MAAM8E,GAASN,EAAcK,GAAQhF,EACrC,KAAIiF,EAAQ,GAAKA,GAASpF,EAAS2C,WAC/BxH,KAAKE,MAAM+J,KAAWA,GAG1B,IAAK,IAAIC,EAAO,EAAGA,EAAO3E,EACrB2E,GAAQ9E,EAAe,CAC1B,MAAM+E,GAASP,EAAcM,GAAQjF,EACrC,GAAIkF,EAAQ,GAAKA,GAAStF,EAASkD,UAC/B/H,KAAKE,MAAMiK,KAAWA,EACxB,SAGF,MAQMM,EARSpF,EACPC,EAAwBC,EAC5B,EACAiF,EAAUvQ,IAAIyM,EAAOqD,EAASE,EAAOE,EAAOrD,KAE5CgD,EAASxE,EAAwBC,EACjCyE,EAAOzE,EAAuB2E,EAED,EAAI,EACxB,IAATO,IAMJZ,GADIP,EAAMrP,IAAIyM,EAAOqD,EAASE,EAAOE,EAAOrD,GACzB2D,KAIzBrB,EAAG/O,IAAIwP,EAASnD,EAAO6C,EAASC,EAAOC,EAAO3C,GAMxD,OAAOsC,EAAG1L,WAGZnE,eACIgD,EAAamO,EAAmBC,EAChCC,GACFvS,EAAiBkE,EAAG,kBAEpB,MAAOmK,EAAOmE,EAAWC,EAAUC,GAAexO,EAAEzC,MAC9CqM,EAAU1M,KAAKwB,SAASsB,EAAEnC,QAC1BuE,EAAS,IAAIwE,aACfvK,OAAK8H,cAAc,CAACgG,EAAOgE,EAAWC,EAAUI,KAE9CC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAElD,IAAIO,EAAY,EAChB,MAAMC,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAChD,IAAK,IAAIzL,EAAI,EAAGA,EAAIkH,EAAOlH,IACzB,IAAK,IAAI6L,EAAI,EAAGA,EAAIX,EAAWW,IAAK,CAClC,MAAMC,EAAgBH,EAAwBE,EACxCE,EAAiBvL,KAAKE,MAAMoL,GAC5BE,EAAUF,EAAgBC,EAC1BE,EAAgBzL,KAAKwB,IAAIqJ,EAAY,EAAG7K,KAAK0L,KAAKJ,IAClDK,EAAenM,EAAIjD,EAAEG,QAAQ,GAAK6O,EAAiBhP,EAAEG,QAAQ,GAC7DkP,EAAepM,EAAIjD,EAAEG,QAAQ,GAAK+O,EAAgBlP,EAAEG,QAAQ,GAClE,IAAK,IAAImP,EAAI,EAAGA,EAAIlB,EAAUkB,IAAK,CACjC,MAAMC,EAAgBV,EAAwBS,EACxCE,EAAiB/L,KAAKE,MAAM4L,GAC5BE,EAAUF,EAAgBC,EAC1BE,EACFjM,KAAKwB,IAAIsJ,EAAW,EAAG9K,KAAK0L,KAAKI,IAC/BI,EAAgBP,EAAeI,EAAiBxP,EAAEG,QAAQ,GAC1DyP,EAAgBP,EAAeG,EAAiBxP,EAAEG,QAAQ,GAC1D0P,EAAiBT,EAAeM,EAAgB1P,EAAEG,QAAQ,GAC1D2P,EAAiBT,EAAeK,EAAgB1P,EAAEG,QAAQ,GAChE,IAAK,IAAI9B,EAAI,EAAGA,EAAImQ,EAAanQ,IAAK,CAIpC,MAAM0R,EAAUnG,EAAQ+F,EAAgBtR,GAClC2R,EAAapG,EAAQgG,EAAgBvR,GAIrCgL,EAAM0G,GAHKnG,EAAQiG,EAAiBxR,GAGR0R,GAAWN,EAEvCQ,EAAW5G,GADF2G,GAHKpG,EAAQkG,EAAiBzR,GAGF2R,GAAcP,EACxBpG,GAAO4F,EAExC7M,EAAOuM,KAAesB,IAK9B,OAAOxP,SAAU2B,EAAQ,CAAC+H,EAAOgE,EAAWC,EAAUI,IAGxDxR,uBAAuByJ,EAAczG,EAAaqO,GAChDvS,EAAiB,CAAC2K,EAAIzG,GAAI,0BAE1B,MAAOmK,EAAO+F,EAASC,EAAQC,GAASpQ,EAAEzC,QACjC8S,EAASC,GAAU7J,EAAGlJ,MAEzBsM,EAAS,IAAIjD,aAAauD,EAAQ+F,EAAUC,EAASC,GAOrDG,EAAmC,CACtClC,GAAgBgC,EAAU,EAAKH,EAAU,EAAIA,EAC7C7B,GAAgBiC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtCnC,GAAgBgC,EAAU,EAAKA,EAAU,EAAIA,EAC7ChC,GAAgBiC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAMhD3J,EAAW3J,KAAKwB,SAAS+H,EAAG5I,QAClC,IAAIwG,EAAS,EACb,IAAK,IAAIpB,EAAI,EAAGA,EAAIkH,EAAOlH,IAAK,CAC9B,MAAM0N,EAAU1N,EAAIjD,EAAEG,QAAQ,GAC9B,IAAK,IAAI2O,EAAI,EAAGA,EAAIuB,EAASvB,IAAK,CAChC,MAAM8B,EAAM9B,EAAI2B,EACVI,EAAcpN,KAAKE,MAAMiN,GACzBE,EAAiBrN,KAAKwB,IAAIxB,KAAK0L,KAAKyB,GAAMV,EAAU,GAEpDa,EAAeJ,EAAUE,EAAc7Q,EAAEG,QAAQ,GACjD6Q,EAAkBL,EAAUG,EAAiB9Q,EAAEG,QAAQ,GAEvD8Q,EAAUL,EAAMC,EAChBK,EAAiB,EAAMD,EAC7B,IAAK,IAAI3B,EAAI,EAAGA,EAAIgB,EAAQhB,IAAK,CAC/B,MAAM6B,EAAM7B,EAAIoB,EACVU,EAAe3N,KAAKE,MAAMwN,GAC1BE,EAAgB5N,KAAKwB,IAAIxB,KAAK0L,KAAKgC,GAAMhB,EAAS,GAClDmB,EAAUH,EAAMC,EAChBG,EAAiB,EAAMD,EAEvBE,EAAkBT,EAAeK,EAAepR,EAAEG,QAAQ,GAC1DsR,EAAmBV,EAAeM,EAAgBrR,EAAEG,QAAQ,GAC5DuR,EACFV,EAAkBI,EAAepR,EAAEG,QAAQ,GACzCwR,EACFX,EAAkBK,EAAgBrR,EAAEG,QAAQ,GAE1CyR,EACFV,EAAiBK,EACfM,EAA6BX,EAAiBI,EAC9CQ,EAA6Bb,EAAUM,EACvCQ,EAAsBd,EAAUK,EACtC,IAAK,IAAIjT,EAAI,EAAGA,EAAI+R,EAAO/R,IAAK,CAC9B,MAAM2T,EAAQnL,EAASxC,KACvBwF,EAAO2H,EAAkBnT,IACrB2T,EAAQJ,EACZ/H,EAAO4H,EAAmBpT,IAAM2T,EAAQH,EACxChI,EAAO6H,EAAqBrT,IACxB2T,EAAQF,EACZjI,EAAO8H,EAAsBtT,IAAM2T,EAAQD,KAKnD,OAAOE,WAAYpI,EAAQ,CAACM,EAAOgG,EAAQD,EAASE,GAAQpQ,EAAEzD,OAGhES,sBACIgD,EAAamO,EAAmBC,EAChCC,GACFvS,EAAiBkE,EAAG,yBAEpB,MAAOmK,EAAOmE,EAAWC,EAAUC,GAAexO,EAAEzC,MAC9CqM,EAAU1M,KAAKwB,SAASsB,EAAEnC,QAC1BgM,EAAS,IAAIjD,aAAauD,EAAQgE,EAAYC,EAAWI,GAEzDC,EAAuC,CAC1CJ,GAAgBF,EAAY,EAAKG,EAAY,EAAIA,EACjDD,GAAgBD,EAAW,EAAKG,EAAW,EAAIA,GAG5CG,EAAwC,CAC3CL,GAAgBF,EAAY,EAAKA,EAAY,EAAIA,EACjDE,GAAgBD,EAAW,EAAKA,EAAW,EAAIA,GAG5CQ,EACFH,EAAmB,GAAKC,EAAoB,GAC1CG,EACFJ,EAAmB,GAAKC,EAAoB,GAEhD,IAAIwD,EAAe,EACnB,IAAK,IAAIjP,EAAI,EAAGA,EAAIkH,EAAOlH,IAAK,CAC9B,MAAMkP,EAAclP,EAAIjD,EAAEG,QAAQ,GAClC,IAAK,IAAI2O,EAAI,EAAGA,EAAIX,EAAWW,IAAK,CAClC,MAAMC,EAAgBH,EAAwBE,EAKxCsD,EAAYD,EAJO1O,KAAKwB,IAC1BqJ,EAAY,EACZD,EAAe5K,KAAK4O,MAAMtD,GACXtL,KAAKE,MAAMoL,IACqB/O,EAAEG,QAAQ,GAC7D,IAAK,IAAImP,EAAI,EAAGA,EAAIlB,EAAUkB,IAAK,CACjC,MAAMC,EAAgBV,EAAwBS,EAKxCgD,EAAYF,EAJO3O,KAAKwB,IAC1BsJ,EAAW,EACXF,EAAe5K,KAAK4O,MAAM9C,GACX9L,KAAKE,MAAM4L,IACmBvP,EAAEG,QAAQ,GAC3D,IAAK,IAAI9B,EAAI,EAAGA,EAAImQ,EAAanQ,IAAK,CAGpC,MAAMkU,EAAS3I,EAAQ0I,EAAYjU,GACnCwL,EAAOqI,KAAkBK,KAKjC,OAAO9R,SACHoJ,EAAQ,CAACM,EAAOgE,EAAWC,EAAUI,GAAcxO,EAAEzD,OAG3DS,8BACIyJ,EAAczG,EAAaqO,GAC7BvS,EAAiB,CAAC2K,EAAIzG,GAAI,iCAE1B,MAAOmK,EAAO+F,EAASC,EAAQC,GAASpQ,EAAEzC,QACjC8S,EAASC,GAAU7J,EAAGlJ,MAEzBsM,EAAS,IAAIjD,aAAauD,EAAQ+F,EAAUC,EAASC,GACrDvJ,EAAW3J,KAAKwB,SAAS+H,EAAG5I,QAK5B0S,EAAmC,CACtClC,GAAgBgC,EAAU,EAAKH,EAAU,EAAIA,EAC7C7B,GAAgBiC,EAAS,EAAKH,EAAS,EAAIA,GAGxCK,EAAmC,CACtCnC,GAAgBgC,EAAU,EAAKA,EAAU,EAAIA,EAC7ChC,GAAgBiC,EAAS,EAAKA,EAAS,EAAIA,GAGxCG,EAAcF,EAAe,GAAKC,EAAe,GACjDE,EAAaH,EAAe,GAAKC,EAAe,GAEhDgC,EAAiB,EAAI/B,EACrBgC,EAAgB,EAAI/B,EAIpBgC,EAAyC,EAA5BjP,KAAK0L,KAAKqD,GAAuB,EAC9CG,EAAuC,EAA3BlP,KAAK0L,KAAKsD,GAAsB,EAGlD,IAAK,IAAIxP,EAAI,EAAGA,EAAIkH,EAAOlH,IAAK,CAC9B,MAAMkP,EAAclP,EAAIjD,EAAEG,QAAQ,GAClC,IAAK,IAAI2O,EAAI,EAAGA,EAAIoB,EAASpB,IAAK,CAChC,MAAMsD,EAAYD,EAAcrD,EAAI9O,EAAEG,QAAQ,GAGxCyS,EAAanP,KAAKE,MAAMmL,EAAI0D,GAC5BK,EAAWpP,KAAKE,MAAMiP,EAAcF,EAAY,GACtD,IAAK,IAAIpD,EAAI,EAAGA,EAAIa,EAAQb,IAAK,CAC/B,MAAMgD,EAAYF,EAAY9C,EAAItP,EAAEG,QAAQ,GAGtC2S,EAAarP,KAAKE,MAAM2L,EAAImD,GAC5BM,EAAWtP,KAAKE,MAAMmP,EAAcH,EAAW,GAErD,IAAK,IAAItU,EAAI,EAAGA,EAAI+R,EAAO/R,IAAK,CAC9B,IAAI2U,EAAQ,EAGZ,IAAK,IAAIC,EAAW,EAAGA,EAAWP,EAAWO,IAAY,CACvD,MAAMC,EAAMD,EAAWJ,EAEvB,GAAIK,EAAM,GAAKA,GAAO7C,EACpB,SAGF,MAAM8C,EAAYhB,EAAce,EAAMzM,EAAGtG,QAAQ,GAC3C4O,EAAgBmE,EAAMzC,EAK5B,GAAI3B,IAJqBrL,KAAKwB,IAC1BiL,EAAU,EACV7B,EAAe5K,KAAK4O,MAAMtD,GACXtL,KAAKE,MAAMoL,IAI9B,IAAK,IAAIqE,EAAW,EAAGA,EAAWT,EAAUS,IAAY,CACtD,MAAMC,EAAMD,EAAWL,EAEvB,GAAIM,EAAM,GAAKA,GAAO/C,EACpB,SAGF,MAAMgD,EAAYH,EAAYE,EAAM5M,EAAGtG,QAAQ,GACzCoP,EAAgB8D,EAAM3C,EAMxBpB,IALqB7L,KAAKwB,IAC1BkL,EAAS,EACT9B,EAAe5K,KAAK4O,MAAM9C,GACX9L,KAAKE,MAAM4L,MAG5ByD,GAASnM,EAASyM,EAAYjV,KAIpCwL,EAAOyI,EAAYjU,GAAK2U,KAKhC,OAAOf,WAAYpI,EAAQ7J,EAAEzC,MAAOyC,EAAEzD,OAGxCS,6BACIgD,EAAauT,EAAqBC,EAAcC,EAChDC,GACF5X,EAAiBkE,EAAG,gCAEpB,MAAM2T,EAAW3T,EAAEzC,MAAM,GACnBqW,EAAOD,EAAW,EAClB/J,EAAU1M,KAAKwB,SAASsB,EAAEnC,QAC1BiD,EAAOd,EAAEc,KACTsB,EAAS,IAAIwE,aAAa9F,GAEhC,SAAS+S,EAAkBxP,GACzB,MAAMyP,EAAiBzP,EAASsP,EAChC,IAAII,EACA1P,EAASyP,EAAiBrQ,KAAKb,IAAI,EAAGkR,EAAiBP,GAC3D,MAAMS,EAAe3P,EAASyP,EAC1BrQ,KAAKwB,IAAI6O,EAAiBP,EAAaK,GAE3C,IAAIxQ,EAAM,EACV,KAAO2Q,GAAkBC,EAAcD,IAAkB,CACvD,MAAME,EAAIrK,EAAQmK,GAClB3Q,GAAO6Q,EAAIA,EAEb,OAAO7Q,EAGT,IAAK,IAAIiB,EAAS,EAAGA,EAASvD,EAAMuD,IAAU,CAC5C,MAAMjB,EAAMyQ,EAAkBxP,GACxB6P,EAAMtK,EAAQvF,GAAUZ,KAAKC,IAAI8P,EAAOC,EAAQrQ,GAAMsQ,GAC5DtR,EAAOiC,GAAU6P,EAGnB,OAAOjC,WAAY7P,EAAQpC,EAAEzC,OAG/BP,QACIyJ,EAAc0N,EAAsBC,EACpCb,EAAqBC,EAAcC,EACnCC,GACF5X,EAAiB2K,EAAI,WACrB,MAAMkN,EAAWlN,EAAGlJ,MAAM,GACpBsJ,EAAW3J,KAAKwB,SAAS+H,EAAG5I,QAC5BwW,EAAmBnX,KAAKwB,SAASyV,EAAWtW,QAC5CyW,EAAoBpX,KAAKwB,SAAS0V,EAAYvW,QAC9CuE,EAAS,IAAIwE,aAAaH,EAAG3F,MAC7BA,EAAO2F,EAAG3F,KAEhB,IAAK,IAAIuD,EAAS,EAAGA,EAASvD,EAAMuD,IAAU,CAC5C,MAAMyP,EAAiBzP,EAASsP,EAC1BY,EACDlQ,EAASyP,EAAkBrQ,KAAKb,IAAI,EAAGkR,EAAiBP,GACvDiB,EAAYnQ,EAASyP,EACvBrQ,KAAKwB,IAAI0O,EAAUG,EAAiBP,EAAc,GAEtD,IAAIkB,EAAO,EACX,IAAK,IAAItO,EAAIoO,EAAYpO,EAAIqO,EAAUrO,IACrCsO,GAAQhR,KAAKC,IAAI2Q,EAAiBlO,GAAI,GAExCsO,EAAOhB,EAAQgB,EAAOjB,EAEtB,IAAK,IAAIrN,EAAIoO,EAAYpO,EAAIqO,EAAUrO,IAAK,CAC1C,IAAIuO,GAAO,EAAIjB,EAAQC,EAAOW,EAAiBlO,GAC3CmO,EAAkBjQ,GAAUoQ,EAC5BpQ,IAAW8B,IACbuO,GAAOjR,KAAKC,IAAI+Q,GAAOf,IAEzBgB,GAAO7N,EAASxC,GAChBjC,EAAO+D,IAAMuO,GAGjB,OAAOzC,WAAY7P,EAAQqE,EAAGlJ,OAGhCP,YACIuF,EAAkBoS,EAAqBC,EACvCC,GACF/Y,EAAiByG,EAAQ,eAEzB,MAAMuS,EAAgBH,EAAapS,EAASwS,UAAWxS,GACjD6H,EAAY0K,EAAcvX,MAAM,GAChCyX,EAAYF,EAAcvX,MAAM,GAChCoE,EAAMsC,QAAkB,CAACmG,EAAWwK,GAAa,SACjDK,EAAU/X,KAAKwB,SAASiD,EAAI9D,QAC5BqX,EAAWhY,KAAKwB,SAASoW,EAAcjX,QAE7C,IAAK,IAAIoF,EAAI,EAAGA,EAAImH,IAAanH,EAAG,CAClC,MAAMoB,EAASpB,EAAI+R,EAGbG,EAAM,IAAIvO,aAAaoO,EAAY,GACzCG,EAAI,GAAKD,EAAS7Q,GAClB,IAAK,IAAI+Q,EAAQ,EAAGA,EAAQD,EAAIlX,SAAUmX,EACxCD,EAAIC,GAASD,EAAIC,EAAQ,GAAKF,EAAS7Q,EAAS+Q,GAGlD,MAAMC,EAASC,OAAgBT,EAAKU,YAC9BC,EAAYvS,EAAI2R,EACtB,IAAK,IAAIa,EAAW,EAAGA,EAAWb,IAAca,EAAU,CACxD,MAAM3G,EAAIuG,IAGVJ,EAAQO,EAAYC,GAAYN,EAAIlX,OAEpC,IAAK,IAAImX,EAAQ,EAAGA,EAAQD,EAAIlX,OAAQmX,IACtC,GAAItG,EAAIqG,EAAIC,GAAQ,CAClBH,EAAQO,EAAYC,GAAYL,EAChC,QAKR,OAAOzT,EAGT3E,OAAOkK,EAAmBkJ,EAAesF,EAAiBC,GAExD7Z,EAAiBoL,EAAS,UAE1B,MAAMvF,EAAM,IAAIiF,aAAaM,EAAQpG,KAAOsP,GAC5CzO,EAAIF,KAAKkU,GACT,MAAMC,EAAa1Y,KAAKwB,SAASwI,EAAQrJ,QAEzC,IAAK,IAAIuX,EAAQ,EAAGA,EAAQlO,EAAQpG,OAAQsU,EACtCQ,EAAWR,IAAU,GAAKQ,EAAWR,GAAShF,IAChDzO,EAAIyT,EAAQhF,EAAQwF,EAAWR,IAAUM,GAG7C,OAAOG,WAAYlU,EAAK,CAACuF,EAAQpG,KAAMsP,GAAQ,SAGjDpT,kBACI8Y,EAAiBC,EAAkBC,EACnCC,EAAsBC,GACxBpa,EAAiBga,EAAO,qBAExB,MAAMK,EAAYjZ,KAAKwB,SAASoX,EAAMjY,QAChCuY,EAAalZ,KAAKwB,SAASqX,EAAOlY,QACxC,OAAOrB,EACH2Z,EAAWC,EAAYJ,EAAeC,EAAcC,GAG1DlZ,aAAagD,EAAaqW,EAAmBC,GAE3Cja,OAAKC,OACc,SAAfga,EACA,IAAM,+DACFA,KACRja,OAAKC,OACD+Z,EAAY,EACZ,IACI,sDAAsDA,KAE9D,MAAMjM,EAAYpK,EAAEzC,MAAM,GACpBgZ,EAAcvW,EAAEzC,MAAM,GACtBiZ,EAAaxW,EAAEzC,MAAM,GACrBkZ,EAAazW,EAAEzC,MAAM,GAErBmZ,EAAeH,EAAcF,EAC7BM,EAAcH,EAAaH,EAC3BO,EAAcH,GAAcJ,EAAYA,GAExCzM,EAAU1M,KAAKwB,SAASsB,EAAEnC,QAC1BuE,EACF,IAAIwE,aAAawD,EAAYsM,EAAeC,EAAcC,GAE9D,IAAIjI,EAAY,EAChB,IAAK,IAAI1L,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAI4T,EAAI,EAAGA,EAAIH,IAAgBG,EAAG,CACrC,MAAMC,EAAMrT,KAAKE,MAAMkT,EAAIR,GACrBU,EAAWF,EAAIR,EACrB,IAAK,IAAIW,EAAI,EAAGA,EAAIL,IAAeK,EAAG,CACpC,MAAMC,EAAMxT,KAAKE,MAAMqT,EAAIX,GAErBa,GAAWH,EAAUV,EADVW,EAAIX,GAC6BO,EAClD,IAAK,IAAIvY,EAAI,EAAGA,EAAIuY,IAAevY,EAAG,CACpC,MACM8Y,EADM9Y,EAAI6Y,EAENT,GAAcQ,EAAMT,GAAcM,EAAMP,EAActT,IAChEb,EAAOuM,KAAe/E,EAAQuN,KAKtC,OAAOlF,WACH7P,EAAQ,CAACgI,EAAWsM,EAAcC,EAAaC,IAG7C5Z,oBACJ+F,EAAWE,EAAW1G,EACtB6a,GACF,MAAMjQ,EAAWxJ,eAAa0Z,2BAA2BtU,EAAExF,MAAO0F,EAAE1F,OAC9D6E,EAAShD,SAAU+H,EAAU5K,GAC7B6H,EAAQlH,KAAKwB,SAASqE,EAAElF,QACxByZ,EAAQpa,KAAKwB,SAASuE,EAAEpF,QACxB0Z,EAAiB5Z,eAAa6Z,iBAAiBzU,EAAExF,MAAO4J,GACxDsQ,EAAiB9Z,eAAa6Z,iBAAiBvU,EAAE1F,MAAO4J,GAExD8N,EAAU7S,EAAO9E,OACvB,GAAIia,EAAetZ,OAASwZ,EAAexZ,SAAW,EACpD,IAAK,IAAI4C,EAAI,EAAGA,EAAIoU,EAAQhX,SAAU4C,EACpCoU,EAAQpU,GAAKuW,EAAGhT,EAAMvD,EAAIuD,EAAMnG,QAASqZ,EAAMzW,EAAIyW,EAAMrZ,aAEtD,CACL,MAAMyZ,EAAOxa,KAAK0D,WAAWmC,GACvB4U,EAAOza,KAAK0D,WAAWqC,GAC7B,IAAK,IAAIpC,EAAI,EAAGA,EAAIoU,EAAQhX,SAAU4C,EAAG,CACvC,MAAME,EAAMqB,EAAOpB,WAAWH,GAExB+W,EAAO7W,EAAIW,OAAOqB,EAAExB,MAC1BgW,EAAepb,QAAQkC,GAAKuZ,EAAKvZ,GAAK,GACtC,MAAMwZ,EAASH,EAAKnQ,WAAWqQ,GAEzBE,EAAO/W,EAAIW,OAAOuB,EAAE1B,MAC1BkW,EAAetb,QAAQkC,GAAKyZ,EAAKzZ,GAAK,GACtC,MAAM0Z,EAASJ,EAAKpQ,WAAWuQ,GAE/B7C,EAAQpU,GAAKuW,EAAGhT,EAAMyT,GAASP,EAAMS,KAGzC,OAAO3V,EAAOjB,WAGhBnE,MAAwBgD,EAAMgY,EAAsBxX,GAClD,OAAO9D,EAAMsD,EAAGgY,EAAYxX,GAG9BxD,WAEAA,iBACE,OAAO,GAITA,UACE,OAAOC,MAAMgb,UAGfjb,cACIkb,EACApC,EACAqC,EACAC,EACAC,EACAC,GAEF,MAAOnO,EAAOoO,EAAaC,EAAYhK,GAAe0J,EAAO3a,MACvDkb,EAAW3C,EAAMvY,MAAM,IAEtBmb,EAAYC,GAAaP,EAC1BvO,EACFzK,SAAU,CAACqZ,EAAUC,EAAYC,EAAWnK,GAAc,WAExDoK,EAAU1b,KAAKwB,SAASoX,EAAMjY,QAC9Bgb,EAAa3b,KAAKwB,SAASyZ,EAASta,QACpCib,EAAY5b,KAAKwB,SAASwZ,EAAOra,QAEjCkb,EAAWb,EAAO/X,QAClB6Y,EAAYnP,EAAO1J,QAKzB,IAAK,IAAI8C,EAAI,EAAGA,EAAIwV,EAAUxV,IAAK,CACjC,MAAMgW,EAAe,EAAJhW,EACXiW,EAAKN,EAAQK,GACbE,EAAKP,EAAQK,EAAW,GACxBG,EAAKR,EAAQK,EAAW,GACxBI,EAAKT,EAAQK,EAAW,GAExBK,EAAeT,EAAW5V,GAChC,GAAIqW,GAAQnP,EACV,SAGF,MAAMsG,EAAeiI,EAAa,GAC7BU,EAAKF,IAAOX,EAAc,IAAMG,EAAa,GAC9C,EACEhI,EACDiI,EAAY,GAAMU,EAAKF,IAAOX,EAAa,IAAMG,EAAY,GAAK,EAEvE,IAAK,IAAIjS,EAAI,EAAGA,EAAIgS,EAAYhS,IAAK,CACnC,MAAM6S,EAAgBb,EAAa,EAC/BQ,GAAMX,EAAc,GAAK7R,IACzB,IAAOwS,EAAKE,IAAOb,EAAc,GAErC,GAAIgB,EAAO,GAAKA,EAAOhB,EAAc,EACnC,IAAK,IAAIvY,EAAI,EAAGA,EAAI2Y,EAAW3Y,IAC7B,IAAK,IAAIsP,EAAI,EAAGA,EAAId,EAAac,IAAK,CACpC,MAAMkK,EACFlK,EAAItP,EAAIgZ,EAAU,GAAKtS,EAAIsS,EAAU,GAAK/V,EAAI+V,EAAU,GAC5DnP,EAAOvM,OAAOkc,GAAOlB,OAM3B,GAAe,aAAXD,EAAuB,CACzB,MAAMoB,EAAShW,KAAKE,MAAM4V,GACpBG,EAAYjW,KAAK0L,KAAKoK,GACtBI,EAAQJ,EAAOE,EAErB,IAAK,IAAIzZ,EAAI,EAAGA,EAAI2Y,EAAW3Y,IAAK,CAClC,MAAM4Z,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKxY,EAAI0Q,EAC5B,IAAOyI,EAAKE,IAAOb,EAAa,GAEpC,GAAIoB,EAAO,GAAKA,EAAOpB,EAAa,EAAG,CACrC,IAAK,IAAIlJ,EAAI,EAAGA,EAAId,EAAac,IAAK,CACpC,MAAMkK,EACFlK,EAAItP,EAAIgZ,EAAU,GAAKtS,EAAIsS,EAAU,GAAK/V,EAAI+V,EAAU,GAC5DnP,EAAOvM,OAAOkc,GAAOlB,EAEvB,SAGF,MAAMuB,EAAUpW,KAAKE,MAAMiW,GACrBE,EAAWrW,KAAK0L,KAAKyK,GACrBG,EAAQH,EAAOC,EAErB,IAAK,IAAIvK,EAAI,EAAGA,EAAId,EAAac,IAAK,CACpC,IAAIkK,EAAMlK,EAAIuK,EAAUd,EAAS,GAAKU,EAASV,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAAMhJ,EAAU+I,EAAUU,GAE1BA,EAAMlK,EAAIwK,EAAWf,EAAS,GAAKU,EAASV,EAAS,GACjDO,EAAOP,EAAS,GACpB,MAAMiB,EAAWlB,EAAUU,GAE3BA,EAAMlK,EAAIuK,EAAUd,EAAS,GAAKW,EAAYX,EAAS,GACnDO,EAAOP,EAAS,GACpB,MAAM/I,EAAa8I,EAAUU,GAE7BA,EAAMlK,EAAIwK,EAAWf,EAAS,GAAKW,EAAYX,EAAS,GACpDO,EAAOP,EAAS,GACpB,MAEM1P,EAAM0G,GAAWiK,EAAWjK,GAAWgK,EACvCE,EAASjK,GAHK8I,EAAUU,GAGaxJ,GAAc+J,EAEzDP,EAAMlK,EAAItP,EAAIgZ,EAAU,GAAKtS,EAAIsS,EAAU,GAAK/V,EAAI+V,EAAU,GAC9DnP,EAAOvM,OAAOkc,GAAOnQ,GAAQ4Q,EAAS5Q,GAAOsQ,SAIjD,IAAK,IAAI3Z,EAAI,EAAGA,EAAI2Y,IAAa3Y,EAAG,CAClC,MAAM4Z,EAAQjB,EAAY,EACtBQ,GAAMX,EAAa,GAAKxY,EAAI0Q,EAC5B,IAAOyI,EAAKE,IAAOb,EAAa,GAEpC,GAAIoB,EAAO,GAAKA,EAAOpB,EAAa,EAAG,CACrC,IAAK,IAAIlJ,EAAI,EAAGA,EAAId,EAAac,IAAK,CACpC,MAAMkK,EACFlK,EAAItP,EAAIgZ,EAAU,GAAKtS,EAAIsS,EAAU,GAAK/V,EAAI+V,EAAU,GAC5DnP,EAAOvM,OAAOkc,GAAOlB,EAEvB,SAGF,MAAM4B,EAAWzW,KAAK4O,MAAMuH,GACtBO,EAAW1W,KAAK4O,MAAMkH,GAC5B,IAAK,IAAIjK,EAAI,EAAGA,EAAId,EAAac,IAAK,CACpC,MAAM8K,EAAQ9K,EAAI4K,EAAWnB,EAAS,GAClCoB,EAAWpB,EAAS,GAAKO,EAAOP,EAAS,GACvCsB,EACF/K,EAAItP,EAAIgZ,EAAU,GAAKtS,EAAIsS,EAAU,GAAK/V,EAAI+V,EAAU,GAC5DnP,EAAOvM,OAAO+c,GAAUvB,EAAUsB,MAM5C,OAAOvQ,EAAO1I,WAGhBnE,cACIsd,EAAuBC,EAAsBC,EAC7CC,GACF,MAAMC,UAACA,EAASC,WAAEA,EAAUxS,UAAEA,EAAShI,QAAEA,EAAOya,WAAEA,GAC9Cjd,eAAakd,gBAAgBN,EAAcD,EAAeE,GAE9D,OAAOtd,KAAK4d,QACRR,EAAeC,EAAcC,EAAaI,EAAYzS,EACtDwS,EAAYD,EAAWva,EAASsa,GAHb,GAMzBzd,SAASgD,EAAWkH,GAClB,MAAM6T,EAAe7T,EAAQ3J,MACvBmd,EAAYK,EAAaA,EAAa9c,OAAS,IAE9C+c,EAAaC,EAAW9S,EAAWhI,GACtCxC,eAAaud,mBAAmBlb,EAAGkH,GACvC,GAAkB,IAAd+T,EACF,OAAOxa,SAAU,GAAIua,EAAahb,EAAEzD,OAGtC,MAAMmE,EAAS,IAAIya,eAAa,CAACF,EAAW9S,GAAYnI,EAAEzD,OACpD6e,EAAcle,KAAKwB,SAASwI,EAAQrJ,QACpCwd,EAAQne,KAAKwB,SAASsB,EAAEnC,QAE9B,IAAK,IAAIgD,EAAI,EAAGA,EAAIoa,EAAWpa,IAAK,CAClC,MAAMoF,EAAQ,GACd,IAAIqV,EAAe,EACnB,IAAK,IAAIpa,EAAI,EAAGA,EAAIwZ,EAAWxZ,IAAK,CAClC,MAAMsB,EAAM4Y,EAAYva,EAAI6Z,EAAYxZ,GACxCoa,GAAgB9Y,EAAMrC,EAAQe,GAC9B+E,EAAMlB,KAAKvC,GAEb,GAAI8Y,EAAe,GAAKA,GAAgBtb,EAAEc,KAAOqH,EAC/C,MAAM,IAAIhJ,MACN,oBAAoB8G,yBAA6BjG,EAAEzC,SAGzD,IAAK,IAAI4I,EAAI,EAAGA,EAAIgC,EAAWhC,IAC7BzF,EAAOpD,OAAOuD,EAAIsH,EAAYhC,GAAKkV,EAAMC,EAAenT,EAAYhC,GAGxE,OAAOzF,EAAOS,WAAWU,QAAQmZ,GAGnChe,UACIkK,EAAiBqU,EAAiBhe,GACpC,MAAMmd,UAACA,EAASC,WAAEA,EAAUxS,UAAEA,EAAShI,QAAEA,EAAOya,WAAEA,GAC9Cjd,eAAakd,gBAAgBU,EAASrU,EAAS3J,GAC7Ckd,EAAevY,SAAU,GAE/B,OAAOhF,KAAK4d,QACR5T,EAASqU,EAAShe,EAAOqd,EAAYzS,EAAWwS,EAAYD,EAC5Dva,EAASsa,GAHU,GAMzBzd,SAAyBgD,GACvB,GAAgB,WAAZA,EAAEzD,MACJ,MAAM,IAAI4C,MAAM,gDAIhB,OAAOqc,OAAQxb,EAAEzC,MAAO,EAAGyC,EAAEzD,OAIjCS,UAA0BgD,GACxB,MAAM1C,EAASjB,OAAKof,kBACDzb,EAAEzD,MAAOF,OAAK8H,cAAcnE,EAAEzC,QACjD,OAAOL,KAAK6J,WAAWzJ,EAAQ0C,EAAEzC,MAAOyC,EAAEzD,OAG5CS,SAAS2C,EAAe+b,EAAcpa,GACpC,OAAO3D,eAAage,aAAahc,EAAO+b,EAAMpa,GAGxCtE,QACJkK,EAAiBqU,EAAiBhe,EAAoBqd,EACtDzS,EAAmBwS,EAAoBD,EACvCva,EAAmBsa,EACnBmB,GACF,MAAMC,EAAe,CAACjB,EAAazS,EAAWA,GAExCiT,EAAcle,KAAKwB,SAASwI,EAAQrJ,QACpCie,EAAc5e,KAAKwB,SAAS6c,EAAQ1d,QAE1C,GAAmB,IAAf+c,EACF,OAAOna,SAAU,GAAIlD,EAAOge,EAAQhf,OAGtC,MAAMmE,EAAS,IAAIya,eAAaU,EAAcN,EAAQhf,OACtDmE,EAAOpD,OAAOmE,KAAMvE,KAAKwB,SAAS+b,EAAa5c,QAAuB,IAEtE,IAAK,IAAIgD,EAAI,EAAGA,EAAI8Z,EAAY9Z,IAAK,CACnC,MAAMoF,EAAQ,GACd,IAAIqV,EAAe,EACnB,IAAK,IAAIpa,EAAI,EAAGA,EAAIwZ,EAAWxZ,IAAK,CAClC,MAAMsB,EAAM4Y,EAAYva,EAAI6Z,EAAYxZ,GACxC+E,EAAMlB,KAAKvC,GACX8Y,GAAgB9Y,EAAMrC,EAAQe,GAGhC,GAAIoa,EAAe,GAAKA,GAAgBV,EAAazS,EACnD,MAAM,IAAIhJ,MACN,oBAAoB8G,yBAA6B1I,KAGvD,IAAK,IAAI4I,EAAI,EAAGA,EAAIgC,EAAWhC,IACzByV,EACFlb,EAAOpD,OAAOge,EAAenT,EAAYhC,IACrC2V,EAAYjb,EAAIsH,EAAYhC,GAEhCzF,EAAOpD,OAAOge,EAAenT,EAAYhC,GAAsB,IAAjBoV,EAAQha,KAClDua,EAAY,GACZA,EAAYjb,EAAIsH,EAAYhC,GAItC,OAAOzF,EAAOS,WAAWU,QAAQtE,aCn2DrBwe,EAAc1a,GAC5B,MAAMsF,EAAe,IAAIC,aAAavF,EAAKpD,QAC3C,IAAK,IAAI4C,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EACjC8F,EAAa9F,GAAK4C,KAAKuY,IAAI3a,EAAKR,IAElC,OAAO8F,EAGF,MAsBMsV,EAA0B,CACrCC,WAAYC,MACZC,YAAa,MACbC,WAzBkBC,IAClB,MAAMtc,EAACA,GAAKsc,EAAKC,OACXC,EAAaF,EAAKG,QACxB,IAAI9V,EAAe,IAAIC,aAAavK,OAAK8H,cAAcnE,EAAEzC,QACzD,GAAgB,cAAZyC,EAAEzD,MAAuB,CAE3BoK,EAAeoV,EADAS,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,YAExC,CACL,MAAMof,EAAcF,EAAWrf,KAAKO,IAAIsC,EAAEnC,QACpCgB,EAAO6d,EAAY/d,mBAAmBE,KACtCE,EAAO2d,EAAY/d,mBAAmBI,KACtC4d,EAAWH,EAAWrf,KAAKO,IAAImB,EAAKhB,QAAQP,OAC5Csf,EAAWJ,EAAWrf,KAAKO,IAAIqB,EAAKlB,QAAQP,OAClD,IAAK,IAAIuD,EAAI,EAAGA,EAAI8b,EAAS1e,OAAQ4C,IAAK,CACxC,MAAMhC,EAAO8d,EAAS9b,GAChB9B,EAAO6d,EAAS/b,GACtB8F,EAAa9F,GAAK4C,KAAKoZ,MAAMhe,EAAME,IAGvC,OAAOyd,EAAWzV,WAAWJ,EAAc3G,EAAEzC,MAAO,sBCxBtCuf,EAA6B1F,GAE3C,MAAO,CAAC2F,EAAkBC,EAAkB5Y,EACpCkT,EAAmB/a,KACzB,MAAM4K,EAAWxJ,eAAa0Z,2BAA2B0F,EAAQC,GAE3DC,EAAa9V,EAASlJ,OACtBif,EAAgB7gB,OAAK8gB,eAAehW,GACpCiW,EAAa/gB,OAAK8H,cAAcgD,GAEhC/E,EACF/F,OAAKghB,uBAAuB9gB,EAA0B6gB,GAEpDE,EAAQP,EAAO9e,OACfsf,EAAQP,EAAO/e,OAEfuf,EAAWnhB,OAAK8gB,eAAeJ,GAC/BU,EAAWphB,OAAK8gB,eAAeH,GAE/BzF,EAAiB5Z,eAAa6Z,iBAAiBuF,EAAQ5V,GACvDsQ,EAAiB9Z,eAAa6Z,iBAAiBwF,EAAQ7V,GAE7D,GAAIoQ,EAAetZ,OAASwZ,EAAexZ,SAAW,EACpD,IAAK,IAAI4C,EAAI,EAAGA,EAAIuB,EAAOnE,SAAU4C,EACnCuB,EAAOvB,GAAKuW,EAAGhT,EAAMvD,EAAIuD,EAAMnG,QAASqZ,EAAMzW,EAAIyW,EAAMrZ,cAG1D,IAAK,IAAI4C,EAAI,EAAGA,EAAIuB,EAAOnE,SAAU4C,EAAG,CACtC,MAAME,EAAM1E,OAAK2E,WAAWH,EAAGoc,EAAYC,GAErCtF,EAAO7W,EAAIW,OAAO4b,GACxB/F,EAAepb,QAAQkC,GAAKuZ,EAAKvZ,GAAK,GACtC,MAAMwZ,EAASxb,OAAKkL,WAAWqQ,EAAM0F,EAAOE,GAEtC1F,EAAO/W,EAAIW,OAAO6b,GACxB9F,EAAetb,QAAQkC,GAAKyZ,EAAKzZ,GAAK,GACtC,MAAM0Z,EAAS1b,OAAKkL,WAAWuQ,EAAMyF,EAAOE,GAE5Crb,EAAOvB,GAAKuW,EAAGhT,EAAMyT,GAASP,EAAMS,IAIxC,MAAO,CAAC3V,EAAQ+E,aC7CJuW,EAAQpB,GAEtB,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpBzd,KAACA,EAAIE,KAAEA,GAAQwd,EAEfI,EAAWF,EAAQtf,KAAKO,IAAImB,EAAKhB,QAAQP,OACzCsf,EAAWH,EAAQtf,KAAKO,IAAIqB,EAAKlB,QAAQP,OAEzCqgB,EAAclB,EAAQmB,eAAe/e,EAAKtB,MAAO,aAYvD,OAVgBkf,EAAQtf,KAAKO,IAAIigB,EAAY9f,QAKrCc,mBAAqB,CAC3BE,KAAM4d,EAAQmB,eAAe/e,EAAKtB,MAAO,UAAWof,GACpD5d,KAAM0d,EAAQmB,eAAe7e,EAAKxB,MAAO,UAAWqf,IAG/Ce,EAGF,MAAME,EAA8B,CACzC3B,WAAY4B,UACZ1B,YAAa,MACbC,WAAYqB,YC1BEK,EACZzB,GACF,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpBtc,EAACA,GAAKuc,EAIZ,OAFAE,EAAQuB,OAAOhe,EAAEnC,QAEV,CAACA,OAAQmC,EAAEnC,OAAQN,MAAOyC,EAAEzC,MAAOhB,MAAOyD,EAAEzD,OAG9C,MAAM0hB,EAA+B,CAC1C/B,WAAYgC,WACZ9B,YAAa,MACbC,WAAY0B,YCbElf,EAAKyd,GAEnB,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpB6B,MAACA,GAAS5B,EAEV1d,EAAO4d,EAAQtf,KAAKO,IAAIygB,EAAMtgB,QAAQc,mBAAmBE,KACzDuf,EAAU3B,EAAQtf,KAAKO,IAAImB,EAAKhB,QAAQP,OAK9C,OAAOmf,EAAQmB,eAAe/e,EAAKtB,MAAOsB,EAAKtC,MAAO6hB,GAGjD,MAAMC,EAA2B,CACtCnC,WAAYoC,OACZlC,YAAa,MACbC,WAAYxd,YCZE0f,EACZjC,GAEF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,GACNhgB,MAACA,GAASiiB,EAGhB,GAAc,cAAVjiB,EAAuB,CACzB,GAAgB,cAAZyD,EAAEzD,MACJ,OAAOwhB,EAAS,CAACxB,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,IAIhC,MAAMgC,EAAcxa,QAASjE,EAAEzC,OACzBmhB,EAASH,EAAK,CAAChC,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,EAAS+B,MAAO,CAACjiB,MAAO,aAEpD6F,EACFsb,EAAQ,CAACnB,OAAQ,CAAC1d,KAAM6f,EAAQ3f,KAAM0f,GAAchC,QAAAA,IAKxD,OAHAgC,EAAYE,UACZlC,EAAQmC,8BAA8BF,GAE/Btc,EAIT,GAAgB,cAAZpC,EAAEzD,MAAuB,CAC3B,MAAMsiB,EAAWhgB,EAAK,CAAC0d,OAAQ,CAAC4B,MAAOne,GAAIyc,QAAAA,IACrCra,EAASmc,EAAK,CAAChC,OAAQ,CAACvc,EAAG6e,GAAWpC,QAAAA,EAAS+B,MAAO,CAACjiB,MAAAA,KAI7D,OAFAkgB,EAAQmC,8BAA8BC,GAE/Bzc,EAGT,IAAK/F,OAAKyiB,gBAAgB9e,EAAEzD,MAAOA,GAAQ,CAGzC,MAAM6F,EAAS2b,EAAS,CAACxB,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,IACtC,MAAO,CAAC5e,OAAQuE,EAAOvE,OAAQN,MAAO6E,EAAO7E,MAAOhB,MAAAA,GAGtD,GAAc,UAAVA,EAAmB,CACrB,MAAMe,EAASmf,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACpCqJ,EAAeoY,WAAWC,KAAK1hB,GACrC,OAAOmf,EAAQmB,eAAe5d,EAAEzC,MAAO,QAASoJ,GAGlD,GAAc,SAAVpK,EAAkB,CAIpB,MAAM6E,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnC2hB,EAAO5iB,OAAK6iB,aAAa,CAAC,GAAIlf,EAAEzD,QAE/B4iB,EAAYnE,GAAe8B,EAC9B,CAAC/Z,EAAGE,IAAOF,IAAME,EAAK,EAAI,EADI6Z,CACD9c,EAAEzC,MAAO,GAAI6D,EAAO6d,EAAM,QAE3D,OAAOxC,EAAQmB,eAAe5C,EAAa,OAAQmE,GAGrD,MAAM,IAAIhgB,MAAM,iCAAiCa,EAAEzD,YAAYA,KAG1D,MAAM6iB,EAA2B,CACtClD,WAAYmD,OACZjD,YAAa,MACbC,WAAYkC,YCzDEe,EACZC,EAAcC,EACdC,EAAuCljB,GACzC,OAAmB,MAAfkjB,EACK,EAAElD,OAAAA,EAAQE,QAAAA,MACf,MAAM1Z,EAACA,EAACE,EAAEA,GAAKsZ,EACTC,EAAaC,EAEnB3gB,EAAiB,CAACiH,EAAGE,GAAIsc,GAEzB,MAAMnb,EAAQoY,EAAWrf,KAAKO,IAAIqF,EAAElF,QAAQP,OACtCga,EAAQkF,EAAWrf,KAAKO,IAAIuF,EAAEpF,QAAQP,OAEtCoiB,EAASnjB,GAASwG,EAAExG,OAEnB4iB,EAAYnE,GACfwE,EAAWzc,EAAExF,MAAO0F,EAAE1F,MAAO6G,EAAOkT,EAAOoI,GAE/C,OAAOlD,EAAWoB,eAAe5C,EAAa0E,EAAQP,IAInD,EAAE5C,OAAAA,EAAQE,QAAAA,MACf,MAAM1Z,EAACA,EAACE,EAAEA,GAAKsZ,EACTC,EAAaC,EAEnB,GAAgB,cAAZ1Z,EAAExG,OAAqC,cAAZ0G,EAAE1G,MAAuB,CACtD,MAAMojB,EAAYpB,EACd,CAAChC,OAAQ,CAACvc,EAAG+C,GAAI0Z,QAASD,EAAYgC,MAAO,CAACjiB,MAAO,eAEnDqjB,EAAgBpD,EAAWrf,KAAKO,IAAIiiB,EAAU9hB,QAE9CgiB,EAAQD,EAAcjhB,mBAAmBE,KACzCihB,EAAQF,EAAcjhB,mBAAmBI,KAEzCghB,EACFvD,EAAWrf,KAAKO,IAAImiB,EAAMhiB,QAAQP,OAChC0iB,EACFxD,EAAWrf,KAAKO,IAAIoiB,EAAMjiB,QAAQP,OAEhC2iB,EAAY1B,EACd,CAAChC,OAAQ,CAACvc,EAAGiD,GAAIwZ,QAASD,EAAYgC,MAAO,CAACjiB,MAAO,eAEnD2jB,EAAgB1D,EAAWrf,KAAKO,IAAIuiB,EAAUpiB,QAE9CsiB,EAAQD,EAAcvhB,mBAAmBE,KACzCuhB,EAAQF,EAAcvhB,mBAAmBI,KAEzCshB,EACF7D,EAAWrf,KAAKO,IAAIyiB,EAAMtiB,QAAQP,OAChCgjB,EACF9D,EAAWrf,KAAKO,IAAI0iB,EAAMviB,QAAQP,QAE/BijB,EAAgBC,EAAgBxF,GAAeyE,EAClD1c,EAAExF,MAAO0F,EAAE1F,MAAOwiB,EAAWC,EAAWK,EAAWC,GAEjDG,EACFjE,EAAWoB,eAAe5C,EAAa,UAAWuF,GAEhDG,EACFlE,EAAWoB,eAAe5C,EAAa,UAAWwF,GAEhDpe,EAASsb,EACX,CAACnB,OAAQ,CAAC1d,KAAM4hB,EAAY1hB,KAAM2hB,GAAajE,QAASD,IAO5D,OALAA,EAAWoC,8BAA8Be,GACzCnD,EAAWoC,8BAA8BqB,GACzCzD,EAAWoC,8BAA8B6B,GACzCjE,EAAWoC,8BAA8B8B,GAElCte,EACF,CACL,MAAMgC,EAAQoY,EAAWrf,KAAKO,IAAIqF,EAAElF,QAAQP,OACtCga,EAAQkF,EAAWrf,KAAKO,IAAIuF,EAAEpF,QAAQP,OAEtCoiB,EAASnjB,GAASwG,EAAExG,OAEnB4iB,EAAYnE,GACfwE,EAAWzc,EAAExF,MAAO0F,EAAE1F,MAAO6G,EAAOkT,EAAOoI,GAE/C,OAAOlD,EAAWoB,eAAe5C,EAAa0E,EAAQP,cAS5CwB,EAA8BvJ,GAE5C,MAAO,CAAC2F,EAAkBC,EAAkB+C,EACpCC,EAAyBK,EACzBC,KACN,MAAMtF,EAAcrd,eAAa0Z,2BAA2B0F,EAAQC,GAC9DI,EAAa/gB,OAAK8H,cAAc6W,GAChCiC,EAAajC,EAAY/c,OACzBif,EAAgB7gB,OAAK8gB,eAAenC,GAEpC4F,EAAiBvkB,OAAKghB,uBAAuB,UAAWD,GACxDyD,EAAiBxkB,OAAKghB,uBAAuB,UAAWD,GAExD7F,EAAiB5Z,eAAa6Z,iBAAiBuF,EAAQ/B,GACvDvD,EAAiB9Z,eAAa6Z,iBAAiBwF,EAAQhC,GAEvD5W,EAAQzG,eAAaqB,uBAAuB+gB,EAAWC,GACvD1I,EAAQ3Z,eAAaqB,uBAAuBqhB,EAAWC,GAEvDhD,EAAQP,EAAO9e,OACfuf,EAAWnhB,OAAK8gB,eAAeJ,GAE/BQ,EAAQP,EAAO/e,OACfwf,EAAWphB,OAAK8gB,eAAeH,GAErC,GAAIzF,EAAetZ,OAASwZ,EAAexZ,SAAW,EACpD,IAAK,IAAI4C,EAAI,EAAGA,EAAI+f,EAAe3iB,OAAQ4C,IAAK,CAC9C,MAAMigB,EAAOjgB,EAAIuD,EAAMnG,OACjB8iB,EAAOlgB,EAAIyW,EAAMrZ,OAEjBmE,EACFgV,EAAGhT,EAAa,EAAP0c,GAAW1c,EAAa,EAAP0c,EAAW,GAAIxJ,EAAa,EAAPyJ,GAC5CzJ,EAAa,EAAPyJ,EAAW,IAExBH,EAAe/f,GAAKuB,EAAOvD,KAC3BgiB,EAAehgB,GAAKuB,EAAOrD,UAG7B,IAAK,IAAI8B,EAAI,EAAGA,EAAI+f,EAAe3iB,OAAQ4C,IAAK,CAC9C,MAAME,EAAM1E,OAAK2E,WAAWH,EAAGoc,EAAYC,GAErCtF,EAAO7W,EAAIW,OAAO4b,GACxB/F,EAAepb,QAAQkC,GAAKuZ,EAAKvZ,GAAK,GACtC,MAAMwZ,EAASxb,OAAKkL,WAAWqQ,EAAM0F,EAAOE,GAEtC1F,EAAO/W,EAAIW,OAAO6b,GACxB9F,EAAetb,QAAQkC,GAAKyZ,EAAKzZ,GAAK,GACtC,MAAM0Z,EAAS1b,OAAKkL,WAAWuQ,EAAMyF,EAAOE,GAEtCuD,EACF5J,EAAGhT,EAAe,EAATyT,GAAazT,EAAe,EAATyT,EAAa,GAAIP,EAAe,EAATS,GAChDT,EAAe,EAATS,EAAa,IAE1B6I,EAAe/f,GAAKmgB,EAASniB,KAC7BgiB,EAAehgB,GAAKmgB,EAASjiB,KAGjC,MAAO,CAAC6hB,EAAgBC,EAAgB7F,ICjKrC,MAAMiG,EAAUnE,GAA+B/Z,EAAGE,IAAMF,EAAIE,GACtDie,EACTP,GAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CAACvhB,KAAMghB,EAAQM,EAAOphB,KAAM+gB,EAAQM,KAGpCe,EAAM7B,EAAiB8B,MAAKH,EAASC,GAErCG,EAA0B,CACrCnF,WAAYkF,MACZhF,YAAa,MACbC,WAAY8E,YCTEG,EAAsBlK,GAEpC,MAAO,CAAC9Z,EAAQf,EAAOiiB,KACrB,MAAMxY,EACF3J,OAAKghB,uBAAuB9gB,EAA0Be,EAAOW,QACjE,IAAK,IAAI4C,EAAI,EAAGA,EAAIvD,EAAOW,SAAU4C,EACnCmF,EAAUnF,GAAKuW,EAAG9Z,EAAOuD,GAAI2d,GAE/B,OAAOxY,YCAKub,EACZhC,EAAcnI,EAA0B7a,GAC1C,MAAO,EAAEggB,OAAAA,EAAQiC,MAAAA,EAAO/B,QAAAA,MACtB,MAAMzc,EAACA,GAAKuc,EAEZ,GADAzgB,EAAiBkE,EAAGuf,GACJ,WAAZvf,EAAEzD,OAAgC,WAAVA,EAC1B,MAAM,IAAI4C,MAAM,wDAGlB,MAAMqd,EAAaC,EACbnf,EAASkf,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACvCkkB,EAAQnlB,OAAK8H,cAAcnE,EAAEzC,OAC7BmiB,EAASnjB,GAASyD,EAAEzD,MACpByJ,EAAY3J,OAAKof,kBAAkBiE,EAAQ8B,GACjD,IAAK,IAAI3gB,EAAI,EAAGA,EAAI2gB,IAAS3gB,EAC3BmF,EAAUnF,GAAKuW,EAAG9Z,EAAOuD,GAAI2d,GAE/B,OAAOhC,EAAWoB,eAAe5d,EAAEzC,MAAOmiB,EAAQ1Z,aAatCyb,EACZlC,EAAcmC,EAA4BnlB,GAC5C,MAAO,EAAEggB,OAAAA,EAAQiC,MAAAA,EAAO/B,QAAAA,MACtB,MAAMzc,EAACA,GAAKuc,EAEZ,GADAzgB,EAAiBkE,EAAGuf,GACJ,WAAZvf,EAAEzD,OAAgC,WAAVA,EAC1B,MAAM,IAAI4C,MAAM,wDAGlB,MAAMqd,EAAaC,EACbnf,EAASkf,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACvCoiB,EAASnjB,GAASyD,EAAEzD,MACpByJ,EAAY0b,EAAUpkB,EAAQoiB,EAAQlB,GAC5C,OAAOhC,EAAWoB,eAAe5d,EAAEzC,MAAOmiB,EAAQ1Z,ICrD/C,MAAM2b,EAAWL,EAAuBM,GAAOne,KAAK0L,KAAKyS,IACnDzS,EAAOsS,EAAwBI,OAAMF,GAErCG,EAA2B,CACtC5F,WAAY2F,OACZzF,YAAa,MACbC,WAAYlN,GCND4S,EAAUT,EAAuBM,GAAOne,KAAKue,IAAIJ,IACjDI,EAAMP,EAAwBQ,MAAKF,GAEnCG,EAA0B,CACrChG,WAAY+F,MACZ7F,YAAa,MACbC,WAAY2F,GCNDG,EAAYb,EAAuBM,GAAOne,KAAK2e,MAAMR,IACrDQ,EAAQX,EAAwBY,QAAOF,GAEvCG,EAA4B,CACvCpG,WAAYmG,QACZjG,YAAa,MACbC,WAAY+F,GCNDG,EAAYjB,EAAuBM,GAAOne,KAAKE,MAAMie,IACrDje,EAAQ8d,EAAwBe,QAAOD,GAEvCE,EAA4B,CACvCvG,WAAYsG,QACZpG,YAAa,MACbC,WAAY1Y,GCND+e,EAAUpB,EAAuBM,GAAOne,KAAKkf,IAAIf,IACjDe,EAAMlB,EAAwBmB,MAAKF,GAEnCG,EAA0B,CACrC3G,WAAY0G,MACZxG,YAAa,MACbC,WAAYsG,YCTEG,EACZ1e,EAAmBF,EAAoB9D,EACvC7D,GACF,MAAM8E,EAAOhF,OAAKghB,uBACd9gB,EAA0BF,OAAK8H,cAAc/D,IAEjD,IAAK,IAAIS,EAAI,EAAGA,EAAIQ,EAAKpD,SAAU4C,EAAG,CACpC,MAAMwD,EAASxD,EAAIqD,EACnB,IAAItB,EAAMwB,EAAMC,GAChB,IAAK,IAAInD,EAAI,EAAGA,EAAIgD,IAAchD,EAAG,CACnC,MAAMiE,EAAQf,EAAMC,EAASnD,GACzBiE,EAAQvC,IACVA,EAAMuC,GAGV9D,EAAKR,GAAK+B,EAEZ,OAAOvB,ECfF,MAAM0hB,EACTjG,GAA+BvZ,EAAQC,IAAWD,EAASC,GAClDwf,EACTrC,GAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CACLvhB,KAAMghB,EAAQM,EAAQL,EAAQM,EAC9BrhB,KAAM8gB,EAAQO,EAAQN,EAAQK,KAIzB8C,EACT3D,EAAiB4D,WAAUH,EAAcC,GAEhCG,EAA+B,CAC1CjH,WAAYgH,WACZ9G,YAAa,MACbC,WAAY4G,GCfDG,EACTtG,GAA+B/Z,EAAGE,IAAOF,IAAME,EAAK,EAAI,GAC/CogB,EACT/D,EAAiBgE,WAAUF,EAAc,KAAsB,QAEtDG,EAA+B,CAC1CrH,WAAYoH,WACZlH,YAAa,MACbC,WAAYgH,GCRDG,EAAYlC,EAAuBM,GAAO,EAAIne,KAAKggB,KAAK7B,IACxD8B,GAAQjC,EAAwBkC,QAAOH,GAEvCI,GAA4B,CACvC1H,WAAYyH,QACZvH,YAAa,MACbC,WAAYqH,aCNEG,GACZxiB,EAAkBpB,EAAiBa,EAAgBvD,EACnDhB,GACF,MAAMunB,EAAczjB,aAAW0jB,iBAAiBxmB,EAAO0C,EAAOa,GACxD7C,EAAS5B,OAAK8H,cAAcrD,GAC5BkjB,EAAW3nB,OAAK8gB,eAAe5f,GAErC,GAAIumB,EAAa,CACf,MAAMG,EAAa5jB,aAAW6jB,kBAAkBjkB,EAAO+jB,GACvD,OAAO3iB,EAAK8iB,SAASF,EAAYA,EAAahmB,GAGhD,MAAMmmB,EAAU/nB,OAAKghB,uBAAuB9gB,EAA0B0B,GACtE,IAAK,IAAI4C,EAAI,EAAGA,EAAI5C,IAAU4C,EAAG,CAC/B,MAAMU,EAAOT,EAAK7C,OACZkC,EAAU9D,OAAK8gB,eAAerc,GAE9BujB,EADMhoB,OAAK2E,WAAWH,EAAGU,EAAMpB,GACpB/B,IAAI,CAACqH,EAAavE,IAAMuE,EAAMxF,EAAMiB,IAC/CojB,EAASjoB,OAAKkL,WAAW8c,EAAM9mB,EAAMU,OAAQ+lB,GACnDI,EAAQvjB,GAAKQ,EAAKijB,GAEpB,OAAOF,WAGO1iB,GACZ4a,GAEF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,GACNtc,MAACA,EAAKa,KAAEA,GAAQ0d,EAEtB1iB,EAAiBkE,EAAG,SAEpB,MAAOukB,EAAQC,GAASnkB,aAAWokB,iBAAiBzkB,EAAGC,EAAOa,GAC9DT,aAAWqkB,kBAAkB1kB,EAAGukB,EAAQC,GAExC,MACMJ,EAAUP,GADHpH,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACRinB,EAAQC,EAAOxkB,EAAEzC,MAAOyC,EAAEzD,OAC1D,OAAOkgB,EAAQmB,eAAe4G,EAAOxkB,EAAEzD,MAAO6nB,GAGzC,MAAMO,GAA4B,CACvCzI,WAAY0I,QACZxI,YAAa,MACbC,WAAY3a,IC5CDmjB,GAAwB/H,GAA+B/Z,EAAGE,KACrE,MAAMuD,EAAOzD,EAAIE,EACjB,OAAOuD,EAAOA,IAEHse,GACTxF,EAAiByF,oBAAmBF,IAE3BG,GAAwC,CACnD9I,WAAY6I,oBACZ3I,YAAa,MACbC,WAAYyI,ICVDG,GACTnI,GAA+BvZ,EAAQC,IAAWD,EAASC,GAClD0hB,GACTvE,GAAgCd,EAAOC,EAAOK,EAAOC,KAC5C,CAACvhB,KAAMghB,EAAQM,EAAOphB,KAAM+gB,EAAQM,KAEpC+E,GAAM7F,EAAiB8F,MAAKH,GAASC,IAErCG,GAA0B,CACrCnJ,WAAYkJ,MACZhJ,YAAa,MACbC,WAAY8I,aCbEG,GACZlkB,EAAmBmkB,EAAkBhpB,EAAiBipB,EACtDre,GACF,MAAMse,EAAQF,EAAOtnB,OACfujB,EAAQnlB,OAAK8H,cAAcohB,GAC3BvB,EAAW3nB,OAAK8gB,eAAeoI,GAC/BG,EAAarpB,OAAK8gB,eAAehW,GAEjC/E,EAAS/F,OAAKghB,uBAChB9gB,EAA0BF,OAAK8H,cAAcgD,IAEjD,IAAK,IAAItG,EAAI,EAAGA,EAAI2gB,IAAS3gB,EAAG,CAC9B,MAAME,EAAM1E,OAAK2E,WAAWH,EAAG4kB,EAAOzB,GAGhC/iB,EAAmB,IAAIhF,MAAM8E,EAAI9C,QACvC,IAAK,IAAI4C,EAAI,EAAGA,EAAII,EAAOhD,OAAQ4C,IACjCI,EAAOJ,GAAKE,EAAIykB,EAAK3kB,IAIvBuB,EADiB/F,OAAKkL,WAAWtG,EAAQwkB,EAAOC,IAC7BtkB,EAAMP,GAE3B,OAAOuB,WCxBOujB,GACZroB,EAAuBkD,EAAcjD,EAAiBhB,GAMxD,MAAMqpB,EAAQvpB,OAAKqG,eAAelC,EAAMjD,GAAO,GAyDzC4J,EAAW,CAAC,EAAG5J,EAAM,GAAI,GAC/B,IAAK,IAAIsD,EAAI,EAAGA,EAAI+kB,EAAO/kB,IACzBsG,EAAS,IAAM5J,EAAMsD,GAEvBsG,EAAS,GAAK5J,EAAMqoB,GACpB,IAAK,IAAI/kB,EAAI+kB,EAAQ,EAAG/kB,EAAItD,EAAMU,OAAQ4C,IACxCsG,EAAS,IAAM5J,EAAMsD,GAKvB,MAAMglB,EAA0C,GAG1C3e,EAAU,IAAI6X,WAAWxhB,EAAMqoB,IAE/BE,EAAc,IAAI3K,eAAahU,EAAU5K,EAAOe,GAGhDyoB,EAA0B,GAC1BC,EAA6B,IAAhB7e,EAAS,IAA4B,IAAhBA,EAAS,GACjD,IAAK,IAAItG,EAAI,EAAGA,EAAItD,EAAMqoB,GAAQ/kB,IAAK,CAErC,IAAIolB,EACJ,GAAID,EAEFC,EAAU3oB,EAAOuD,GAAG0U,eACf,CACL,MAAM2Q,EAAa,GACnB,IAAK,IAAIC,EAAI,EAAGA,EAAIhf,EAAS,GAAIgf,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAIjf,EAAS,GAAIif,IAC/BF,EAAWnhB,KAAK+gB,EAAYpoB,IAAIyoB,EAAGtlB,EAAGulB,IAG1CH,EAAUC,EAAWG,KAAK,KAI5B,QAAgCC,IAA5BT,EAAeI,GACjB/e,EAAQrG,GAAKglB,EAAeI,OACvB,CACL,MAAMM,EAAcC,OAAOC,KAAKZ,GAAgB5nB,OAChD4nB,EAAeI,GAAWM,EAC1Brf,EAAQrG,GAAK0lB,EACbR,EAAchhB,KAAKlE,IAOvB,MAAM6lB,EAAiBvf,EAASzF,QAChCglB,EAAe,GAAKF,OAAOC,KAAKZ,GAAgB5nB,OAChD,MAAM0oB,EAAe,IAAIxL,eAAauL,EAAgBnqB,GACtDwpB,EAAc5pB,QAAQ,CAACyqB,EAAoB/lB,KACzC,IAAK,IAAIslB,EAAI,EAAGA,EAAIhf,EAAS,GAAIgf,IAC/B,IAAK,IAAIC,EAAI,EAAGA,EAAIjf,EAAS,GAAIif,IAC/BO,EAAa7oB,IAAIgoB,EAAYpoB,IAAIyoB,EAAGS,EAAoBR,GAAID,EAAGtlB,EAAGulB,KAOxE,MAAM5L,EAAcjd,EAAMmE,QAG1B,OAFA8Y,EAAYoL,GAASc,EAAe,GAE7B,CACLG,aAAcF,EAAarpB,OAC3Bkd,YAAAA,EACAtT,QAAAA,iRC3HY,MAAO,IAAM,IAAIpK,EAAkB,GCT5C,MAAMgqB,GACTvF,EAAgBwF,MAAMnF,GAAOA,GAAM,EAAIA,EAAMne,KAAKue,IAAIJ,GAAM,GAEnDoF,GAA0B,CACrC9K,WAAY6K,MACZ3K,YAAa,MACbC,WAAYyK,ICJRG,GAAYnK,EACd,CAACoK,EAAgB3jB,IAAmB2jB,EAAS,EAAI3jB,EAAS2jB,EAASA,YAEvDC,GAAM7K,GAEpB,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpBtc,EAACA,EAACyT,MAAEA,GAAS8I,EAEnBzgB,EAAiB,CAACkE,EAAGyT,GAAQ,SAE7B,MAAMrP,EAAQqY,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnCga,EAAQmF,EAAQtf,KAAKO,IAAI+V,EAAM5V,QAAQP,QAEtC6hB,EAAYnE,GACfiM,GAAUjnB,EAAEzC,MAAOkW,EAAMlW,MAAO6G,EAAOkT,EAAOtX,EAAEzD,OAEpD,OAAOkgB,EAAQmB,eAAe5C,EAAahb,EAAEzD,MAAO4iB,GAG/C,MAAMiI,GAA4B,CACvClL,WAAYmL,QACZjL,YAAa,MACbC,WAAY8K,ICxBDG,GAAO/F,EAAgBgG,OAAO3F,GAAOne,KAAKb,IAAI,EAAGgf,IAEjD4F,GAA2B,CACtCtL,WAAYqL,OACZnL,YAAa,MACbC,WAAYiL,ICLDG,GACTlG,EAAgBmG,QAAQ9F,GAAOne,KAAKwB,IAAIxB,KAAKb,IAAI,EAAGgf,GAAK,IAEhD+F,GAA4B,CACvCzL,WAAYwL,QACZtL,YAAa,MACbC,WAAYoL,aCDEG,GACZnL,EAAyBzc,EAAe6nB,EACxCC,GACF,GAAmB,WAAfD,EACF,OAAO9J,EAAS,CAACxB,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,IACzB,GAAmB,SAAfoL,EACT,OAAOP,GAAK,CAAC/K,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,IACrB,GAAmB,QAAfoL,EACT,OAAOf,GAAI,CAACvK,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,IACpB,GAAmB,UAAfoL,EACT,OAAOJ,GAAM,CAAClL,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,IACtB,GAAmB,UAAfoL,EACT,OAAOV,GAAM,CAAC5K,OAAQ,CAACvc,EAAAA,EAAGyT,MAAOqU,GAAyBrL,QAAAA,IAE5D,MAAM,IAAItd,MACN,cAAc0oB,4DCpBJhmB,GACZya,GAGF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,GACNhf,MAACA,GAASihB,EAEVgD,EAAQnlB,OAAK8H,cAAcnE,EAAEzC,OAC7BwqB,EAAS1rB,OAAK2rB,uBAAuBzqB,EAAOikB,GAC5CyG,EAAS5rB,OAAK8H,cAAc4jB,GAElC1rB,OAAKC,OACDklB,IAAUyG,EACV,IAAM,kBAAkBF,UAAeE,0BACnC,UAAUjoB,EAAEzC,cAAcikB,qCAC1B,gDAER/E,EAAQuB,OAAOhe,EAAEnC,QAEjB,MAAMwd,EAAQoB,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAEjC,GAAgC,MAA5Bwd,EAAM1c,mBAA4B,CACpC,MAAME,EAAOwc,EAAM1c,mBAAmBE,KAChCE,EAAOsc,EAAM1c,mBAAmBI,KAEtCF,EAAKtB,MAAQwqB,EACbhpB,EAAKxB,MAAQwqB,EAGf,MAAO,CAAClqB,OAAQmC,EAAEnC,OAAQN,MAAOwqB,EAAQxrB,MAAOyD,EAAEzD,OAG7C,MAAM2rB,GAA8B,CACzChM,WAAYiM,UACZ/L,YAAa,MACbC,WAAYxa,aCjCEumB,GAAY9L,GAK1B,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3BvZ,EAACA,EAACE,EAAEA,GAAKsZ,GACT8L,WAACA,EAAUC,WAAEA,GAAc9J,EAEjC1iB,EAAiB,CAACiH,EAAGE,GAAI,UAEzB,MAAMqa,EAAQva,EAAExF,MAAMU,OAChBsf,EAAQta,EAAE1F,MAAMU,OAEhBsqB,EAAcF,EAAatlB,EAAExF,MAAM+f,EAAQ,GAAKva,EAAExF,MAAM+f,EAAQ,GAChEkL,EAAcF,EAAarlB,EAAE1F,MAAMggB,EAAQ,GAAKta,EAAE1F,MAAMggB,EAAQ,GAEhEkL,EAAcJ,EAAatlB,EAAExF,MAAM+f,EAAQ,GAAKva,EAAExF,MAAM+f,EAAQ,GAChEoL,EAAcJ,EAAarlB,EAAE1F,MAAMggB,EAAQ,GAAKta,EAAE1F,MAAMggB,EAAQ,GAEhEoL,EAAa5lB,EAAExF,MAAMmE,MAAM,GAAI,GAC/BknB,EAAa3lB,EAAE1F,MAAMmE,MAAM,GAAI,GAE/BmnB,EAAYxsB,OAAK8H,cAAcwkB,GAC/BG,EAAYzsB,OAAK8H,cAAcykB,GAE/BG,EACFF,IAAcC,GAA2B,IAAdD,GAAiC,IAAdC,EAElDzsB,OAAKC,OACDghB,GAAS,GAAKC,GAAS,GAAKwL,EAC5B,IAAM,kIAEF,wBAAwBJ,WAAoBC,OAEpD,MAEMxoB,GADFyoB,EAAYC,EAAY/lB,EAAExF,MAAMmE,MAAM,GAAI,GAAKuB,EAAE1F,MAAMmE,MAAM,GAAI,IAClCsnB,OAAO,CAACP,EAAaC,IAExDrsB,OAAKC,OACDisB,IAAgBC,EAChB,IAAM,kCAAkCD,WACpC,GAAGC,6BAAuCzlB,EAAExF,aAC5C,GAAG0F,EAAE1F,wBAAwB8qB,IAC7B,mBAAmBC,iBAE3B,MAEMW,EAAWX,EAAa,CAACQ,EAAWJ,EAAaF,GACzB,CAACM,EAAWN,EAAaE,GAGjDQ,EAAMrnB,GAAQ,CAAC0a,OAAQ,CAACvc,EAAG+C,GAAI0Z,QAAAA,EAAS+B,MAAO,CAACjhB,MANrC8qB,EAAa,CAACQ,EAAWN,EAAaE,GACzB,CAACI,EAAWJ,EAAaF,MAMjDY,EAAMtnB,GAAQ,CAAC0a,OAAQ,CAACvc,EAAGiD,GAAIwZ,QAAAA,EAAS+B,MAAO,CAACjhB,MAAO0rB,KAEvDG,EAAYf,EAAaa,EAAI3rB,MAAM,GAAK2rB,EAAI3rB,MAAM,GAClD8rB,EAAUhB,EAAaa,EAAI3rB,MAAM,GAAK2rB,EAAI3rB,MAAM,GAChD+rB,EAAWhB,EAAaa,EAAI5rB,MAAM,GAAK4rB,EAAI5rB,MAAM,GACjDgsB,EAAW9lB,KAAKb,IAAIimB,EAAWC,GAE/BU,EAAY/M,EAAQtf,KAAKO,IAAIwrB,EAAIrrB,QAAQP,OACzCmsB,EAAYhN,EAAQtf,KAAKO,IAAIyrB,EAAItrB,QAAQP,OAEzCosB,EAAartB,OAAK8gB,eAAe+L,EAAI3rB,OACrCosB,EAAattB,OAAK8gB,eAAegM,EAAI5rB,QAEpCqsB,EAAQC,EAAYC,GAAczB,EACrC,CAACqB,EAAW,GAAI,EAAGA,EAAW,IAC9B,CAACA,EAAW,GAAIA,EAAW,GAAI,IAC5BK,EAAYC,EAAYC,GAAU3B,EACrC,CAAC,EAAGqB,EAAW,GAAIA,EAAW,IAC9B,CAACA,EAAW,GAAI,EAAGA,EAAW,IAE5B7oB,EAAOuoB,EAAUC,EACjBlnB,EAAS1B,SAAO,CAAC6oB,EAAUF,EAASC,GAAWJ,EAAI3sB,OAEnD0Y,EAAU7S,EAAO9E,OACjB+Y,EAAYoG,EAAQpG,UAE1B,IAAK,IAAI6T,EAAK,EAAGA,EAAKX,EAAUW,IAC9B,IAAK,IAAIC,EAAK,EAAGA,EAAKd,EAASc,GAAM9T,EACnC,IAAK,IAAI+T,EAAK,EAAGA,EAAKd,EAAUc,GAAM/T,EACpC,IAAK,IAAIgU,EAAK,EAAGA,EAAKjB,EAAWiB,GAAMhU,EAAW,CAEhD,MAAMiU,EAAS7mB,KAAKwB,IAAIklB,EAAK9T,EAAWgT,GAClCkB,EAAS9mB,KAAKwB,IAAImlB,EAAK/T,EAAWiT,GAClCkB,EAAS/mB,KAAKwB,IAAIolB,EAAKhU,EAAW+S,GAExC,IAAK,IAAIvoB,EAAIspB,EAAItpB,EAAIypB,EAAQzpB,IAC3B,IAAK,IAAIK,EAAIkpB,EAAIlpB,EAAIqpB,EAAQrpB,IAAK,CAChC,IAAIkC,EAAM,EAEV,IAAK,IAAI+C,EAAIkkB,EAAIlkB,EAAIqkB,EAAQrkB,IAAK,CAChC,MAAMskB,EAAehnB,KAAKwB,IAAIilB,EAAIrB,EAAY,GAAKe,EAC7Cc,EAAejnB,KAAKwB,IAAIilB,EAAIpB,EAAY,GAAKmB,EAKnD7mB,GAHIomB,EAAUiB,EAAe5pB,EAAIgpB,EAAa1jB,EAAI2jB,GAE9CL,EAAUtjB,EAAI4jB,EAAa7oB,EAAI8oB,EAAaU,GAGlDzV,EAAQiV,EAAKppB,GAAQD,EAAIyoB,EAAWpoB,KAAOkC,GAYvD,OAJAqZ,EAAQmC,8BAA8BsK,GACtCzM,EAAQmC,8BAA8BuK,GAG/B1M,EAAQmB,eACXxd,EAAUgC,EAAO7F,MAAO6F,EAAO9E,QAG9B,MAAMqtB,GAAkC,CAC7CzO,WAAY0O,cACZxO,YAAa,MACbC,WAAY+L,ICjFP,MAAMyC,GAAmC,CAC9C3O,WAAY4O,eACZ1O,YAAa,MACbC,oBAzC2BC,GAK3B,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3BvZ,EAACA,EAACE,EAAEA,EAACuQ,KAAEA,EAAIsU,uBAAEA,GAA0BvL,GACvC8L,WAACA,EAAUC,WAAEA,EAAUT,WAAEA,GAAcrJ,EAE7C,IAAIuM,EACAC,EACAC,EAEJ,MAAMC,EAA8B,GAIpCH,EADI3C,GAAY,CAAC7L,OAAQ,CAACxZ,EAAAA,EAAGE,EAAAA,GAAIub,MAAO,CAAC6J,WAAAA,EAAYC,WAAAA,GAAa7L,QAAAA,IAG9DjJ,IACFwX,EAAS7J,EAAI,CAAC5E,OAAQ,CAACxZ,EAAGgoB,EAAS9nB,EAAGuQ,GAAOiJ,QAAAA,IAC7CyO,EAAcnmB,KAAKgmB,GACnBA,EAAUC,GAERnD,IACFoD,EACIrD,GAAgBnL,EAASsO,EAASlD,EAAYC,GAClDoD,EAAcnmB,KAAKgmB,GACnBA,EAAUE,GAGZ,IAAK,MAAMpqB,KAAKqqB,EACdzO,EAAQmC,8BAA8B/d,GAGxC,OAAOkqB,ICvCII,GAAO5J,EAAgB6J,OAAOxJ,GAAOne,KAAK0nB,KAAKvJ,IAE/CyJ,GAA2B,CACtCnP,WAAYkP,OACZhP,YAAa,MACbC,WAAY8O,ICLDG,GAAQ/J,EAAgBgK,QAAQ3J,GAAOne,KAAK6nB,MAAM1J,IAElD4J,GAA4B,CACvCtP,WAAYqP,QACZnP,YAAa,MACbC,WAAYiP,ICLDG,GAAOlK,EAAgBmK,OAAO9J,GAAOne,KAAKgoB,KAAK7J,IAE/C+J,GAA2B,CACtCzP,WAAYwP,OACZtP,YAAa,MACbC,WAAYoP,ICLDG,GAAQrK,EAAgBsK,QAAQjK,GAAOne,KAAKmoB,MAAMhK,IAElDkK,GAA4B,CACvC5P,WAAY2P,QACZzP,YAAa,MACbC,WAAYuP,ICLDG,GAAOxK,EAAgByK,OAAOpK,GAAOne,KAAKsoB,KAAKnK,IAE/CqK,GAA2B,CACtC/P,WAAY8P,OACZ5P,YAAa,MACbC,WAAY0P,ICLDG,GAAQ3K,EAAgB4K,QAAQvK,GAAOne,KAAKyoB,MAAMtK,IAElDwK,GAA4B,CACvClQ,WAAYiQ,QACZ/P,YAAa,MACbC,WAAY6P,aCPEG,GACZziB,EAAqB2b,EAAkBhpB,EAAiB4D,EACxDmI,EACAC,GACF,MAAME,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBE,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBE,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCI,EAASd,EAASY,QAAQG,IAC1BC,EAAUhB,EAASY,QAAQK,KAE3BC,EACY,QAAbjB,EAAqBkB,OAAOC,kBACPD,OAAOE,kBAE3BE,EAASnJ,SAAO4H,EAASlI,SAAU7D,GACnCuN,EAAaD,EAAOvM,OAEpByM,EACFzB,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAC9D6J,EAAmB3B,EAASlI,SAAS,GAAKkI,EAASlI,SAAS,GAC5D8J,EAAmB5B,EAASlI,SAAS,GAE3C,IAAK,IAAI6C,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EAAG,CAC3C,MAAMoH,EAAoBpH,EAAI8G,EACxBO,EAAmBrH,EAAI9C,EAAQ,GACrC,IAAK,IAAI9B,EAAI,EAAGA,EAAIiK,EAASkC,aAAcnM,EACzC,IAAK,IAAIiuB,EAAK,EAAGA,EAAKhkB,EAAS2C,YAAaqhB,EAAI,CAC9C,MAAMC,EAAWD,EAAK7jB,EAAeW,EAC/BojB,EAAQ/oB,KAAKb,IAAI,EAAG2pB,GACpBE,EACFhpB,KAAKwB,IAAIqD,EAAS+C,SAAUtC,EAAwBwjB,GAClDjhB,EAAkBjB,EAAoBiiB,EAAKriB,EACjD,IAAK,IAAIyiB,EAAK,EAAGA,EAAKpkB,EAASkD,WAAYkhB,EAAI,CAC7C,MAAMC,EAAWD,EAAKhkB,EAAcY,EAC9BsjB,EAAQnpB,KAAKb,IAAI,EAAG+pB,GACpBE,EACFppB,KAAKwB,IAAIqD,EAASsD,QAAS5C,EAAuB2jB,GACtD,IAAI7gB,EAActC,EACduC,EAAW,EACXC,EAAQ,EACZ,IAAK,IAAI8gB,EAAKN,EAAOM,EAAKL,EAAOK,GAAMlkB,EAAgB,CACrD,MAAMmkB,EAAWziB,EAAmBwiB,EAAK3sB,EAAQ,GACjD,IAAK,IAAI6sB,EAAKJ,EAAOI,EAAKH,EAAOG,GAAMnkB,EAAe,CACpD,MACMyD,EAAQ1C,EADGmjB,EAAWC,EAAK7sB,EAAQ,GACR9B,GACf,QAAbkK,GAAsB+D,EAAQR,EACjCA,EAAcQ,EACQ,QAAb/D,IACTwD,GAAYO,EACZN,KAGJ,GAAIO,MAAMT,GACR,MAIJhC,EADqBwB,EAAkBohB,EAAKxiB,EAAmB7L,GAE9C,QAAbkK,EAAqBwD,EAAWC,EAAQF,IAKpD,OAAOjC,WAGOojB,GACZrjB,EAAqB2b,EAAkBhpB,EACvC+L,EAAmC4kB,GAAmB,EACtDC,GAAsB,GACxB,MAAMtf,EAAenN,SAAO4H,EAASlI,SAAU,SACzCqI,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBE,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBE,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCI,EAASd,EAASY,QAAQG,IAC1BC,EAAUhB,EAASY,QAAQK,KAE3B5I,EAAOD,SAAO6kB,EAAQhpB,EAAOqN,GACnC,IAAK,IAAI3G,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EACxC,IAAK,IAAI5E,EAAI,EAAGA,EAAIiK,EAASkC,aAAcnM,EACzC,IAAK,IAAIiuB,EAAK,EAAGA,EAAKhkB,EAAS2C,YAAaqhB,EAAI,CAC9C,MAAMC,EAAWD,EAAK7jB,EAAeW,EACrC,IAAIojB,EAAQD,EACZ,KAAOC,EAAQ,GACbA,GAAS5jB,EAGX,MAAM6jB,EACFhpB,KAAKwB,IAAIqD,EAAS+C,SAAUtC,EAAwBwjB,GACxD,IAAK,IAAIG,EAAK,EAAGA,EAAKpkB,EAASkD,WAAYkhB,EAAI,CAC7C,MAAMC,EAAWD,EAAKhkB,EAAcY,EACpC,IAAIsjB,EAAQD,EACZ,KAAOC,EAAQ,GACbA,GAAS/jB,EAEX,MAAMgkB,EACFppB,KAAKwB,IAAIqD,EAASsD,QAAS5C,EAAuB2jB,GACtD,IAAI7e,EAAWrE,OAAOC,kBAClBqE,GAAe,EAEnB,IAAK,IAAI+e,EAAKN,EAAOM,EAAKL,EAAOK,GAAMlkB,EAAgB,CACrD,MAAMwkB,EAAKN,EAAKP,EAChB,IAAK,IAAIS,EAAKJ,EAAOI,EAAKH,EAAOG,GAAMnkB,EAAe,CACpD,MAAMwkB,EAAKL,EAAKL,EACVrgB,EAAQ3L,EAAKjD,IAAIuF,EAAG6pB,EAAIE,EAAI3uB,GAC9BiO,EAAQwB,IACVA,EAAWxB,EAETyB,EADEmf,EACYC,IACRlqB,EAAIqF,EAAS+C,SAAWyhB,GAAMxkB,EAASsD,QAAUohB,GAC3C1kB,EAASkC,WACbnM,GACHyuB,EAAKxkB,EAASsD,QAAUohB,GAAM1kB,EAASkC,WAAanM,EAE3C+uB,EAAKpkB,EAAuBqkB,IAKlDxf,EAAa/P,IAAIiQ,EAAa9K,EAAGqpB,EAAII,EAAIruB,IAKjD,OAAOwP,EC7FF,MAAMyf,GAA8B,CACzCpR,WAAYqR,UACZnR,YAAa,MACbC,oBAnCEC,GAGF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,EACZzgB,EAAiBkE,EAAG,WACpB,MAAMwtB,WAACA,EAAUrtB,QAAEA,EAAOstB,IAAEA,EAAGC,gBAAEA,GAAmBlP,EAGpDniB,OAAKC,OACDqB,eAAagwB,+BAA+BxtB,EAH9B,GAId,IAAM,4DACF,eAAeA,uBAEvB,MAAMmI,EAAW3K,eAAaiwB,kBAC1B5tB,EAAEzC,MAA2CiwB,EAAYrtB,EAR3C,EASHstB,EAAKC,GACpB,IAAI/rB,EAEJ,GAA6B,IAAzB2G,EAASsE,aAA+C,IAA1BtE,EAASqE,cACvCtQ,OAAKwxB,YAAYvlB,EAASwlB,QAASxlB,EAASlI,UAC9CuB,EAAMoc,EAAS,CAACxB,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,QACxB,CACL,MAAM7S,EAAU6S,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACrC6C,EAAU9D,OAAK8gB,eAAend,EAAEzC,OAChCmD,EAAS2rB,GAAKziB,EAAS5J,EAAEzC,MAAOyC,EAAEzD,MAAO4D,EAASmI,EAAU,OAClE3G,EAAM8a,EAAQmB,eACVtV,EAASlI,SAAUJ,EAAEzD,MAAOmE,EAAOpD,QAEzC,OAAOqE,ICkCF,MAAMosB,GAAsC,CACjD7R,WAAY8R,kBACZ5R,YAAa,MACbC,oBArE8BC,GAK9B,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3B7V,GAACA,EAAE0X,MAAEA,GAAS5B,EACdvc,EAAIme,EACVriB,EAAiB,CAAC2K,EAAI0X,GAAQ,mBAC9B,MAAMqP,WAACA,EAAUrtB,QAAEA,EAAOstB,IAAEA,GAAOjP,EAE7BlW,EAAW3K,eAAaiwB,kBAC1B5tB,EAAEzC,MAA2CiwB,EAAYrtB,EACzD,EAAmBstB,GACjBhlB,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBiE,EAAerE,EAASqE,aACxBC,EAActE,EAASsE,YACvBhE,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBE,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCM,EAAUN,EAAuB,EAAIV,EAASY,QAAQK,KACtDH,EAASL,EAAwB,EAAIT,EAASY,QAAQG,IACtDwD,EACFnM,SAAgBV,EAAEzC,MAA2C,WAE3DuP,EAAgB,GAAKH,EAAeC,GAEpCqhB,EAASxR,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,OACrCyP,EAAQrM,SACV+F,EAAGlJ,MAA2C,UAAW0wB,GAE7D,IAAK,IAAIhrB,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EACxC,IAAK,IAAI5E,EAAI,EAAGA,EAAIiK,EAASkC,aAAcnM,EACzC,IAAK,IAAIuS,EAAM,EAAGA,EAAMtI,EAAS+C,WAAYuF,EAC3C,IAAK,IAAIO,EAAM,EAAGA,EAAM7I,EAASsD,UAAWuF,EAAK,CAE/C,MAAM+c,EAAYtd,EAAMxH,EAClB+kB,EAAYhd,EAAM7H,EACxB,IAAIgE,EAAU,EACd,IAAK,IAAI8f,EAAK,EAAGA,EAAKrkB,EAAuBqkB,GAAMxkB,EAAgB,CACjE,MAAMsK,GAAOgb,EAAYd,GAAM3kB,EAC/B,KAAIyK,EAAM,GAAKA,GAAO5K,EAAS2C,WAC3BxH,KAAKE,MAAMuP,KAASA,GAGxB,IAAK,IAAIma,EAAK,EAAGA,EAAKrkB,EAAsBqkB,GAAMxkB,EAAe,CAC/D,MAAMwK,GAAO8a,EAAYd,GAAM3kB,EAC3B2K,EAAM,GAAKA,GAAO/K,EAASkD,UAC3B/H,KAAKE,MAAM0P,KAASA,IAKxB/F,GADcP,EAAMrP,IAAIuF,EAAGiQ,EAAKG,EAAKhV,KAIzCwO,EAAG/O,IAAIwP,EAAUR,EAAe7J,EAAG2N,EAAKO,EAAK9S,GAKrD,OAAOoe,EAAQmB,eAAe/Q,EAAGtP,MAAOsP,EAAGtQ,MAAOsQ,EAAGvP,UCKhD,MAAM8wB,GAAgC,CAC3ClS,WAAYmS,iBACZjS,YAAa,MACbC,oBAtEwBC,GAKxB,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACsuB,MAAEA,EAAKjqB,OAAEA,EAAMkqB,KAAEA,EAAIC,SAAEA,GAAYjS,EAE3ClgB,OAAKC,OACDiyB,EAAKhxB,MAAMU,SAAWuwB,EAASjxB,MAAMU,OACrC,IAAM,gFAEV5B,OAAKC,OACS,MAAV+H,GAAkBkqB,EAAKhxB,MAAMU,SAAWoG,EAAO9G,MAAMU,OACrD,IAAM,8EAEV5B,OAAKC,OACQ,MAATgyB,GAAiBC,EAAKhxB,MAAMU,SAAWqwB,EAAM/wB,MAAMU,OACnD,IAAM,6EAGVnC,EAAiB,CAACkE,EAAGuuB,EAAMC,EAAUF,EAAOjqB,GAAS,aAErD,IAAIoqB,gBAACA,GAAmBjQ,EACD,MAAnBiQ,IACFA,EAAkB,MAGpB,MAAMrtB,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnCoxB,EAAQjS,EAAQtf,KAAKO,IAAI6wB,EAAK1wB,QAAQP,OACtCqxB,EAAUlS,EAAQtf,KAAKO,IAAI8wB,EAAS3wB,QAAQP,OAC5CsxB,EAAQN,EAAQ7R,EAAQtf,KAAKO,IAAI4wB,EAAMzwB,QAAQP,OAC/B,IAAIsJ,aAAa,CAAC,IAClCioB,EAAUxqB,EACZoY,EAAQtf,KAAKO,IAAI2G,EAAOxG,QAAQP,OAChC,IAAIsJ,aAAa,CAAC,IAChBwd,EAAU,IAAIxd,aAAaxF,EAAMnD,QAEjC6wB,EAAgBD,EAAQ5wB,OACxB8wB,EAAcH,EAAM3wB,OACpB+wB,EAAgBL,EAAQ1wB,OACxBgxB,EAAcP,EAAMzwB,OAE1B,IAAIixB,EAAO,EACPC,EAAK,EACLC,EAAK,EACLC,EAAK,EACT,IAAK,IAAIxuB,EAAI,EAAGA,EAAIO,EAAMnD,SAAU4C,EAClCujB,EAAQvjB,GAAKguB,EAAQK,MAChB9tB,EAAMP,GAAK6tB,EAAMS,MAASP,EAAMQ,KAC7B3rB,KAAKggB,KAAKkL,EAAQU,KAAQZ,GAC9BS,GAAQJ,IACVI,EAAO,GAELC,GAAMF,IACRE,EAAK,GAEHC,GAAML,IACRK,EAAK,GAEHC,GAAML,IACRK,EAAK,GAGT,OAAO5S,EAAQmB,eAAe5d,EAAEzC,MAAOyC,EAAEzD,MAAO6nB,KCjErCkL,GAAO/N,EAAgBgO,cAAa,CAAC3N,EAAIpD,KACpD,MAAMgR,EAAYhR,EAClB,OAAIoD,EAAK4N,EAAUC,aACVD,EAAUC,aAEZ7N,EAAK4N,EAAUE,aAAeF,EAAUE,aAAe9N,IAGnD+N,GAA2B,CACtCzT,WAAYqT,cACZnT,YAAa,MACbC,WAAYiT,aCXEvwB,GAAKud,GAEnB,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpB6B,MAACA,GAAS5B,EAEVxd,EAAO0d,EAAQtf,KAAKO,IAAIygB,EAAMtgB,QAAQc,mBAAmBI,KACzD6wB,EAAUnT,EAAQtf,KAAKO,IAAIqB,EAAKlB,QAAQP,OAK9C,OAAOmf,EAAQmB,eAAe7e,EAAKxB,MAAOwB,EAAKxC,MAAOqzB,GAGjD,MAAMC,GAA2B,CACtC3T,WAAY4T,OACZ1T,YAAa,MACbC,WAAYtd,aCZEiqB,GACZ1M,GAEF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3B9b,KAACA,GAAQge,EAEToH,EAAQvpB,OAAKqG,eAAelC,EAAM+b,EAAO,GAAGhf,OAAO,GACzD,IAAI6C,EAAWzC,eAAa2C,gBAAgBic,EAAOne,IAAIhC,GAAKA,EAAEmB,OAAQqoB,GAEtE,GAAqC,IAAjCvpB,OAAK8H,cAAc/D,GACrB,OAAOqc,EAAQmB,eAAexd,EAAUmc,EAAO,GAAGhgB,MAAO,IAI3D,MAAMwzB,EAAUxT,EAAOyT,OAAO5zB,GAAKC,OAAK8H,cAAc/H,EAAEmB,OAAS,GACjE,GAAuB,IAAnBwyB,EAAQ9xB,OACV,OAAO8xB,EAAQ,GAGjB,MAAME,EAASF,EAAQ3xB,IAAIhC,GAAKA,EAAEmB,OAGlC,GAFAI,eAAauyB,uBAAuBD,EAAQrK,GAEnB,cAArBmK,EAAQ,GAAGxzB,MAAuB,CACpC,MAAM4zB,EAAQJ,EAAQ3xB,IAAKhC,GAAMyC,EAAK,CAAC0d,OAAQ,CAAC4B,MAAO/hB,GAAIqgB,QAAAA,KACrD2T,EAAQL,EAAQ3xB,IAAKhC,GAAM2C,GAAK,CAACwd,OAAQ,CAAC4B,MAAO/hB,GAAIqgB,QAAAA,KAErD4T,EAAerH,GAAO,CAACzM,OAAQ4T,EAAO1T,QAAAA,EAAS+B,MAAO,CAAChe,KAAMolB,KAC7D0K,EAAetH,GAAO,CAACzM,OAAQ6T,EAAO3T,QAAAA,EAAS+B,MAAO,CAAChe,KAAMolB,KAE7DxjB,EACFsb,EAAQ,CAACnB,OAAQ,CAAC1d,KAAMwxB,EAActxB,KAAMuxB,GAAe7T,QAAAA,IAO/D,OALA0T,EAAMh0B,QAAQ2S,GAAK2N,EAAQmC,8BAA8B9P,IACzDshB,EAAMj0B,QAAQ0E,GAAK4b,EAAQmC,8BAA8B/d,IACzD4b,EAAQmC,8BAA8ByR,GACtC5T,EAAQmC,8BAA8B0R,GAE/BluB,EAUT,MAAMmuB,EAAWR,EAAQ3xB,IAAIhC,IAC3B,MAAMo0B,EAAYn0B,OAAK8H,cAAc/H,EAAEmB,MAAMmE,MAAMkkB,IAEnD,OAAO/jB,GAAQ,CAAC0a,OAAQ,CAACvc,EAAG5D,GAAIqgB,QAAAA,EAAS+B,MAAO,CAACjhB,MADnC,EAAE,EAAGizB,QAKrBpwB,EACIzC,eAAa2C,gBAAgBiwB,EAASnyB,IAAIhC,GAAKA,EAAEmB,OAAQ,GAE7D,MAAM6mB,EAAU/nB,OAAKghB,uBACjB0S,EAAQ,GAAGxzB,MAAoBF,OAAK8H,cAAc/D,IAEtD,GAA6B,IAAzBmwB,EAAS,GAAGhzB,MAAM,GAAU,CAE9B,IAAI8G,EAAS,EACbksB,EAASp0B,QAAQC,IACf,MAAM8X,EAAMuI,EAAQtf,KAAKO,IAAItB,EAAEyB,QAAQP,OACjCwD,EAAOzE,OAAK8H,cAAc/H,EAAEmB,OAElC6mB,EAAQtmB,IAAIoW,EAAK7P,GACjBA,GAAUvD,QAEP,CACL,IAAIwR,EAAY,EAEhBie,EAASp0B,QAAQC,IACf,MAAMq0B,EAAQhU,EAAQtf,KAAKO,IAAItB,EAAEyB,QAAQP,OAEzC,IAAIozB,EAAO,EAEX,IAAK,IAAIC,EAAM,EAAGA,EAAMv0B,EAAEmB,MAAM,KAAMozB,EAAK,CACzC,MAAMC,EAASD,EAAMvwB,EAAS,GAAKkS,EACnC,IAAK,IAAIue,EAAM,EAAGA,EAAMz0B,EAAEmB,MAAM,KAAMszB,EACpCzM,EAAQwM,EAASC,GAAOJ,EAAMC,KAIlCpe,GAAalW,EAAEmB,MAAM,KAIzB,MAAMuzB,EACFnzB,eAAa2C,gBAAgByvB,EAAQ3xB,IAAIhC,GAAKA,EAAEmB,OAAQqoB,GAEtDmL,EACFtU,EAAQmB,eAAekT,EAAevU,EAAO,GAAGhgB,MAAO6nB,GAI3D,OAFAmM,EAASp0B,QAAQC,GAAKqgB,EAAQmC,8BAA8BxiB,IAErD20B,EAGF,MAAMC,GAA6B,CACxC9U,WAAY+U,SACZ7U,YAAa,MACbC,WAAY2M,aC3GEkI,GACZ5U,GAEF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACgwB,OAAEA,GAAUzT,GACdpc,QAACA,EAAOstB,IAAEA,EAAGnX,WAAEA,EAAU6a,UAAEA,EAASzD,gBAAEA,GAAmBlP,EAE/D1iB,EAAiB,CAACkE,EAAGgwB,GAAS,UAE9B,MAAMoB,EAAczzB,eAAa0zB,wBAAwB/a,GACnDhO,EAAW3K,eAAa2zB,kBAC1BtxB,EAAEzC,MACFyyB,EAAOzyB,MAA2C4C,EAASgxB,EAAW1D,EACtEC,GAAiB,EAAuB0D,GAEtCzkB,EAAerE,EAASqE,aACxBC,EAActE,EAASsE,YACvBhE,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBS,EAAUhB,EAASY,QAAQK,KAC3BH,EAASd,EAASY,QAAQG,IAC1BkoB,EAAyC,iBAAxBjpB,EAASgO,WAE1B5P,EAAI,IAAIyU,eAAa7S,EAASlI,SAAUJ,EAAEzD,OAE1CynB,EAAW3nB,OAAK8gB,eAAend,EAAEzC,OACjCi0B,EAAgBn1B,OAAK8gB,eAAe6S,EAAOzyB,OAE3Ck0B,EAAezN,EAAS,GACxB0N,EAAaH,EAAiBvN,EAAS,GAAKA,EAAS,GACrD2N,EAAaJ,EAAiBvN,EAAS,GAAK,EAC5C4N,EAAiBL,EAAiB,EAAIvN,EAAS,GAC/C6N,EAAenrB,EAAEvG,QAAQ,GACzB2xB,EAAaP,EAAiB7qB,EAAEvG,QAAQ,GAAKuG,EAAEvG,QAAQ,GACvD4xB,EAAaR,EAAiB7qB,EAAEvG,QAAQ,GAAK,EAC7C6xB,EAAiBT,EAAiB,EAAI7qB,EAAEvG,QAAQ,GAEhDiB,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnC20B,EAAQxV,EAAQtf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,OACxC40B,EAAQxrB,EAAEpJ,OAEhB,IAAK,IAAI2F,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EAAG,CAC3C,MAAMkvB,EAAWlvB,EAAIwuB,EACfW,EAAWnvB,EAAI4uB,EACrB,IAAK,IAAIvF,EAAK,EAAGA,EAAKhkB,EAAS2C,YAAaqhB,EAAI,CAC9C,MAAM+F,EAAWD,EAAW9F,EAAKwF,EAC3BvF,EAAWD,EAAKhkB,EAASG,aAAeW,EAC9C,IAAK,IAAIgkB,EAAK,EAAGA,EAAKzgB,IAAgBygB,EAAI,CACxC,MAAMN,EAAKP,EAAWa,EAAKxkB,EAC3B,GAAIkkB,EAAK,GAAKA,GAAMxkB,EAAS+C,SAC3B,SAEF,MAAMinB,EAAWlF,EAAKoE,EAAc,GAC9Be,EAAWJ,EAAWrF,EAAK4E,EACjC,IAAK,IAAIhF,EAAK,EAAGA,EAAKpkB,EAASkD,WAAYkhB,EAAI,CAC7C,MAAM8F,EAAWH,EAAW3F,EAAKqF,EAC3BpF,EAAWD,EAAKpkB,EAASI,YAAcY,EAC7C,IAAK,IAAI+jB,EAAK,EAAGA,EAAKzgB,IAAeygB,EAAI,CACvC,MAAML,EAAKL,EAAWU,EAAKxkB,EAC3B,GAAImkB,EAAK,GAAKA,GAAM1kB,EAASsD,QAC3B,SAEF,MACM6mB,EAAWF,EAAWvF,EAAK2E,EACjC,IAAIe,EAFaJ,EAAWjF,EAAKmE,EAAc,GAG/C,IAAK,IAAImB,EAAK,EAAGA,EAAKrqB,EAASkC,aAAcmoB,EAAI,CAC/C,MAAMC,EAAOxxB,EAAMqxB,EAAWE,EAAKf,GACnC,IAAK,IAAIiB,EAAK,EAAGA,EAAKvqB,EAASwqB,cAAeD,EAC5CX,EAAMM,EAAWK,EAAKb,IAClBY,EAAOX,EAAMS,EAAWG,GAE9BH,GAAYpqB,EAASwqB,iBAQjC,OAAOrW,EAAQmB,eAAelX,EAAEnJ,MAAOmJ,EAAEnK,MAAO21B,GAG3C,MAAMa,GAA6B,CACxC7W,WAAY8W,SACZ5W,YAAa,MACbC,WAAY6U,ICnBP,MAAM+B,GAA2C,CACtD/W,WAAYgX,uBACZ9W,YAAa,MACbC,oBArEmCC,GAKnC,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACyG,GAAEA,GAAM8V,GACVpc,QAACA,EAAOstB,IAAEA,EAAGnX,WAAEA,EAAUoX,gBAAEA,EAAeyF,YAAEA,GAAe3U,EAEjE1iB,EAAiB,CAACkE,EAAGyG,GAAK,wBAE1B,MAAM2qB,EAAczzB,eAAa0zB,wBAAwB/a,GACnDhO,EAAW3K,eAAa2zB,kBAC1BtxB,EAAEzC,MAA2C41B,EAAahzB,EAC1D,EAAmBstB,EAAKC,GAAiB,EACzC0D,IAEE3oB,aAACA,EAAYC,YAAEA,EAAWiE,aAAEA,EAAYC,YAAEA,GAAetE,EACzDipB,EAAyC,iBAAxBjpB,EAASgO,WAC1B8c,EAAK,IAAIjY,eAAa7S,EAAS6qB,YAAa,WAE5CE,EAAU/qB,EAASY,QAAQK,KAC3B+pB,EAAShrB,EAASY,QAAQG,IAC1BjI,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnCi2B,EAAS9W,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,OAErCqD,EAAO,IAAIwa,eAAanb,EAAEzC,MAAOyC,EAAEzD,MAAO6E,GAC1C2L,EAAQ,IAAIoO,eAAa1U,EAAGlJ,MAAOkJ,EAAGlK,MAAOg3B,GAEnD,IAAK,IAAInG,EAAK,EAAGA,EAAKzgB,IAAgBygB,EAAI,CACxC,MAAMoG,EAAQ/vB,KAAKb,IAAI,EAAGa,KAAK0L,MAAMmkB,EAASlG,GAAM3kB,IAC9CgrB,EAAQhwB,KAAKwB,IACfqD,EAAS2C,WAAY3C,EAAS+C,SAAWioB,EAASlG,GAAM3kB,GAE5D,IAAK,IAAI4kB,EAAK,EAAGA,EAAKzgB,IAAeygB,EAAI,CACvC,MAAMqG,EAAQjwB,KAAKb,IAAI,EAAGa,KAAK0L,MAAMkkB,EAAUhG,GAAM3kB,IAC/CirB,EAAQlwB,KAAKwB,IACfqD,EAASkD,UAAWlD,EAASsD,QAAUynB,EAAUhG,GAAM3kB,GAE3D,IAAK,IAAIiqB,EAAK,EAAGA,EAAKrqB,EAASkC,aAAcmoB,EAC3C,IAAK,IAAIE,EAAK,EAAGA,EAAKvqB,EAASwqB,cAAeD,EAAI,CAChD,IAAIvlB,EAAU,EACd,IAAK,IAAIrK,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EACxC,IAAK,IAAIqpB,EAAKkH,EAAOlH,EAAKmH,IAASnH,EAAI,CACrC,MAAMQ,EAAKM,EAAKd,EAAK7jB,EAAe6qB,EACpC,IAAK,IAAI5G,EAAKgH,EAAOhH,EAAKiH,IAASjH,EAAI,CACrC,MAAMM,EAAKK,EAAKX,EAAKhkB,EAAc2qB,EAEjC/lB,GADEikB,EACU5wB,EAAKjD,IAAIuF,EAAG6pB,EAAIE,EAAI2F,GAC3B5lB,EAAMrP,IAAIuF,EAAGqpB,EAAII,EAAImG,GAEdlyB,EAAKjD,IAAIuF,EAAG0vB,EAAI7F,EAAIE,GAC3BjgB,EAAMrP,IAAIuF,EAAG4vB,EAAIvG,EAAII,IAKlC0G,EAAGt1B,IAAIwP,EAAS8f,EAAIC,EAAIsF,EAAIE,KAMpC,OAAOpW,EAAQmB,eAAewV,EAAG71B,MAAO61B,EAAG72B,MAAO62B,EAAG91B,UC+BhD,MAAMs2B,GAA0C,CACrD1X,WAAY2X,sBACZzX,YAAa,MACbC,oBAjGkCC,GAKlC,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3B7V,GAACA,EAAEupB,OAAEA,GAAUzT,GACfuX,WAACA,EAAU3zB,QAAEA,EAAOstB,IAAEA,EAAGnX,WAAEA,EAAUoX,gBAAEA,GAAmBlP,EAEhE1iB,EAAiB,CAAC2K,EAAIupB,GAAS,uBAE/B,MAAMwB,EAAgBn1B,OAAK8gB,eAAe6S,EAAOzyB,OAC3Cw2B,EAAY13B,OAAK8gB,eAAe1W,EAAGlJ,OAEzC,IAAI6zB,EAAczzB,eAAa0zB,wBAAwB/a,GACvD,MAAMhO,EAAW3K,eAAa2zB,kBAC1BwC,EAAY9D,EAAOzyB,MAA2C4C,EAC9D,EAAmBstB,EAAKC,GAAiB,EAAO0D,GAE9CvkB,EAAK,IAAIsO,eAAa7S,EAASwlB,QAAS,WACxCkG,EAAWnnB,EAAGvP,OACduJ,EAAW4V,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,OACvC22B,EAAYxX,EAAQtf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,QAC3C42B,EAAOC,EAAOC,GAAS5C,GACxBpnB,UACJA,EAASuC,aACTA,EAAYC,YACZA,EAAWpC,WACXA,EAAUa,SACVA,EAAQO,QACRA,EAAOknB,YACPA,EAAW7nB,UACXA,EAASO,SACTA,EAAQ/C,aACRA,EAAYC,YACZA,GACEJ,EACJ8oB,EAAc9oB,EAASgO,WACvB,MAAMgd,EAAS3mB,EAAe,EAAIrE,EAASY,QAAQG,IAC7CgqB,EAAUzmB,EAAc,EAAItE,EAASY,QAAQK,KAE7CgoB,EAAiC,iBAAhBH,EACjBK,EAAe5kB,EAAG1M,QAAQ,GAC1BuxB,EAAaH,EAAiB1kB,EAAG1M,QAAQ,GAAK0M,EAAG1M,QAAQ,GACzDwxB,EAAaJ,EAAiB1kB,EAAG1M,QAAQ,GAAK,EAC9CyxB,EAAiBL,EAAiB,EAAI1kB,EAAG1M,QAAQ,GACjD0xB,EAAekC,EAAU,GACzBjC,EAAaP,EAAiBwC,EAAU,GAAKA,EAAU,GACvDhC,EAAaR,EAAiBwC,EAAU,GAAK,EAC7C/B,EAAiBT,EAAiB,EAAIwC,EAAU,GAEtD,IAAK,IAAI9wB,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAI0vB,EAAK,EAAGA,EAAKnoB,IAAcmoB,EAClC,IAAK,IAAI7F,EAAK,EAAGA,EAAKzhB,IAAYyhB,EAAI,CACpC,MAAMP,EAAWO,EAAKwG,EAChB9G,EAAQ/oB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKod,EAAW9jB,IACzCgrB,EACFhwB,KAAKwB,IAAIgG,GAAY0B,EAAe4f,GAAY9jB,GAEpD,IAAK,IAAIukB,EAAK,EAAGA,EAAKphB,IAAWohB,EAAI,CACnC,MAAML,EAAWK,EAAKqG,EAChBzG,EAAQnpB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKwd,EAAWjkB,IACzCirB,EACFlwB,KAAKwB,IAAIuG,GAAWoB,EAAc+f,GAAYjkB,GAElD,IAAI4E,EAAU,EACd,IAAK,IAAIgf,EAAKE,EAAOF,EAAKmH,IAASnH,EAAI,CACrC,MAAMc,EAAKd,EAAK7jB,EAAe8jB,EAE/B,IAAK,IAAIG,EAAKE,EAAOF,EAAKiH,IAASjH,EAAI,CACrC,MACM2H,EACFxC,EAAe5uB,EAAI6uB,EAAaxF,EAAKyF,EAAarF,EAChD4H,EAAYJ,GAASvnB,EAAe,EAAIygB,GAC1C+G,GAASvnB,EAAc,GAJhB8f,EAAKhkB,EAAcikB,IAIOyH,EAAQzB,EAE7C,IAAK,IAAIE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvCvlB,GAFczG,EAASwtB,EAAWrC,EAAiBa,GACpCoB,EAAUK,EAAYzB,KAO3CmB,EAFiBvC,EAAexuB,EAAIyuB,EAAa5E,EAC7C6E,EAAa3E,EAAK4E,EAAiBe,GAClBrlB,GAM7B,OAAOmP,EAAQmB,eAAe/Q,EAAGtP,MAAOsP,EAAGtQ,MAAOsQ,EAAGvP,UCHhD,MAAMi3B,GAA6B,CACxCrY,WAAYsY,SACZpY,YAAa,MACbC,oBA1FEC,GAEF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACgwB,OAAEA,GAAUzT,GACdpc,QAACA,EAAOstB,IAAEA,EAAG0D,UAAEA,GAAa3S,EAElC1iB,EAAiB,CAACkE,EAAGgwB,GAAS,UAE9B,MAAM1nB,EAAW3K,eAAa82B,kBAC1Bz0B,EAAEzC,MACFyyB,EAAOzyB,MAAmD4C,EAC1DgxB,EAAW1D,IAET/gB,YACJA,EAAWC,aACXA,EAAYC,YACZA,EAAWjE,cACXA,EAAaC,eACbA,EAAcC,cACdA,EAAaK,QACbA,GACEZ,EACEW,EAAWC,EAAQC,MACnBG,EAAUJ,EAAQK,KAClBH,EAASF,EAAQG,IACjB3C,EAAI,IAAIyU,eAAa7S,EAASlI,SAAUJ,EAAEzD,OAE1C6E,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnC20B,EAAQxV,EAAQtf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,OACxC40B,EAAQxrB,EAAEpJ,OAEV0mB,EAAW3nB,OAAK8gB,eAAend,EAAEzC,OACjCi0B,EAAgBn1B,OAAK8gB,eAAe6S,EAAOzyB,OAEjD,IAAK,IAAI0F,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EAAG,CAC3C,MAAMkvB,EAAWlvB,EAAI+gB,EAAS,GACxBoO,EAAWnvB,EAAIyD,EAAEvG,QAAQ,GAC/B,IAAK,IAAIu0B,EAAK,EAAGA,EAAKpsB,EAASoC,WAAYgqB,EAAI,CAC7C,MAAMrC,EAAWD,EAAWsC,EAAKhuB,EAAEvG,QAAQ,GACrCw0B,EAAWD,EAAKpsB,EAASE,YAAcS,EAC7C,IAAK,IAAI2rB,EAAK,EAAGA,EAAKloB,IAAekoB,EAAI,CACvC,MAAMC,EAAKF,EAAWC,EAAKjsB,EAC3B,GAAIksB,EAAK,GAAKA,GAAMvsB,EAASwC,QAC3B,SAEF,MAAMwnB,EAAWsC,EAAKpD,EAAc,GAC9Be,EAAWJ,EAAW0C,EAAK7Q,EAAS,GAE1C,IAAK,IAAIsI,EAAK,EAAGA,EAAKhkB,EAAS2C,YAAaqhB,EAAI,CAC9C,MAAMkG,EAAWH,EAAW/F,EAAK5lB,EAAEvG,QAAQ,GACrCosB,EAAWD,EAAKhkB,EAASG,aAAeW,EAC9C,IAAK,IAAIgkB,EAAK,EAAGA,EAAKzgB,IAAgBygB,EAAI,CACxC,MAAMN,EAAKP,EAAWa,EAAKxkB,EAC3B,GAAIkkB,EAAK,GAAKA,GAAMxkB,EAAS+C,SAC3B,SAEF,MAAMypB,EAAWxC,EAAWlF,EAAKoE,EAAc,GACzCiB,EAAWF,EAAWzF,EAAK9I,EAAS,GAC1C,IAAK,IAAI0I,EAAK,EAAGA,EAAKpkB,EAASkD,WAAYkhB,EAAI,CAC7C,MAAMqI,EAAWvC,EAAW9F,EAAKpkB,EAASwqB,YACpCnG,EAAWD,EAAKpkB,EAASI,YAAcY,EAC7C,IAAK,IAAI+jB,EAAK,EAAGA,EAAKzgB,IAAeygB,EAAI,CACvC,MAAML,EAAKL,EAAWU,EAAKxkB,EAC3B,GAAImkB,EAAK,GAAKA,GAAM1kB,EAASsD,QAC3B,SAEF,MAAM8mB,EAAWoC,EAAWzH,EAAKmE,EAAc,GACzCwD,EAAWvC,EAAWzF,EAAK1kB,EAASkC,WAC1C,IAAIyqB,EAAWvC,EACf,IAAK,IAAIC,EAAK,EAAGA,EAAKrqB,EAASkC,aAAcmoB,EAAI,CAC/C,MAAMC,EAAOxxB,EAAM4zB,EAAWrC,GAC9B,IAAK,IAAIE,EAAK,EAAGA,EAAKvqB,EAASwqB,cAAeD,EAC5CX,EAAM6C,EAAWlC,IAAOD,EAAOX,EAAMgD,EAAWpC,GAElDoC,GAAY3sB,EAASwqB,mBAUrC,OAAOrW,EAAQmB,eAAelX,EAAEnJ,MAAOmJ,EAAEnK,MAAOmK,EAAEpJ,UCS7C,MAAM43B,GAA6C,CACxDhZ,WAAYiZ,yBACZ/Y,YAAa,MACbC,oBAjGqCC,GAKrC,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACyG,GAAEA,GAAM8V,GACVpc,QAACA,EAAOstB,IAAEA,EAAG0F,YAAEA,GAAe3U,EAEpC1iB,EAAiB,CAACkE,EAAGyG,GAAK,0BAE1B,MAAMud,EAAW3nB,OAAK8gB,eAAend,EAAEzC,OACjCw2B,EAAY13B,OAAK8gB,eAAe1W,EAAGlJ,OAEnC+K,EAAW3K,eAAa82B,kBAC1Bz0B,EAAEzC,MAAmD41B,EAAahzB,EAClE,EAAmBstB,GAEjBjlB,EAAcF,EAASE,YACvBC,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBgE,EAAcpE,EAASoE,YACvBC,EAAerE,EAASqE,aACxBC,EAActE,EAASsE,YAEvBwoB,EAAK,IAAIja,eAAa7S,EAAS6qB,YAAa,WAC5CkC,EAAWD,EAAG93B,QACbg4B,EAAMC,EAAMC,EAAMC,GAAQL,EAAGj1B,QAC9B0G,EAAW4V,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,QACtCo4B,EAAMC,EAAMC,EAAMC,GAAQ9B,EAC3BnqB,EAAU6S,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,QACpCw4B,EAAKC,EAAKC,EAAKC,GAAOjS,EAEvBkS,EAAW5tB,EAASY,QAAQC,MAC5BkqB,EAAU/qB,EAASY,QAAQK,KAC3B+pB,EAAShrB,EAASY,QAAQG,IAEhC,IAAK,IAAIurB,EAAK,EAAGA,EAAKloB,IAAekoB,EAAI,CACvC,MAAMuB,EAAQ1yB,KAAKb,IAAI,EAAGa,KAAK0L,MAAM+mB,EAAWtB,GAAMpsB,IAChD4tB,EAAQ3yB,KAAKwB,IACfqD,EAASoC,UAAWpC,EAASwC,QAAUorB,EAAWtB,GAAMpsB,GACtD8pB,EAAWsC,EAAKU,EAEtB,IAAK,IAAIlI,EAAK,EAAGA,EAAKzgB,IAAgBygB,EAAI,CACxC,MAAMoG,EAAQ/vB,KAAKb,IAAI,EAAGa,KAAK0L,MAAMmkB,EAASlG,GAAM3kB,IAC9CgrB,EAAQhwB,KAAKwB,IACfqD,EAAS2C,WAAY3C,EAAS+C,SAAWioB,EAASlG,GAAM3kB,GACtDqsB,EAAW1H,EAAKmI,EAAOjD,EAE7B,IAAK,IAAIjF,EAAK,EAAGA,EAAKzgB,IAAeygB,EAAI,CACvC,MAAMqG,EAAQjwB,KAAKb,IAAI,EAAGa,KAAK0L,MAAMkkB,EAAUhG,GAAM3kB,IAC/CirB,EAAQlwB,KAAKwB,IACfqD,EAASkD,UAAWlD,EAASsD,QAAUynB,EAAUhG,GAAM3kB,GACrDgqB,EAAWrF,EAAKmI,EAAOV,EAE7B,IAAK,IAAInC,EAAK,EAAGA,EAAKrqB,EAASkC,aAAcmoB,EAAI,CAC/C,MAAMsC,EAAWtC,EAAK8C,EAAO/C,EAE7B,IAAK,IAAIG,EAAK,EAAGA,EAAKvqB,EAASwqB,cAAeD,EAAI,CAChD,IAAIvlB,EAAU,EACd,IAAK,IAAIrK,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EAAG,CAC3C,MAAMkvB,EAAWlvB,EAAI6yB,EACf1D,EAAWnvB,EAAIyyB,EAErB,IAAK,IAAIhB,EAAKyB,EAAOzB,EAAK0B,IAAS1B,EAAI,CACrC,MACMnC,GADKqC,EAAKF,EAAKlsB,EAAc0tB,GACbH,EAAM5D,EACtBE,EAAWqC,EAAKiB,EAAOvD,EAE7B,IAAK,IAAI9F,EAAKkH,EAAOlH,EAAKmH,IAASnH,EAAI,CACrC,MACMmG,GADKrF,EAAKd,EAAK7jB,EAAe6qB,GACd0C,EAAMzD,EACtBC,EAAWlG,EAAKsJ,EAAOvD,EAE7B,IAAK,IAAI3F,EAAKgH,EAAOhH,EAAKiH,IAASjH,EAAI,CACrC,MAEMqI,EAAWrI,EAAKmJ,EAAOrD,EAE7BllB,GAAW1D,GAJAyjB,EAAKX,EAAKhkB,EAAc2qB,GACb4C,EAAMxD,EAGEE,GAAM9rB,EAASkuB,EAAWlC,MAKhEwC,EAASJ,EAAWpC,GAAMvlB,MAOpC,OAAOmP,EAAQmB,eAAewX,EAAG73B,MAAO63B,EAAG74B,MAAO64B,EAAG93B,UCUhD,MAAM+4B,GAA4C,CACvDna,WAAYoa,wBACZla,YAAa,MACbC,oBAxGoCC,GAKpC,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3B7V,GAACA,EAAEupB,OAAEA,GAAUzT,GACfkR,IAACA,EAAGttB,QAAEA,EAAO2zB,WAAEA,GAActV,EAEnC1iB,EAAiB,CAAC2K,GAAK,yBAEvB,MAAMstB,EAAY13B,OAAK8gB,eAAe1W,EAAGlJ,OACnCi0B,EAAgBn1B,OAAK8gB,eAAe6S,EAAOzyB,OAE3C+K,EAAW3K,eAAa82B,kBAC1BX,EAAY9D,EAAOzyB,MACnB4C,EAAS,EAAmBstB,GAE1B5gB,EAAK,IAAIsO,eAAa7S,EAASwlB,QAAS,WACxCkG,EAAWnnB,EAAGvP,QACbi5B,EAAMC,EAAMC,EAAMC,GAAQ7pB,EAAG1M,QAC9B0G,EAAW4V,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,QACtCo4B,EAAMC,EAAMC,EAAMC,GAAQ9B,EAC3BE,EAAYxX,EAAQtf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,QAC3C42B,EAAOC,EAAOC,EAAOuC,GAASnF,GAC/BpnB,UACJA,EAASsC,YACTA,EAAWC,aACXA,EAAYC,YACZA,EAAWpC,WACXA,EAAUM,QACVA,EAAOO,SACPA,EAAQO,QACRA,EAAOknB,YACPA,EAAWpoB,SACXA,EAAQO,UACRA,EAASO,SACTA,EAAQhD,YACRA,EAAWC,aACXA,EAAYC,YACZA,GACEJ,EACE4tB,EAAWxpB,EAAc,EAAIpE,EAASY,QAAQC,MAC9CmqB,EAAS3mB,EAAe,EAAIrE,EAASY,QAAQG,IAC7CgqB,EAAUzmB,EAAc,EAAItE,EAASY,QAAQK,KAEnD,IAAK,IAAItG,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAI0vB,EAAK,EAAGA,EAAKnoB,IAAcmoB,EAElC,IAAK,IAAIkC,EAAK,EAAGA,EAAK/pB,IAAW+pB,EAAI,CACnC,MAAMF,EAAWE,EAAKqB,EAChBU,EAAQnzB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKwlB,EAAWnsB,IACzC4tB,EACF3yB,KAAKwB,IAAIyF,GAAWgC,EAAcioB,GAAYnsB,GAGlD,IAAK,IAAIskB,EAAK,EAAGA,EAAKzhB,IAAYyhB,EAAI,CACpC,MAAMP,EAAWO,EAAKwG,EAChB9G,EAAQ/oB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKod,EAAW9jB,IACzCgrB,EACFhwB,KAAKwB,IAAIgG,GAAY0B,EAAe4f,GAAY9jB,GAEpD,IAAK,IAAIukB,EAAK,EAAGA,EAAKphB,IAAWohB,EAAI,CACnC,MAAML,EAAWK,EAAKqG,EAChBzG,EAAQnpB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKwd,EAAWjkB,IACzCirB,EACFlwB,KAAKwB,IAAIuG,GAAWoB,EAAc+f,GAAYjkB,GAElD,IAAI4E,EAAU,EACd,IAAK,IAAIonB,EAAKkC,EAAOlC,EAAK0B,IAAS1B,EAAI,CACrC,MAAME,EAAKF,EAAKlsB,EAAcmsB,EAE9B,IAAK,IAAIrI,EAAKE,EAAOF,EAAKmH,IAASnH,EAAI,CACrC,MAAMc,EAAKd,EAAK7jB,EAAe8jB,EAE/B,IAAK,IAAIG,EAAKE,EAAOF,EAAKiH,IAASjH,EAAI,CACrC,MACM2H,EAAWqB,EAAOzyB,EAAI0yB,EAAOjB,EAAKkB,EAAOtJ,EAAKuJ,EAAOnJ,EACrD4H,EAAYJ,GAASxnB,EAAc,EAAIkoB,GACzCT,GAASxnB,EAAe,EAAIygB,GAC5BgH,GAASxnB,EAAc,GAJhB8f,EAAKhkB,EAAcikB,IAIOgK,EAAQhE,EAE7C,IAAK,IAAIE,EAAK,EAAGA,EAAKC,IAAeD,EAAI,CAGvCvlB,GAFczG,EAASwtB,EAAWxB,GACnBoB,EAAUK,EAAYzB,MAM7CmB,EAASuC,EAAOtzB,EAAIuzB,EAAO3B,EAAK4B,EAAO3J,EAAK4J,EAAO1J,EAAK2F,GACpDrlB,IAOd,OAAOmP,EAAQmB,eAAe/Q,EAAGtP,MAAOsP,EAAGtQ,MAAOsQ,EAAGvP,UCnG1Cu5B,GAAMtV,EAAgBuV,MAAMlV,GAAOne,KAAKozB,IAAIjV,IAE5CmV,GAA0B,CACrC7a,WAAY4a,MACZ1a,YAAa,MACbC,WAAYwa,ICLDG,GAAOzV,EAAgB0V,OAAOrV,GAAOne,KAAKuzB,KAAKpV,IAE/CsV,GAA2B,CACtChb,WAAY+a,OACZ7a,YAAa,MACbC,WAAY2a,aCJEG,GAAsB7a,GAKpC,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACgwB,OAAEA,GAAUzT,GACdpc,QAACA,EAAOstB,IAAEA,EAAG0D,UAAEA,EAASzD,gBAAEA,GAAmBlP,EAEnD1iB,EAAiB,CAACkE,EAAGgwB,GAAS,yBAE9B,MAAMhM,EAAW3nB,OAAK8gB,eAAend,EAAEzC,OACjCi0B,EAAgBn1B,OAAK8gB,eAAe6S,EAAOzyB,OAEjD,IAAI65B,EAAajG,EACC,MAAdiG,IACFA,EAAa,CAAC,EAAG,IAGnB/6B,OAAKC,OACDqB,eAAagwB,+BAA+BxtB,EAASi3B,GACrD,IAAM,iEACF,kBAAkBj3B,oBAA0Bi3B,MAEpD,MAAM9uB,EAAW3K,eAAa2zB,kBAC1BtxB,EAAEzC,MACFyyB,EAAOzyB,MAA2C4C,EAASi3B,EAC3D3J,EAAKC,GAAiB,IAEpB/gB,aAACA,EAAYC,YAAEA,EAAWhE,eAAEA,EAAcC,cAAEA,EAAaK,QAAEA,GAC7DZ,EACEgB,EAAUJ,EAAQK,KAClBH,EAASF,EAAQG,IACjBguB,EAAQ/uB,EAASwqB,YAAcxqB,EAASkC,WACxC9D,EAAI,IAAIyU,eAAa7S,EAASlI,SAAUJ,EAAEzD,OAC1C6E,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnC20B,EAAQxV,EAAQtf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,OACxC40B,EAAQxrB,EAAEpJ,OAEhB,IAAK,IAAI2F,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EAAG,CAC3C,MAAMkvB,EAAWlvB,EAAI+gB,EAAS,GACxBoO,EAAWnvB,EAAIyD,EAAEvG,QAAQ,GAC/B,IAAK,IAAImsB,EAAK,EAAGA,EAAKhkB,EAAS2C,YAAaqhB,EAAI,CAC9C,MAAM+F,EAAWD,EAAW9F,EAAK5lB,EAAEvG,QAAQ,GACrCosB,EAAWD,EAAKhkB,EAASG,aAAea,EAC9C,IAAK,IAAI8jB,EAAK,EAAGA,EAAKzgB,IAAgBygB,EAAI,CACxC,MAAMN,EAAKP,EAAWa,EAAKxkB,EAC3B,GAAIkkB,EAAK,GAAKA,GAAMxkB,EAAS+C,SAC3B,SAEF,MAAMinB,EAAWlF,EAAKoE,EAAc,GAC9Be,EAAWJ,EAAWrF,EAAK9I,EAAS,GAC1C,IAAK,IAAI0I,EAAK,EAAGA,EAAKpkB,EAASkD,WAAYkhB,EAAI,CAC7C,MAAM8F,EAAWH,EAAW3F,EAAKhmB,EAAEvG,QAAQ,GACrCwsB,EAAWD,EAAKpkB,EAASI,YAAcU,EAC7C,IAAK,IAAIikB,EAAK,EAAGA,EAAKzgB,IAAeygB,EAAI,CACvC,MAAML,EAAKL,EAAWU,EAAKxkB,EAC3B,GAAImkB,EAAK,GAAKA,GAAM1kB,EAASsD,QAC3B,SAEF,MAAMkpB,EAAWxC,EAAWjF,EAAKmE,EAAc,GACzCiB,EAAWF,EAAWvF,EAAK1kB,EAASkC,WAC1C,IAAIuqB,EAAWvC,EACXE,EAAWoC,EACf,IAAK,IAAInC,EAAK,EAAGA,EAAKrqB,EAASkC,aAAcmoB,EAAI,CAC/C,MAAMC,EAAOxxB,EAAMqxB,EAAWE,GAC9B,IAAK,IAAI2E,EAAI,EAAGA,EAAID,IAASC,EAC3BpF,EAAM6C,EAAWuC,IAAM1E,EAAOX,EAAMS,EAAW4E,GAEjDvC,GAAYsC,EACZ3E,GAAY2E,OAQxB,OAAO5a,EAAQmB,eAAelX,EAAEnJ,MAAOmJ,EAAEnK,MAAOmK,EAAEpJ,QAG7C,MAAMi6B,GAA4C,CACvDrb,WAAYsb,wBACZpb,YAAa,MACbC,WAAY8a,ICxBP,MAAMM,GAA0D,CACrEvb,WAAYwb,sCACZtb,YAAa,MACbC,oBA/DkDC,GAKlD,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACyG,GAAEA,GAAM8V,GACVpc,QAACA,EAAOgxB,UAAEA,EAAS1D,IAAEA,EAAGC,gBAAEA,EAAeyF,YAAEA,GAAe3U,EAEhE1iB,EAAiB,CAACkE,EAAGyG,GAAK,uCAE1B,MAAM6B,EAAW3K,eAAa2zB,kBAC1BtxB,EAAEzC,MAA2C41B,EAAahzB,EAC1DgxB,EAAW1D,EAAKC,GAAiB,IAE/BjlB,aAACA,EAAYC,YAAEA,EAAWiE,aAAEA,EAAYC,YAAEA,GAAetE,EAEzD8qB,EAAK,IAAIjY,eAAa7S,EAAS6qB,YAAa,WAE5CE,EAAU/qB,EAASY,QAAQK,KAC3B+pB,EAAShrB,EAASY,QAAQG,IAC1BguB,EAAQ/uB,EAASwqB,YAAcxqB,EAASkC,WAExCpJ,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnCqD,EAAO,IAAIwa,eAAanb,EAAEzC,MAAOyC,EAAEzD,MAAO6E,GAC1CmyB,EAAS9W,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,OACrCyP,EAAQ,IAAIoO,eAAa1U,EAAGlJ,MAAOkJ,EAAGlK,MAAOg3B,GACnD,IAAK,IAAInG,EAAK,EAAGA,EAAKzgB,IAAgBygB,EAAI,CACxC,MAAMoG,EAAQ/vB,KAAKb,IAAI,EAAGa,KAAK0L,MAAMmkB,EAASlG,GAAM3kB,IAC9CgrB,EAAQhwB,KAAKwB,IACfqD,EAAS2C,WAAY3C,EAAS+C,SAAWioB,EAASlG,GAAM3kB,GAE5D,IAAK,IAAI4kB,EAAK,EAAGA,EAAKzgB,IAAeygB,EAAI,CACvC,MAAMqG,EAAQjwB,KAAKb,IAAI,EAAGa,KAAK0L,MAAMkkB,EAAUhG,GAAM3kB,IAC/CirB,EAAQlwB,KAAKwB,IACfqD,EAASkD,UAAWlD,EAASsD,QAAUynB,EAAUhG,GAAM3kB,GAE3D,IAAK,IAAImqB,EAAK,EAAGA,EAAKvqB,EAASwqB,cAAeD,EAAI,CAChD,MAAMF,EAAKlvB,KAAKk0B,MAAM9E,EAAKwE,GACrBO,EAAK/E,EAAKwE,EAEhB,IAAI/pB,EAAU,EACd,IAAK,IAAIrK,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EACxC,IAAK,IAAIqpB,EAAKkH,EAAOlH,EAAKmH,IAASnH,EAAI,CACrC,MAAMQ,EAAKM,EAAKd,EAAK7jB,EAAe6qB,EACpC,IAAK,IAAI5G,EAAKgH,EAAOhH,EAAKiH,IAASjH,EAAI,CACrC,MAAMM,EAAKK,EAAKX,EAAKhkB,EAAc2qB,EACnC/lB,GAAY3M,EAAKjD,IAAIuF,EAAG6pB,EAAIE,EAAI2F,GAC3B5lB,EAAMrP,IAAIuF,EAAGqpB,EAAII,EAAImG,IAIhCO,EAAGt1B,IAAIwP,EAAS8f,EAAIC,EAAIsF,EAAIiF,KAKlC,OAAOnb,EAAQmB,eAAewV,EAAG71B,MAAO61B,EAAG72B,MAAO62B,EAAG91B,UC0BhD,MAAMu6B,GAAyD,CACpE3b,WAAY4b,qCACZ1b,YAAa,MACbC,oBAtFiDC,GAKjD,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3B7V,GAACA,EAAEupB,OAAEA,GAAUzT,GACfpc,QAACA,EAAOgxB,UAAEA,EAAS1D,IAAEA,EAAGC,gBAAEA,EAAeoG,WAAEA,GAActV,EAE/D1iB,EAAiB,CAAC2K,EAAIupB,GAAS,sCAE/B,MAAM+D,EAAY13B,OAAK8gB,eAAe1W,EAAGlJ,OACnCi0B,EAAgBn1B,OAAK8gB,eAAe6S,EAAOzyB,OAE3C+K,EAAW3K,eAAa2zB,kBAC1BwC,EAAY9D,EAAOzyB,MAA2C4C,EAC9DgxB,EAAW1D,EAAKC,GAAiB,GAE/B7gB,EAAK,IAAIsO,eAAa7S,EAASwlB,QAAS,WACxCkG,EAAWnnB,EAAGvP,QACbi5B,EAAMC,EAAMC,GAAQ5pB,EAAG1M,QACxB0G,EAAW4V,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,QACtCo4B,EAAMC,EAAMC,GAAQ7B,EACrBE,EAAYxX,EAAQtf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,QAC3C42B,EAAOC,EAAOC,GAAS5C,GACxBpnB,UACJA,EAASuC,aACTA,EAAYC,YACZA,EAAWpC,WACXA,EAAUa,SACVA,EAAQO,QACRA,EAAOknB,YACPA,EAAW7nB,UACXA,EAASO,SACTA,EAAQ/C,aACRA,EAAYC,YACZA,GACEJ,EACEgrB,EAAS3mB,EAAe,EAAIrE,EAASY,QAAQG,IAC7CgqB,EAAUzmB,EAAc,EAAItE,EAASY,QAAQK,KAC7C8tB,EAAQvE,EAActoB,EAE5B,IAAK,IAAIvH,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAI0vB,EAAK,EAAGA,EAAKnoB,IAAcmoB,EAClC,IAAK,IAAI7F,EAAK,EAAGA,EAAKzhB,IAAYyhB,EAAI,CACpC,MAAMP,EAAWO,EAAKwG,EAChB9G,EAAQ/oB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKod,EAAW9jB,IACzCgrB,EACFhwB,KAAKwB,IAAIgG,GAAY0B,EAAe4f,GAAY9jB,GAEpD,IAAK,IAAIukB,EAAK,EAAGA,EAAKphB,IAAWohB,EAAI,CACnC,MAAML,EAAWK,EAAKqG,EAChBzG,EAAQnpB,KAAKb,IAAI,EAAGa,KAAK0L,KAAKwd,EAAWjkB,IACzCirB,EACFlwB,KAAKwB,IAAIuG,GAAWoB,EAAc+f,GAAYjkB,GAElD,IAAI4E,EAAU,EACd,IAAK,IAAIgf,EAAKE,EAAOF,EAAKmH,IAASnH,EAAI,CACrC,MAAMc,EAAKd,EAAK7jB,EAAe8jB,EAE/B,IAAK,IAAIG,EAAKE,EAAOF,EAAKiH,IAASjH,EAAI,CACrC,MACM2H,EAAWqB,EAAOzyB,EAAI0yB,EAAOrJ,EAAKsJ,EAAOlJ,EACzC4H,EAAYJ,GAASvnB,EAAe,EAAIygB,GAC1C+G,GAASvnB,EAAc,GAHhB8f,EAAKhkB,EAAcikB,IAGOyH,EAAQzB,EAE7C,IAAK,IAAIiF,EAAK,EAAGA,EAAKP,IAASO,EAAI,CAIjCtqB,GAFczG,EAASwtB,GADZ1B,EAAK0E,EAAQO,IAET3D,EAAUK,EAAYsD,KAK3C5D,EAASuC,EAAOtzB,EAAIuzB,EAAO1J,EAAK2J,EAAOzJ,EAAK2F,GAAMrlB,GAM1D,OAAOmP,EAAQmB,eAAe/Q,EAAGtP,MAAOsP,EAAGtQ,MAAOsQ,EAAGvP,UCjF1Cy6B,GAAiC,CAC5C7b,WAAY8b,aACZ5b,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQE,QAAAA,EAAS+B,MAAAA,MAC7B,MAAMxe,EAACA,EAACgwB,OAAEA,GAAUzT,GACdpc,QAACA,EAAOstB,IAAEA,EAAG0D,UAAEA,GAAa3S,EAC5BhC,EAAaC,EAEbrb,EAAQob,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACtCmoB,EAAQzlB,EAAEzC,MAAMU,OAEhBg6B,EAAazb,EAAWrf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,OAChD46B,EAAalI,EAAOzyB,MAAMU,QAE1BmM,UACJA,EAASiB,SACTA,EAAQO,QACRA,EAAOpB,WACPA,EAAUS,UACVA,EAASO,SACTA,EAAQtC,QACRA,EAAOT,aACPA,EAAYC,YACZA,EAAWiE,aACXA,EAAYC,YACZA,EAAWhE,eACXA,EAAcC,cACdA,EAAazI,SACbA,GAEEzC,eAAaw6B,sBACTn4B,EAAEzC,MACFyyB,EAAOzyB,MAAmC4C,EAASstB,EACnD,OAAyB0D,GAE3BiH,EAAU/7B,OAAK8H,cAAc/D,GAC7Bi4B,EAAUj4B,EAASnC,OACnB6L,EAAazN,OAAKof,kBAAkBzb,EAAEzD,MAAO67B,GAMnD,IAAK,IAAIn1B,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAIq1B,EAAO,EAAGA,EAAOrtB,IAAaqtB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7vB,EAAeS,EAAQG,IAC3C,IAAK,IAAImvB,EAAO,EAAGA,EAAOhtB,IAAYgtB,EAAM,CAC1C,MAAMC,EAAOD,EAAO9vB,EAAcQ,EAAQK,KAC1C,IAAK,IAAIlL,EAAI,EAAGA,EAAImM,IAAcnM,EAAG,CACnC,IAAIq6B,EAASjvB,OAAOkvB,iBACpB,IAAK,IAAI9hB,EAAI,EAAGA,EAAIlK,IAAgBkK,EAAG,CACrC,MAAM+hB,EAAML,EAAO1hB,EAAIjO,EACvB,GAAIgwB,GAAO,GAAKA,EAAMvtB,EACpB,IAAK,IAAI2L,EAAI,EAAGA,EAAIpK,IAAeoK,EAAG,CACpC,MAAM6hB,EAAMJ,EAAOzhB,EAAInO,EACvB,GAAIgwB,GAAO,GAAKA,EAAMjtB,EAAS,CAC7B,MAAM0Y,EAASjoB,OAAKkL,WAChB,CAACtE,EAAG21B,EAAKC,EAAKx6B,GAAIonB,EAAOppB,OAAK8gB,eAAend,EAAEzC,QAC7Cu7B,EAAcz8B,OAAKkL,WACrB,CAACsP,EAAGG,EAAG3Y,GAAI65B,EACX77B,OAAK8gB,eAAe6S,EAAOzyB,QACzB2W,EAAM9S,EAAMkjB,GAAU2T,EAAWa,GACnC5kB,EAAMwkB,IACRA,EAASxkB,KAQnBpK,EAFoBzN,OAAKkL,WACrB,CAACtE,EAAGq1B,EAAME,EAAMn6B,GAAIg6B,EAASh8B,OAAK8gB,eAAe/c,KAC3Bs4B,IASlC,MAAO,CAAC76B,OAHO2e,EAAWje,MACtBlC,OAAK6iB,aAAapV,EAAY9J,EAAEzD,OAAQ6D,EAAUJ,EAAEzD,OAExCgB,MAAO6C,EAAU7D,MAAOyD,EAAEzD,SC/EjCw8B,GAA+C,CAC1D7c,WAAY8c,2BACZ5c,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQE,QAAAA,EAAS+B,MAAAA,MAC7B,MAAMxe,EAACA,EAACgwB,OAAEA,EAAMvpB,GAAEA,GACd8V,GACEpc,QAACA,EAAOstB,IAAEA,EAAG0D,UAAEA,GAAa3S,EAC5BhC,EAAaC,EAEbwc,EACF58B,OAAK68B,cACDl5B,EAAEzC,MAAOif,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,QAGzC67B,EAAU98B,OAAK68B,cACDlJ,EAAOzyB,MACPif,EAAWrf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,SAGjD8M,UACJA,EAASiB,SACTA,EAAQO,QACRA,EAAOpB,WACPA,EAAUS,UACVA,EAASO,SACTA,EAAQtC,QACRA,EAAOT,aACPA,EAAYC,YACZA,EAAWiE,aACXA,EAAYC,YACZA,EAAWhE,eACXA,EAAcC,cACdA,EAAazI,SACbA,GAEEzC,eAAaw6B,sBACTn4B,EAAEzC,MACFyyB,EAAOzyB,MAAmC4C,EAASstB,EACnD,OAAyB0D,GAEjC90B,OAAKC,OACDmK,EAAGlF,OAASnB,EAASnC,OACrB,IAAM,YAAY+6B,kCACd,qCAAqC54B,EAASnC,mBAC9C,GAAGwI,EAAGlF,QAEd,MAAM63B,EACF/8B,OAAK68B,cACD94B,EAAUoc,EAAWrf,KAAKO,IAAI+I,EAAG5I,QAAQP,QAK3C+7B,EAAYh9B,OAAKi9B,0BACDtJ,EAAOzyB,MAAOyyB,EAAOzzB,OAO3C,IAAK,IAAI0G,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAIq1B,EAAO,EAAGA,EAAOrtB,IAAaqtB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7vB,EAAeS,EAAQG,IAC3C,IAAK,IAAImvB,EAAO,EAAGA,EAAOhtB,IAAYgtB,EAAM,CAC1C,MAAMC,EAAOD,EAAO9vB,EAAcQ,EAAQK,KAC1C,IAAK,IAAIlL,EAAI,EAAGA,EAAImM,IAAcnM,EAAG,CACnC,IAAIq6B,EAASjvB,OAAOkvB,iBAChBY,EAAO,EACPC,EAAO,EACX,IAAK,IAAI3iB,EAAI,EAAGA,EAAIlK,IAAgBkK,EAAG,CACrC,MAAM+hB,EAAML,EAAO1hB,EAAIjO,EACvB,GAAIgwB,GAAO,GAAKA,EAAMvtB,EACpB,IAAK,IAAI2L,EAAI,EAAGA,EAAIpK,IAAeoK,EAAG,CACpC,MAAM6hB,EAAMJ,EAAOzhB,EAAInO,EACvB,GAAIgwB,GAAO,GAAKA,EAAMjtB,EAAS,CAC7B,MAAMsI,EAAM+kB,EAAGh2B,GAAG21B,GAAKC,GAAKx6B,GAAK86B,EAAQtiB,GAAGG,GAAG3Y,GAC3C6V,EAAMwkB,IACRA,EAASxkB,EACTqlB,EAAO1iB,EACP2iB,EAAOxiB,KAMjBqiB,EAAUE,GAAMC,GAAMn7B,IAAM+6B,EAAIn2B,GAAGq1B,GAAME,GAAMn6B,KASvD,MAAO,CAACR,OAHO2e,EAAWje,MACtBlC,OAAK6iB,aAAama,EAAWr5B,EAAEzD,OAAQyzB,EAAOzyB,MAAOyyB,EAAOzzB,OAEhDgB,MAAOyyB,EAAOzyB,MAAOhB,MAAOyzB,EAAOzzB,SC/F1Ck9B,GAA8C,CACzDvd,WAAYwd,0BACZtd,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQE,QAAAA,EAAS+B,MAAAA,MAC7B,MAAMxe,EAACA,EAACgwB,OAAEA,EAAMvpB,GAAEA,GACd8V,GACEpc,QAACA,EAAOstB,IAAEA,EAAG0D,UAAEA,GAAa3S,EAC5BhC,EAAaC,EAEbwc,EACF58B,OAAK68B,cACDl5B,EAAEzC,MAAOif,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,QAGzC67B,EAAU98B,OAAK68B,cACDlJ,EAAOzyB,MACPif,EAAWrf,KAAKO,IAAIsyB,EAAOnyB,QAAQP,SAGjD8M,UACJA,EAASiB,SACTA,EAAQO,QACRA,EAAOpB,WACPA,EAAUS,UACVA,EAASO,SACTA,EAAQtC,QACRA,EAAOT,aACPA,EAAYC,YACZA,EAAWiE,aACXA,EAAYC,YACZA,EAAWhE,eACXA,EAAcC,cACdA,EAAazI,SACbA,GAEEzC,eAAaw6B,sBACTn4B,EAAEzC,MACFyyB,EAAOzyB,MAAmC4C,EAASstB,EACnD,OAAyB0D,GAEjC90B,OAAKC,OACDmK,EAAGlF,OAASnB,EAASnC,OACrB,IAAM,YAAYy7B,iCACd,qCAAqCt5B,EAASnC,mBAC9C,GAAGwI,EAAGlF,QAEd,MAAM63B,EACF/8B,OAAK68B,cACD94B,EAAUoc,EAAWrf,KAAKO,IAAI+I,EAAG5I,QAAQP,QAK3C+7B,EACFh9B,OAAKi9B,0BAA0Bt5B,EAAEzC,MAAOyC,EAAEzD,OAO9C,IAAK,IAAI0G,EAAI,EAAGA,EAAImH,IAAanH,EAC/B,IAAK,IAAIq1B,EAAO,EAAGA,EAAOrtB,IAAaqtB,EAAM,CAC3C,MAAMC,EAAOD,EAAO7vB,EAAeS,EAAQG,IAC3C,IAAK,IAAImvB,EAAO,EAAGA,EAAOhtB,IAAYgtB,EAAM,CAC1C,MAAMC,EAAOD,EAAO9vB,EAAcQ,EAAQK,KAC1C,IAAK,IAAIlL,EAAI,EAAGA,EAAImM,IAAcnM,EAAG,CACnC,IAAIq6B,EAASjvB,OAAOkvB,iBAChBgB,EAAUpB,EAAO,EAAK,EAAIA,EAC1BqB,EAAUnB,EAAO,EAAK,EAAIA,EAC9B,IAAK,IAAI5hB,EAAI,EAAGA,EAAIlK,IAAgBkK,EAAG,CACrC,MAAM+hB,EAAML,EAAO1hB,EAAIjO,EACvB,GAAIgwB,GAAO,GAAKA,EAAMvtB,EACpB,IAAK,IAAI2L,EAAI,EAAGA,EAAIpK,IAAeoK,EAAG,CACpC,MAAM6hB,EAAMJ,EAAOzhB,EAAInO,EACvB,GAAIgwB,GAAO,GAAKA,EAAMjtB,EAAS,CAC7B,MAAMsI,EAAM+kB,EAAGh2B,GAAG21B,GAAKC,GAAKx6B,GAAK86B,EAAQtiB,GAAGG,GAAG3Y,GAC3C6V,EAAMwkB,IACRA,EAASxkB,EACTylB,EAASf,EACTgB,EAASf,KAMnBQ,EAAUp2B,GAAG02B,GAAQC,GAAQv7B,IAAM+6B,EAAIn2B,GAAGq1B,GAAME,GAAMn6B,KAS9D,MAAO,CAACR,OAHO2e,EAAWje,MACtBlC,OAAK6iB,aAAama,EAAWr5B,EAAEzD,OAAQyD,EAAEzC,MAAOyC,EAAEzD,OAEtCgB,MAAOyC,EAAEzC,MAAOhB,MAAOyD,EAAEzD,SC/FhCs9B,GACT/c,EAA6B,CAAC/Z,EAAWE,IAAcF,EAAIE,GAClD62B,GAAMxa,EAAiBya,MAAKF,IAE5BG,GAA0B,CACrC9d,WAAY6d,MACZ3d,YAAa,MACbC,WAAYyd,ICRRG,GAAIt8B,eAAau8B,MACjBC,GAAKx8B,eAAay8B,OAClBC,GAAK18B,eAAa28B,OAClBC,GAAK58B,eAAa68B,OAClBC,GAAK98B,eAAa+8B,OAClBC,GAAKh9B,eAAai9B,OAEXC,GAAMtZ,EACfuZ,MACClZ,IACC,MAAMmZ,EAAOt3B,KAAKs3B,KAAKnZ,GACjB9a,EAAIrD,KAAKuY,IAAI4F,GACbxlB,EAAI,GAAO,EAAM69B,GAAInzB,GAC3B,OAAOi0B,GACF,MACKJ,GAAKv+B,EAAIq+B,IAAMr+B,EAAKm+B,IAAMn+B,EAAIi+B,IAAMj+B,EAAI+9B,IAAM/9B,EAC/CqH,KAAKue,KAAKlb,EAAIA,MAIhBk0B,GAA0B,CACrC9e,WAAY4e,MACZ1e,YAAa,MACbC,WAAYwe,aCVEI,GACZ9c,EAAmB+c,EACnB1e,GACF,MAAMsX,EAAa3V,EAAM5gB,MACnB4M,EAAQ2pB,EAAW,GACnBqH,EAAWrH,EAAW,GAEtBsH,EAAY5e,EAAWrf,KAAKO,IAAIygB,EAAMtgB,QAEtCw9B,EAASD,EAAUz8B,mBAAmBE,KACtCy8B,EAASF,EAAUz8B,mBAAmBI,KAGtCic,EAAc,CAAC7Q,EAAOgxB,GACtB/d,EAAa/gB,OAAK8H,cAAc6W,GAChCyF,EAAapkB,OAAKghB,uBAAuB,UAAWD,GACpDsD,EAAarkB,OAAKghB,uBAAuB,UAAWD,GAE1D,IAAK,IAAIna,EAAI,EAAGA,EAAIkH,EAAOlH,IAAK,CAE9B,MAAM6L,EAAIpN,GAAM,CACd6a,OAAQ,CAACvc,EAAGq7B,GACZ5e,QAASD,EACTgC,MAAO,CAACve,MAAO,CAACgD,EAAG,GAAInC,KAAM,CAAC,EAAGq6B,MAE7Bt6B,EAAIa,GAAM,CACd6a,OAAQ,CAACvc,EAAGs7B,GACZ7e,QAASD,EACTgC,MAAO,CAACve,MAAO,CAACgD,EAAG,GAAInC,KAAM,CAAC,EAAGq6B,MAG7Bhd,EAAQT,EAAQ,CAACnB,OAAQ,CAAC1d,KAAMiQ,EAAG/P,KAAM8B,GAAI4b,QAASD,KAGtD3d,KAACA,EAAIE,KAAEA,GAAQw8B,GAAQpd,EAAO+c,EAAS1e,GACvC7a,EAAMhE,eAAaqB,uBAAuBH,EAAME,GAEtD,IAAK,IAAIV,EAAI,EAAGA,EAAI88B,EAAU98B,IAAK,CACjC,MAAMiR,EAAI3R,eAAa69B,oBAAoB75B,EAAKtD,GAChDoiB,EAAWxd,EAAIk4B,EAAW98B,GAAKiR,EAAEzQ,KACjC6hB,EAAWzd,EAAIk4B,EAAW98B,GAAKiR,EAAEvQ,KAGnCyd,EAAWoC,8BAA8B9P,GACzC0N,EAAWoC,8BAA8B/d,GACzC2b,EAAWoC,8BAA8BT,GAG3C,MAAMsd,EACFjf,EAAWoB,eAAe5C,EAAa,UAAWyF,GAChDib,EACFlf,EAAWoB,eAAe5C,EAAa,UAAW0F,GAEhDte,EAASsb,EACX,CAACnB,OAAQ,CAAC1d,KAAM48B,EAAW18B,KAAM28B,GAAYjf,QAASD,IAK1D,OAHAA,EAAWoC,8BAA8B6c,GACzCjf,EAAWoC,8BAA8B8c,GAElCt5B,WAGOm5B,GACZpd,EAAmB+c,EACnB1e,GACF,MAAMmf,EAAYt/B,OAAK8H,cAAcga,EAAM5gB,OAErC69B,EAAY5e,EAAWrf,KAAKO,IAAIygB,EAAMtgB,QAEtC8e,EACFH,EAAWrf,KAAKO,IAAI09B,EAAUz8B,mBAAmBE,KAAKhB,QAAQP,OAG5Dsf,EACFJ,EAAWrf,KAAKO,IAAI09B,EAAUz8B,mBAAmBI,KAAKlB,QAAQP,OAGlE,GAsD6B,KADRwD,EArDH66B,GAsDH76B,EAAO,GAtDQ,CAC5B,MAAMsB,EAyDV,SAASw5B,EACLjf,EAAwBC,EAAwB9b,EAChDo6B,EACA1e,GACF,GAAa,IAAT1b,EACF,MAAO,CAACjC,KAAM8d,EAAU5d,KAAM6d,GAGhC,MAAMzf,EAAOQ,eAAaqB,uBAAuB2d,EAAUC,GAErDif,EAAO/6B,EAAO,EAEdg7B,EAAcn+B,eAAao+B,qBAAqB5+B,GAEhD6+B,EAAeF,EAAYj9B,KAC3Bo9B,EAAeH,EAAY/8B,KAE3Bm9B,EAAY,CAACF,EAAa/9B,QAE1Bk+B,EACF3f,EAAWoB,eAAese,EAAW,UAAWF,GAC9CI,EACF5f,EAAWoB,eAAese,EAAW,UAAWD,GAE9CI,EAAiB3e,EACnB,CAACnB,OAAQ,CAAC1d,KAAMs9B,EAAcp9B,KAAMq9B,GAAe3f,QAASD,IAE1D8f,EAAa3+B,eAAa4+B,oBAAoBp/B,GAE9Cq/B,EAAcF,EAAWz9B,KACzB49B,EAAcH,EAAWv9B,KAEzB29B,EAAW,CAACF,EAAYv+B,QAExB0+B,EACFngB,EAAWoB,eAAe8e,EAAU,UAAWF,GAC7CI,EACFpgB,EAAWoB,eAAe8e,EAAU,UAAWD,GAE7CI,EAAgBnf,EAClB,CAACnB,OAAQ,CAAC1d,KAAM89B,EAAa59B,KAAM69B,GAAcngB,QAASD,IAGxDsgB,EACFlB,EAAUI,EAAcC,EAAcJ,EAAMX,EAAS1e,GAEnDugB,EAAgBD,EAAaj+B,KAC7Bm+B,EAAgBF,EAAa/9B,KAE7Bk+B,EAAa,CAACF,EAAc9+B,QAE5Bi/B,EACF1gB,EAAWoB,eAAeqf,EAAY,UAAWF,GAC/CI,EACF3gB,EAAWoB,eAAeqf,EAAY,UAAWD,GAE/CI,EAAkB1f,EAAQ,CAC9BnB,OAAQ,CAAC1d,KAAMq+B,EAAen+B,KAAMo+B,GACpC1gB,QAASD,IAGL6gB,EACFzB,EAAUY,EAAaC,EAAaZ,EAAMX,EAAS1e,GAEjD8gB,EAAeD,EAAYx+B,KAC3B0+B,EAAeF,EAAYt+B,KAE3By+B,EAAY,CAACF,EAAar/B,QAE1Bw/B,EACFjhB,EAAWoB,eAAe4f,EAAW,UAAWF,GAC9CI,EACFlhB,EAAWoB,eAAe4f,EAAW,UAAWD,GAE9CI,EAAiBjgB,EACnB,CAACnB,OAAQ,CAAC1d,KAAM4+B,EAAc1+B,KAAM2+B,GAAejhB,QAASD,IAE1DohB,EAAIjgC,eAAakgC,UAAU/8B,EAAMo6B,GACjC4C,EAAS,CAACF,EAAE/+B,KAAKZ,QAEjB8/B,EAAYvhB,EAAWoB,eAAekgB,EAAQ,UAAWF,EAAE/+B,MAC3Dm/B,EAAYxhB,EAAWoB,eAAekgB,EAAQ,UAAWF,EAAE7+B,MAE3D4e,EAAcD,EAChB,CAACnB,OAAQ,CAAC1d,KAAMk/B,EAAWh/B,KAAMi/B,GAAYvhB,QAASD,IAEpDyhB,EACFhb,EACI,CAAC1G,OAAQ,CAACxZ,EAAG4a,EAAa1a,EAAG06B,GAAiBlhB,QAASD,IAGzD0hB,EAAU/c,EAAI,CACF5E,OAAQ,CAACxZ,EAAGq6B,EAAiBn6B,EAAGg7B,GAChCxhB,QAASD,IAErB2hB,EAAUhZ,GAAI,CACF5I,OAAQ,CAACxZ,EAAGq6B,EAAiBn6B,EAAGg7B,GAChCxhB,QAASD,IAGrB4hB,EAAcv/B,EAAK,CAAC0d,OAAQ,CAAC4B,MAAO+f,GAAUzhB,QAASD,IACvD6hB,EAAcx/B,EAAK,CAAC0d,OAAQ,CAAC4B,MAAOggB,GAAU1hB,QAASD,IAEvD8hB,EAAcv/B,GAAK,CAACwd,OAAQ,CAAC4B,MAAO+f,GAAUzhB,QAASD,IACvD+hB,EAAcx/B,GAAK,CAACwd,OAAQ,CAAC4B,MAAOggB,GAAU1hB,QAASD,IAEvDgiB,EAAQxV,GAAO,CACnBzM,OAAQ,CAAC6hB,EAAuBC,GAChC5hB,QAASD,EACTgC,MAAO,CAAChe,KAAM,KAEVi+B,GAAQzV,GAAO,CACnBzM,OAAQ,CAAC+hB,EAAuBC,GAChC9hB,QAASD,EACTgC,MAAO,CAAChe,KAAM,KAGVk+B,GAAYliB,EAAWrf,KAAKO,IAAI8gC,EAAM3gC,QAAQP,OAC9CqhC,GAAYniB,EAAWrf,KAAKO,IAAI+gC,GAAM5gC,QAAQP,OA2BpD,OAzBAkf,EAAWoC,8BAA8Bud,GACzC3f,EAAWoC,8BAA8Bwd,GACzC5f,EAAWoC,8BAA8Byd,GACzC7f,EAAWoC,8BAA8B+d,GACzCngB,EAAWoC,8BAA8Bge,GACzCpgB,EAAWoC,8BAA8Bie,GACzCrgB,EAAWoC,8BAA8Bse,GACzC1gB,EAAWoC,8BAA8Bue,GACzC3gB,EAAWoC,8BAA8Bwe,GACzC5gB,EAAWoC,8BAA8B6e,GACzCjhB,EAAWoC,8BAA8B8e,GACzClhB,EAAWoC,8BAA8B+e,GACzCnhB,EAAWoC,8BAA8Bmf,GACzCvhB,EAAWoC,8BAA8Bof,GACzCxhB,EAAWoC,8BAA8BjB,GACzCnB,EAAWoC,8BAA8Bqf,GACzCzhB,EAAWoC,8BAA8Bsf,GACzC1hB,EAAWoC,8BAA8Buf,GACzC3hB,EAAWoC,8BAA8Bwf,GACzC5hB,EAAWoC,8BAA8B0f,GACzC9hB,EAAWoC,8BAA8Byf,GACzC7hB,EAAWoC,8BAA8B2f,GACzC/hB,EAAWoC,8BAA8B4f,GACzChiB,EAAWoC,8BAA8B6f,IAElC,CAAC5/B,KAAM6/B,GAAW3/B,KAAM4/B,IAzMzB/C,CAAUjf,EAAUC,EAAU+e,EAAWT,EAAS1e,GAEhDxB,EAAc,CAACmD,EAAM5gB,MAAM,GAAI4gB,EAAM5gB,MAAM,IAEjD,GAAI29B,EAAS,CACX,MAAM0D,EACFpiB,EAAWoB,eAAe5C,EAAa,UAAW5Y,EAAOvD,MACvDggC,EACFriB,EAAWoB,eAAe5C,EAAa,UAAW5Y,EAAOrD,MAEvD+/B,EAAuBtiB,EAAWoB,eACpC,GAAI,UACJvhB,OAAK0iC,kBAAkBpD,EAA8B,YACnDqD,EACFjhB,EAAS,CAACxB,OAAQ,CAACvc,EAAG8+B,GAAWriB,QAASD,IAExCyiB,EACFjF,GAAU3d,WACN,CAACE,OAAQ,CAACxZ,EAAG67B,EAAU37B,EAAG67B,GAAWriB,QAASD,IAEhD0iB,EACFlF,GAAU3d,WACN,CAACE,OAAQ,CAACxZ,EAAG87B,EAAU57B,EAAG+7B,GAAeviB,QAASD,IAGpD2iB,EACF3iB,EAAWrf,KAAKO,IAAIuhC,EAAYphC,QAAQP,OACtC8hC,EACF5iB,EAAWrf,KAAKO,IAAIwhC,EAAYrhC,QAAQP,OAS5C,OAPAkf,EAAWoC,8BAA8BggB,GACzCpiB,EAAWoC,8BAA8BigB,GACzCriB,EAAWoC,8BAA8BkgB,GACzCtiB,EAAWoC,8BAA8BogB,GACzCxiB,EAAWoC,8BAA8BqgB,GACzCziB,EAAWoC,8BAA8BsgB,GAElC,CAACrgC,KAAMsgC,EAAapgC,KAAMqgC,GAGnC,OAAOh9B,EACF,CACL,MAEMi9B,EAiKV,SACIliC,EAAkB2D,EAAco6B,GAClC,MAAMoE,EAAM,IAAI14B,aAAoB,EAAP9F,GAE7B,IAAK,IAAIgO,EAAI,EAAGA,EAAIhO,EAAMgO,IAAK,CAC7B,IAAIjQ,EAAO,EACPE,EAAO,EACX,IAAK,IAAIuQ,EAAI,EAAGA,EAAIxO,EAAMwO,IAAK,CAC7B,MAAMsuB,EAAIjgC,eAAa4hC,SAASzwB,EAAIQ,EAAGxO,EAAMo6B,GACvCsE,EAAO7hC,eAAa69B,oBAAoBr+B,EAAsBmS,GACpEzQ,GAAQ2gC,EAAK3gC,KAAO++B,EAAE/+B,KAAO2gC,EAAKzgC,KAAO6+B,EAAE7+B,KAC3CA,GAAQygC,EAAK3gC,KAAO++B,EAAE7+B,KAAOygC,EAAKzgC,KAAO6+B,EAAE/+B,KAEzCq8B,IACFr8B,GAAQiC,EACR/B,GAAQ+B,GAEVnD,eAAa8hC,mBAAmBH,EAAKzgC,EAAME,EAAM+P,GAEnD,OAAOwwB,EAnLDI,CAHS/hC,eAAaqB,uBAAuB2d,EAAUC,GAGxB+e,EAAWT,GAE9C,OAAOv9B,eAAagiC,uBAAuBN,GAI/C,IAAuBv+B,ECjHhB,MAAM8+B,GAA0B,CACrC1jB,WAAY2jB,MACZzjB,YAAa,MACbC,oBA/BkBC,GAElB,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpB6B,MAACA,GAAS5B,EAEVof,EAAYt/B,OAAK8H,cAAcga,EAAM5gB,OAGrCuiC,EAAqB3hB,EAAM5gB,MAAM4gB,EAAM5gB,MAAMU,OAAS,GAGtD8hC,EAAUl+B,GAAQ,CACtB0a,OAAQ,CAACvc,EAAGme,GACZ1B,QAAAA,EACA+B,MAAO,CAACjhB,MAAO,CALHo+B,EAAYmE,EAKDA,MAGnB19B,EAAS64B,GAAS8E,GAAS,EAAOtjB,GAElCujB,EACFn+B,GAAQ,CAAC0a,OAAQ,CAACvc,EAAGoC,GAASqa,QAAAA,EAAS+B,MAAO,CAACjhB,MAAO4gB,EAAM5gB,SAKhE,OAHAkf,EAAQmC,8BAA8BmhB,GACtCtjB,EAAQmC,8BAA8Bxc,GAE/B49B,ICfF,MAAMC,GAA2B,CACtC/jB,WAAYgkB,OACZ9jB,YAAa,MACbC,oBAfmBC,GAEnB,MAAMG,QAACA,EAAO+B,MAAEA,GAASlC,GACnB/e,MAACA,EAAK4H,MAAEA,EAAK5I,MAAEA,GAASiiB,EAExBkB,EAASnjB,GAASF,OAAK8jC,WAAWh7B,GAClC7H,EAASjB,OAAKof,kBAAkBiE,EAAQrjB,OAAK8H,cAAc5G,IAGjE,OASF,SACID,EAAoB6H,EAAsB5I,GAEzCe,EAAoBmE,KAAK0D,GAd5Bi7B,CAAW9iC,EAAQ6H,GAEZsX,EAAQmB,eAAergB,EAAOmiB,EAAQpiB,KCRxC,MAAM+iC,GAAoC,CAC/CnkB,WAAYokB,gBACZlkB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQiC,MAAAA,EAAO/B,QAAAA,MAC3B,MAAM8jB,MAACA,GAAShkB,EACVC,EAAaC,EAEb5S,EAASxN,OAAKghB,uBAChBkjB,EAAMhkC,MAA0BF,OAAK8H,cAAco8B,EAAMhjC,SACtD4M,EAAOoO,EAAaC,EAAYhK,GAAe+xB,EAAMhjC,MAEtDub,EAAY0D,EAAWrf,KAAKO,IAAI6iC,EAAM1iC,QAAQP,OAEpD,IAAK,IAAIkjC,EAAW,EAAGA,EAAWr2B,EAAOq2B,IAAY,CACnD,MAAMruB,EAAcquB,EAAWhoB,EAAaD,EAAc/J,EAE1D,IAAK,IAAImiB,EAAM,EAAGA,EAAMpY,EAAaoY,IAAO,CAC1C,MAAMve,EAAYue,GAAOnY,EAAahK,GAEtC,IAAK,IAAIqiB,EAAM,EAAGA,EAAMrY,EAAYqY,IAAO,CACzC,MAAMve,EAAYue,EAAMriB,EAExB,IAAK,IAAIjE,EAAU,EAAGA,EAAUiE,EAAajE,IAAW,CACtD,MAEMvK,EAFS,CAACmK,EAAOwmB,EAAKE,EAAKtmB,GAEhB,GAEXk2B,EAASh9B,KAAK4O,MAAMmG,EAAaxY,GACjC0gC,EAASvuB,EAAcC,EAAYE,EAAY/H,EAErD,IAAIo2B,EAAc7nB,EAAU4nB,GAE5B,GAAID,GAAU,GAAKA,EAASjoB,EAAY,CAKtCmoB,EAAc7nB,EADV3G,EAAcC,EAFOquB,EAASjyB,EAEejE,GAGnDV,EAAO62B,GAAUC,KAOzB,MAAO,CAAC9iC,OADO2e,EAAWje,MAAMsL,EAAQ02B,EAAMhjC,MAAOgjC,EAAMhkC,OAC3CgB,MAAOgjC,EAAMhjC,MAAOhB,MAAOgkC,EAAMhkC,SCZ9C,MAAMqkC,GAAkC,CAC7C1kB,WAAY2kB,cACZzkB,YAAa,MACbC,oBAnC0BC,GAK1B,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACgwB,OAAEA,EAAMxc,KAAEA,EAAIsU,uBAAEA,GAA0BvL,GAC5Cpc,QAACA,EAAOstB,IAAEA,EAAGnX,WAAEA,EAAU6a,UAAEA,EAASzD,gBAAEA,EAAe7F,WAAEA,GACzDrJ,EAEJ,IAAIpc,EAAS8uB,GAAO,CAClB3U,OAAQ,CAACvc,EAAAA,EAAGgwB,OAAAA,GACZvT,QAAAA,EACA+B,MAAO,CAACre,QAAAA,EAASstB,IAAAA,EAAKnX,WAAAA,EAAY6a,UAAAA,EAAWzD,gBAAAA,KAG/C,GAAIla,EAAM,CACR,MAAMstB,EAAY1+B,EAClBA,EAAS+e,EAAI,CAAC5E,OAAQ,CAACxZ,EAAGX,EAAQa,EAAGuQ,GAAOiJ,QAAAA,IAC5CA,EAAQmC,8BAA8BkiB,GAGxC,GAAIjZ,EAAY,CACd,MAAMiZ,EAAY1+B,EAClBA,EACIwlB,GAAgBnL,EAASra,EAAQylB,EAAYC,GACjDrL,EAAQmC,8BAA8BkiB,GAGxC,OAAO1+B,ICEF,MAAM2+B,GAA2C,CACtD7kB,WAAY8kB,uBACZ5kB,YAAa,MACbC,oBAlCmCC,GAKnC,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,EAACgwB,OAAEA,EAAMxc,KAAEA,EAAIsU,uBAAEA,GAA0BvL,GAC5Cpc,QAACA,EAAOstB,IAAEA,EAAGnX,WAAEA,EAAU6a,UAAEA,EAASzD,gBAAEA,EAAe7F,WAAEA,GACzDrJ,EAEJ,IAAIpc,EAAS+0B,GAAsB,CACjC5a,OAAQ,CAACvc,EAAAA,EAAGgwB,OAAAA,GACZvT,QAAAA,EACA+B,MAAO,CAACre,QAAAA,EAASstB,IAAAA,EAAKnX,WAAAA,EAAY6a,UAAAA,EAAWzD,gBAAAA,KAG/C,GAAIla,EAAM,CACR,MAAMytB,EAAY7+B,EAClBA,EAAS+e,EAAI,CAAC5E,OAAQ,CAACxZ,EAAGX,EAAQa,EAAGuQ,GAAOiJ,QAAAA,IAC5CA,EAAQmC,8BAA8BqiB,GAExC,GAAIpZ,EAAY,CACd,MAAMoZ,EAAY7+B,EAClBA,EACIwlB,GAAgBnL,EAASra,EAAQylB,EAAYC,GACjDrL,EAAQmC,8BAA8BqiB,GAGxC,OAAO7+B,ICDF,MAAM8+B,GAA2B,CACtChlB,WAAYilB,OACZ/kB,YAAa,MACbC,oBA/BmBC,GAEnB,MAAMC,OAACA,EAAME,QAAEA,GAAWH,GACpB6B,MAACA,GAAS5B,EAEVof,EAAYt/B,OAAK8H,cAAcga,EAAM5gB,OAGrCuiC,EAAqB3hB,EAAM5gB,MAAM4gB,EAAM5gB,MAAMU,OAAS,GAGtD8hC,EAAUl+B,GAAQ,CACtB0a,OAAQ,CAACvc,EAAGme,GACZ1B,QAAAA,EACA+B,MAAO,CAACjhB,MAAO,CALHo+B,EAAYmE,EAKDA,MAGnB19B,EAAS64B,GAAS8E,GAAS,EAAMtjB,GAEjCujB,EACFn+B,GAAQ,CAAC0a,OAAQ,CAACvc,EAAGoC,GAASqa,QAAAA,EAAS+B,MAAO,CAACjhB,MAAO4gB,EAAM5gB,SAKhE,OAHAkf,EAAQmC,8BAA8BmhB,GACtCtjB,EAAQmC,8BAA8Bxc,GAE/B49B,IC3BIoB,GACT7f,EAAgB8f,WAAWzf,GAAOnY,OAAO23B,SAASxf,GAAM,EAAI,EAAG,QAEtD0f,GAA+B,CAC1CplB,WAAYmlB,WACZjlB,YAAa,MACbC,WAAY+kB,ICNDG,GACThgB,EAAgBigB,QAAQ5f,GAAOne,KAAKuY,IAAI4F,KAAQ6f,EAAAA,EAAW,EAAI,EAAG,QAEzDC,GAA4B,CACvCxlB,WAAYslB,QACZplB,YAAa,MACbC,WAAYklB,ICNDh1B,GACTgV,EAAgBogB,QAAQ/f,GAAOnY,OAAO8C,MAAMqV,GAAM,EAAI,EAAG,QAEhDggB,GAA4B,CACvC1lB,WAAYylB,QACZvlB,YAAa,MACbC,WAAY9P,ICNDs1B,GAAQtgB,EAAgBugB,QAAQlgB,GAAOne,KAAKo+B,MAAMjgB,IAElDmgB,GAA4B,CACvC7lB,WAAY4lB,QACZ1lB,YAAa,MACbC,WAAYwlB,ICLDG,GACTzgB,EAAgB0gB,aAAargB,GAAOA,EAAK,EAAI,EAAG,QAEvCsgB,GAAiC,CAC5ChmB,WAAY+lB,aACZ7lB,YAAa,MACbC,WAAY2lB,ICADG,GAA0B,CACrCjmB,WAAYkmB,MACZhmB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQiC,MAAAA,EAAO/B,QAAAA,MAC3B,MAAMzc,EAACA,GAAKuc,GACN8lB,iBAACA,EAAgBC,SAAEA,GAAY9jB,EAC/BhC,EAAaC,EACnB,IAAI8I,EAASvlB,EAAEzC,MACf,MAAMkoB,EAAQF,EAAOtnB,OAEfskC,EAAWlmC,OAAKqG,eAAe2/B,EAAkB9c,GACvD,IAAI9iB,EAAO8/B,EACX,MAAMC,EAAe7kC,eAAa8kC,mBAAmBhgC,EAAMgjB,GAC3D,IAAIrkB,EAAQob,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,OAC1C,GAAoB,MAAhBklC,EAAsB,CACxB,MAAMr7B,EAAqB,IAAIlL,MAAMwpB,GACrC,IAAK,IAAI5kB,EAAI,EAAGA,EAAIsG,EAASlJ,OAAQ4C,IACnCsG,EAAStG,GAAK0kB,EAAOid,EAAa3hC,IAGpCO,EAAQkkB,GAAclkB,EAAOmkB,EAAQvlB,EAAEzD,MAAOimC,EAAcr7B,GAC5D1E,EAAO9E,eAAa+kC,iBAAiBjgC,EAAKxE,OAAQwnB,GAElDF,EAASpe,EAGXrL,EAAiBkE,EAAG,OACpBrC,eAAaiG,2BAA2B,MAAOnB,EAAMgjB,GACrD,MAAOkd,EAAa9+B,GAChBlG,eAAamG,0BAA0ByhB,EAAQ9iB,GAI7CL,EAAS0gB,EAAQ1hB,EAFJ/E,OAAK8H,cAAcN,GAEI8+B,EAAa3iC,EAAEzD,OACnDsB,EAAS2e,EAAWje,MAAM6D,EAAQugC,EAAa3iC,EAAEzD,OAEvD,IAAI6D,EAAWuiC,EACf,GAAIL,EAAU,CAGZliC,EADiBzC,eAAamF,qBAAqB6/B,EAAaJ,GAIlE,MAAO,CAAC1kC,OAAAA,EAAQN,MAAO6C,EAAU7D,MAAOyD,EAAEzD,SCdvC,MAAMqmC,GAA8B,CACzC1mB,WAAY2mB,UACZzmB,YAAa,MACbC,oBAnCEC,GAGF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,EACZzgB,EAAiBkE,EAAG,WACpB,MAAMwtB,WAACA,EAAUrtB,QAAEA,EAAOstB,IAAEA,EAAGC,gBAAEA,GAAmBlP,EAGpDniB,OAAKC,OACDqB,eAAagwB,+BAA+BxtB,EAH9B,GAId,IAAM,4DACF,eAAeA,uBAEvB,MAAMmI,EAAW3K,eAAaiwB,kBAC1B5tB,EAAEzC,MAA2CiwB,EAAYrtB,EAR3C,EASHstB,EAAKC,GACpB,IAAI/rB,EAEJ,GAA6B,IAAzB2G,EAASsE,aAA+C,IAA1BtE,EAASqE,cACvCtQ,OAAKwxB,YAAYvlB,EAASwlB,QAASxlB,EAASlI,UAC9CuB,EAAMoc,EAAS,CAACxB,OAAQ,CAACvc,EAAAA,GAAIyc,QAAAA,QACxB,CACL,MAAM7S,EAAU6S,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACrC6C,EAAU9D,OAAK8gB,eAAend,EAAEzC,OAChCmD,EAAS2rB,GAAKziB,EAAS5J,EAAEzC,MAAOyC,EAAEzD,MAAO4D,EAASmI,EAAU,OAClE3G,EAAM8a,EAAQmB,eACVtV,EAASlI,SAAUJ,EAAEzD,MAAOmE,EAAOpD,QAEzC,OAAOqE,IC2CF,MAAMmhC,GAAsC,CACjD5mB,WAAY6mB,kBACZ3mB,YAAa,MACbC,oBA7E8BC,GAK9B,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3B7V,GAACA,EAAE0X,MAAEA,EAAKtU,OAAEA,GAAU0S,EACtBvc,EAAIme,EACVriB,EAAiB,CAACqiB,EAAOtU,GAAS,mBAClC,MAAM2jB,WAACA,EAAUrtB,QAAEA,EAAOstB,IAAEA,EAAGC,gBAAEA,GAAmBlP,EAE9ClW,EAAW3K,eAAaiwB,kBAC1B5tB,EAAEzC,MAA2CiwB,EAAYrtB,EACzD,EAAmBstB,EAAKC,GACtB9jB,EAAU6S,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACrC2Q,EAAYvN,SACd4H,EAASlI,SAAUJ,EAAEzD,MACrB0wB,GAAiBrjB,EAAS5J,EAAEzC,MAAOyC,EAAEzD,MAAO+L,GAAUhL,QACpDmL,EAAeH,EAASG,aACxBC,EAAcJ,EAASI,YACvBE,EAAiBN,EAASM,eAC1BC,EAAgBP,EAASO,cACzBE,EAAwBT,EAASS,sBACjCC,EAAuBV,EAASU,qBAChCM,EAAUN,EAAuB,EAAIV,EAASY,QAAQK,KACtDH,EAASL,EAAwB,EAAIT,EAASY,QAAQG,IACtDwD,EACFnM,SAAgBV,EAAEzC,MAA2C,WAE3D0wB,EAASxR,EAAQtf,KAAKO,IAAI+I,EAAG5I,QAAQP,OACrCyP,EAAQrM,SACV+F,EAAGlJ,MAA2C,UAAW0wB,GAE7D,IAAK,IAAIhrB,EAAI,EAAGA,EAAIqF,EAAS8B,YAAanH,EACxC,IAAK,IAAI5E,EAAI,EAAGA,EAAIiK,EAASkC,aAAcnM,EACzC,IAAK,IAAIuS,EAAM,EAAGA,EAAMtI,EAAS+C,WAAYuF,EAC3C,IAAK,IAAIO,EAAM,EAAGA,EAAM7I,EAASsD,UAAWuF,EAAK,CAE/C,MAAM+c,EAAYtd,EAAMxH,EAClB+kB,EAAYhd,EAAM7H,EACxB,IAAIgE,EAAU,EACd,IAAK,IAAI8f,EAAK,EAAGA,EAAKrkB,EAAuBqkB,GAAMxkB,EAAgB,CACjE,MAAMsK,GAAOgb,EAAYd,GAAM3kB,EAC/B,KAAIyK,EAAM,GAAKA,GAAO5K,EAAS2C,WAC3BxH,KAAKE,MAAMuP,KAASA,GAGxB,IAAK,IAAIma,EAAK,EAAGA,EAAKrkB,EAAsBqkB,GAAMxkB,EAAe,CAC/D,MAAMwK,GAAO8a,EAAYd,GAAM3kB,EAC/B,GAAI2K,EAAM,GAAKA,GAAO/K,EAASkD,UAC3B/H,KAAKE,MAAM0P,KAASA,EACtB,SAEF,MAIMnF,EAJSnF,EAAwBC,EAAuB,EACzDiF,EAAUvQ,IAAIuF,EAAGiQ,EAAKG,EAAKhV,KACjB+uB,EAAKpkB,EAAuBqkB,EAEV,EAAI,EACxB,IAATnf,IAKJZ,GADcP,EAAMrP,IAAIuF,EAAGiQ,EAAKG,EAAKhV,GAClB6P,IAGvBrB,EAAG/O,IAAIwP,EAASrK,EAAG2N,EAAKO,EAAK9S,GAKrC,OAAOoe,EAAQmB,eAAe/Q,EAAGtP,MAAOsP,EAAGtQ,MAAOsQ,EAAGvP,UCrEhD,MAAM0lC,GAAwC,CACnD9mB,WAAY+mB,oBACZ7mB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQiC,MAAAA,EAAO/B,QAAAA,MAC3B,MAAMzc,EAACA,GAAKuc,GACNiR,WAACA,EAAUrtB,QAAEA,EAAOstB,IAAEA,EAAGN,oBAAEA,GAC7B3O,EACEhC,EAAaC,EACnB3gB,EAAiBkE,EAAG,qBAEpB,MAAM1C,EAASkf,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACvCgL,EAAW3K,eAAaiwB,kBAC1B5tB,EAAEzC,MAA2CiwB,EAAYrtB,EACzD,CAAC,EAAG,GAAIstB,IACLyV,EAAQC,YClBfv5B,EAAqB2b,EAAkBhpB,EACvC4wB,EAA8B7kB,GAChC,MACM86B,EAAW/W,GAAKziB,EAAS2b,EAAQhpB,EADvBF,OAAK8gB,eAAeoI,GACmBjd,EAAU,OAC3DuF,EAAeof,GACjBrjB,EAAS2b,EAAQhpB,EAAO+L,GAAU,EAAM6kB,GAE5C,MAAO,CAACiW,EAAS9lC,OAAQuQ,EAAavQ,QDWV+lC,CACtB/lC,EAAQ0C,EAAEzC,MAAOyC,EAAEzD,MAAO4wB,EAAqB7kB,GAE7Cg7B,EACF9mB,EAAWje,MAAM2kC,EAAwB56B,EAASlI,SAAUJ,EAAEzD,OAC5DgnC,EACF/mB,EAAWje,MAAM4kC,EAAuB76B,EAASlI,SAAUJ,EAAEzD,OACjE,MAAO,CACL,CAACsB,OAAQylC,EAAc/lC,MAAO+K,EAASlI,SAAU7D,MAAOyD,EAAEzD,OAC1D,CAACsB,OAAQ0lC,EAAehmC,MAAO+K,EAASlI,SAAU7D,MAAO,YEwBxD,MAAMinC,GAAgC,CAC3CtnB,WAAYunB,YACZrnB,YAAa,MACbC,oBApDwBC,GAKxB,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,GACNmnB,SAACA,EAAQC,KAAEA,GAAQnlB,EAEzB1iB,EAAiBkE,EAAG,aAEpB,MAAMI,EAAWsjC,EAAStlC,IACtB,CAAC67B,EAAGp5B,IAAMo5B,EAAE,GAAqBj6B,EAAEzC,MAAMsD,GAAKo5B,EAAE,IAE9Ct6B,EAAQ+jC,EAAStlC,IAAI67B,GAAKA,EAAE,IAC5B/5B,EAAMwjC,EAAStlC,IAAI,CAAC67B,EAAGp5B,IAAMo5B,EAAE,GAAKj6B,EAAEzC,MAAMsD,IAC5CwD,EAAkB,YAATs/B,EAAqB,EAAI,EAElCviC,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnCmoB,EAAQzlB,EAAEzC,MAAMU,OAChB+lB,EAAW3nB,OAAK8gB,eAAend,EAAEzC,OAEjC6f,EAAa/gB,OAAK8H,cAAc/D,GAChC6c,EAAa7c,EAASnC,OACtBif,EAAgB7gB,OAAK8gB,eAAe/c,GACpC6U,EACF5Y,OAAKghB,uBAAuBrd,EAAEzD,MAA0B6gB,GAE5D,IAAK,IAAIvc,EAAI,EAAGA,EAAIuc,EAAYvc,IAAK,CACnC,IAAI+iC,EAASvnC,OAAK2E,WAAWH,EAAGoc,EAAYC,GAC5C,IAAK,IAAIrc,EAAI,EAAGA,EAAIoc,EAAYpc,IAC1B+iC,EAAO/iC,GAAKlB,EAAMkB,GACpB+iC,EAAO/iC,GAAgB,EAAXlB,EAAMkB,GAAS+iC,EAAO/iC,GAAKwD,EAC9Bu/B,EAAO/iC,IAAMX,EAAIW,KAC1B+iC,EAAO/iC,GAAoB,GAAdX,EAAIW,GAAK,GAAS+iC,EAAO/iC,GAAKwD,GAG/Cu/B,EAASA,EAAOxlC,IAAI,CAACkR,EAAGzO,IAAMyO,EAAI3P,EAAMkB,IAExC,MAAMgjC,EAAUxnC,OAAKkL,WAAWq8B,EAAQne,EAAOzB,GAE/C/O,EAAQpU,GAAKO,EAAMyiC,GAKrB,MAAO,CAAChmC,OAFM4e,EAAQle,MAAM0W,EAAS7U,EAAUJ,EAAEzD,OAE1BgB,MAAO6C,EAAU7D,MAAOyD,EAAEzD,SChD7CunC,GAA0BrnC,eAAaqnC,wBAIhCC,GAA0C,CACrD7nB,WAAY8nB,sBACZ5nB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQE,QAAAA,EAAS+B,MAAAA,MAC7B,MAAM1I,MAACA,EAAKC,OAAEA,GAAUwG,GAClBvG,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAc+tB,mBAAEA,GAChDzlB,EAEEhC,EAAaC,EAEnB3gB,EAAiBga,EAAO,2BAExB,MAAMK,EAAYqG,EAAWrf,KAAKO,IAAIoY,EAAMjY,QAAQP,OAC9C8Y,EAAaoG,EAAWrf,KAAKO,IAAIqY,EAAOlY,QAAQP,QAEhD4mC,gBAACA,EAAeC,aAAEA,GAAgBL,GACpC3tB,EAAWC,EAAYJ,EAAeC,EAAcC,EACpD+tB,GAEJ,MAAO,CAACC,EAAiBC,KCvBvBC,GAA0B3nC,eAAa2nC,wBAIhCC,GAA0C,CACrDnoB,WAAYooB,sBACZloB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQE,QAAAA,EAAS+B,MAAAA,MAC7B,MAAM1I,MAACA,EAAKC,OAAEA,GAAUwG,GAClBvG,cAACA,EAAaC,aAAEA,EAAYC,eAAEA,EAAcquB,aAAEA,GAChD/lB,EAEEhC,EAAaC,EAEnB3gB,EAAiBga,EAAO,8BAExB,MAAMK,EAAYqG,EAAWrf,KAAKO,IAAIoY,EAAMjY,QAAQP,OAC9C8Y,EAAaoG,EAAWrf,KAAKO,IAAIqY,EAAOlY,QAAQP,OAEhDknC,EAAmBxuB,EACnByuB,EAAkBxuB,EAClByuB,EAAoBxuB,EACpByuB,EAAkBJ,GAElBL,gBAACA,EAAeU,eAAEA,GAAkBR,GACtCjuB,EAAWC,EAAYouB,EAAkBC,EACzCC,EAAmBC,GAEvB,MAAO,CAACT,EAAiBU,KCgBtB,MAAMC,GAA4B,CACvC3oB,WAAY4oB,QACZ1oB,YAAa,MACbC,oBA5CEC,GAEF,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,GACNmnB,SAACA,EAAQqB,cAAEA,GAAiBvmB,EAElC1iB,EAAiBkE,EAAG,OAEpB,MAAMI,EAAWsjC,EAAStlC,IACtB,CAAC67B,EAAGp5B,IAAMo5B,EAAE,GAAqBj6B,EAAEzC,MAAMsD,GAAKo5B,EAAE,IAE9Ct6B,EAAQ+jC,EAAStlC,IAAI67B,GAAKA,EAAE,IAE5B74B,EAAQqb,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACnCkkB,EAAQnlB,OAAK8H,cAAcnE,EAAEzC,OAC7BkoB,EAAQzlB,EAAEzC,MAAMU,OAChB+lB,EAAW3nB,OAAK8gB,eAAend,EAAEzC,OAEjC6f,EAAa/gB,OAAK8H,cAAc/D,GAChC6c,EAAa7c,EAASnC,OACtBif,EAAgB7gB,OAAK8gB,eAAe/c,GACpC6U,EACF5Y,OAAKghB,uBAAuBrd,EAAEzD,MAA0B6gB,GAEtC,IAAlB2nB,GACF9vB,EAAQxT,KAAKsjC,GAGf,IAAK,IAAIlkC,EAAI,EAAGA,EAAI2gB,EAAO3gB,IAAK,CAC9B,MACMmkC,EADS3oC,OAAK2E,WAAWH,EAAG4kB,EAAOzB,GAChB5lB,IAAI,CAACkR,EAAGzO,IAAMyO,EAAI3P,EAAMkB,IAGjDoU,EAFiB5Y,OAAKkL,WAAWy9B,EAAW/nB,EAAYC,IAEpC9b,EAAMP,GAK5B,MAAO,CAAChD,OAFM4e,EAAQle,MAAM0W,EAAS7U,EAAUJ,EAAEzD,OAE1BgB,MAAO6C,EAAU7D,MAAOyD,EAAEzD,SCxCtC0oC,GAAa1jB,EAAgB2jB,aAAatjB,GAAO,EAAIA,GAErDujB,GAAiC,CAC5CjpB,WAAYgpB,aACZ9oB,YAAa,MACbC,WAAY4oB,ICJDG,GAAuC,CAClDlpB,WAAYmpB,mBACZjpB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQiC,MAAAA,EAAO/B,QAAAA,MAC3B,MAAM8jB,MAACA,GAAShkB,GACV+oB,QAACA,EAAOC,UAAEA,EAASC,OAAEA,GAAUhnB,EAC/BhC,EAAaC,EAEb5S,EAASxN,OAAKghB,uBAChBkjB,EAAMhkC,MAA0BF,OAAK8H,cAAco8B,EAAMhjC,SACtD4M,EAAOoO,EAAaC,EAAYhK,GAAe+xB,EAAMhjC,OAErDkoC,EAASC,GACZ/nC,eAAagoC,eAAeH,EAAQjtB,EAAaC,GAG/CotB,EAAYniC,KAAKoiC,IAAIP,GACrBQ,EAAYriC,KAAKozB,IAAIyO,GACrBxsB,EAAY0D,EAAWrf,KAAKO,IAAI6iC,EAAM1iC,QAAQP,OAEpD,IAAK,IAAIkjC,EAAW,EAAGA,EAAWr2B,EAAOq2B,IAAY,CACnD,MAAMruB,EAAcquB,EAAWhoB,EAAaD,EAAc/J,EAE1D,IAAK,IAAImiB,EAAM,EAAGA,EAAMpY,EAAaoY,IAAO,CAC1C,MAAMve,EAAYue,GAAOnY,EAAahK,GAEtC,IAAK,IAAIqiB,EAAM,EAAGA,EAAMrY,EAAYqY,IAAO,CACzC,MAAMve,EAAYue,EAAMriB,EAExB,IAAK,IAAIjE,EAAU,EAAGA,EAAUiE,EAAajE,IAAW,CACtD,MAAMq5B,EAAS,CAACz5B,EAAOwmB,EAAKE,EAAKtmB,GAE3BvK,EAAI4jC,EAAO,GACXl9B,EAAIk9B,EAAO,GAGjB,IAAInD,GAAUzgC,EAAIylC,GAAWK,GAAap/B,EAAIg/B,GAAWE,EACrDG,GAAU/lC,EAAIylC,GAAWG,GAAal/B,EAAIg/B,GAAWI,EACzDrF,EAASh9B,KAAK4O,MAAMouB,EAASgF,GAC7BM,EAAStiC,KAAK4O,MAAM0zB,EAASL,GAE7B,IAAI/E,EAAc4E,EAUlB,GATyB,iBAAdA,IAEP5E,EADc,IAAZp2B,EA7BW,IAgCCg7B,EAAUh7B,IAKxBk2B,GAAU,GAAKA,EAASjoB,GAAcutB,GAAU,GAChDA,EAASxtB,EAAa,CAMxBooB,EAAc7nB,EADV3G,EAHqB4zB,GAAUvtB,EAAahK,GACvBiyB,EAASjyB,EAEsBjE,GAK1DV,EADesI,EAAcC,EAAYE,EAAY/H,GACpCo2B,KAOzB,MAAO,CAAC9iC,OADO2e,EAAWje,MAAMsL,EAAQ02B,EAAMhjC,MAAOgjC,EAAMhkC,OAC3CgB,MAAOgjC,EAAMhjC,MAAOhB,MAAOgkC,EAAMhkC,SCtExC8V,GAAQkP,EAAgBykB,QAAQpkB,IAE3C,MAAMqkB,EAAOxiC,KAAKE,MAAMie,GACxB,OAAIA,EAAKqkB,EAAO,GACPxiC,KAAKE,MAAMie,GACTA,EAAKqkB,EAAO,GACdxiC,KAAK0L,KAAKyS,GAEbqkB,EAAO,GAAQ,EACVA,EAEAA,EAAO,IAKPC,GAA4B,CACvChqB,WAAY8pB,QACZ5pB,YAAa,MACbC,WAAYhK,ICnBR8zB,GAAaxoC,eAAayoC,gBAC1B9X,GAAQ3wB,eAAa0oC,WAEdC,GAAO/kB,EAAgBglB,OAAO3kB,GACrCA,GAAM,EACD0M,GAAQ1M,EAERukB,IAAc1iC,KAAKue,IAAIJ,GAAM,IAI3B4kB,GAA2B,CACtCtqB,WAAYqqB,OACZnqB,YAAa,MACbC,WAAYiqB,ICdDG,GACTllB,EAAgBmlB,UAAU9kB,GAAO,GAAK,EAAIne,KAAKue,KAAKJ,KAE3C+kB,GAA8B,CACzCzqB,WAAYwqB,UACZtqB,YAAa,MACbC,WAAYoqB,ICND1L,GAAOxZ,EAAgBqlB,OAAOhlB,GACrCA,EAAK,GACC,EACCA,EAAK,EACP,EAEA,GAIEilB,GAA2B,CACtC3qB,WAAY0qB,OACZxqB,YAAa,MACbC,WAAY0e,ICbD8K,GAAMtkB,EAAgBulB,MAAMllB,GAAOne,KAAKoiC,IAAIjkB,IAE5CmlB,GAA0B,CACrC7qB,WAAY4qB,MACZ1qB,YAAa,MACbC,WAAYwpB,ICLDmB,GAAOzlB,EAAgB0lB,OAAOrlB,GAAOne,KAAKujC,KAAKplB,IAE/CslB,GAA2B,CACtChrB,WAAY+qB,OACZ7qB,YAAa,MACbC,WAAY2qB,ICCRG,GAAY1jC,KAAKkf,IADP,uBACsB,EAEzBykB,GAAW7lB,EAAgB8lB,WAAWzlB,IAGjD,MAAM0lB,EAAW1lB,GAAMulB,GAIjBI,EAAW3lB,EAAKulB,GAEhBK,EAAO/jC,KAAKue,IAAIJ,GACtB,IAAIxf,EASJ,OANEA,EADEmlC,EACOC,EACAF,EACA1lB,EAEAne,KAAKkf,IAAI,EAAM6kB,GAEnBplC,IAGIqlC,GAA+B,CAC1CvrB,WAAYmrB,WACZjrB,YAAa,MACbC,WAAY+qB,aC9BEM,GAAUprB,GAKxB,MAAMC,OAACA,EAAMiC,MAAEA,EAAK/B,QAAEA,GAAWH,GAC3Btc,EAACA,GAAKuc,GACNiJ,KAACA,GAAQhH,EAEf1iB,EAAiBkE,EAAG,aAEpB,MAAMylB,EAAQzlB,EAAEzC,MAAMU,OAEhBkJ,EAAqB,IAAIlL,MAAMwpB,GACrC,IAAK,IAAI5kB,EAAI,EAAGA,EAAIsG,EAASlJ,OAAQ4C,IACnCsG,EAAStG,GAAKb,EAAEzC,MAAMioB,EAAK3kB,IAG7B,MACMuB,EAASkjB,GADA7I,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACL0C,EAAEzC,MAAOyC,EAAEzD,MAAOipB,EAAMre,GAG7D,MAAO,CAACtJ,OADO4e,EAAQle,MAAM6D,EAAQ+E,EAAUnH,EAAEzD,OACjCgB,MAAO4J,EAAU5K,MAAOyD,EAAEzD,OAGrC,MAAMorC,GAAgC,CAC3CzrB,WAAY0rB,YACZxrB,YAAa,MACbC,WAAYqrB,ICgCP,MAAMG,GAAqC,CAChD3rB,WAAY4rB,iBACZ1rB,YAAa,MACbC,oBA7D6BC,GAK7B,MAAMC,OAACA,EAAME,QAAEA,EAAO+B,MAAEA,GAASlC,GAC3Btc,EAACA,GAAKuc,GACN/U,WAACA,EAAUk8B,SAAEA,GAAYllB,EAE/B1iB,EAAiB,CAACkE,GAAI,kBAEtB,MAAMsE,EAAOjI,OAAK8H,cAAcqD,GAE1BugC,EAA4C,CAAC,CAAC,EAAG,IACvDA,EAAiBhjC,QAAS2+B,GAE1B,IAAK,IAAI7iC,EAAI,EAAI2G,EAAWvJ,OAAQ4C,EAAIb,EAAEzC,MAAMU,SAAU4C,EACxDknC,EAAiBhjC,KAAK,CAAC,EAAG,IAG5B,MAAMijC,EAAUnD,GAAYxoB,WAAW,CACrCE,OAAQ,CAACvc,EAAAA,GACTyc,QAAAA,EACA+B,MAAO,CAACklB,SAAUqE,EAAkBhD,cAAe,KAG/CkD,EACFtqC,eAAaiK,YAAYogC,EAAQzqC,MAAOiK,EAAYlD,GAAM,GAExD4jC,EAAoCvqC,eAAamK,YACnDmgC,EAAoBhqC,OAAQuJ,EAAWvJ,QAAQ,GAE7C4d,EACFle,eAAaqK,oBAAoBggC,EAAQzqC,MAAOiK,EAAYlD,GAAM,GAIhE6jC,EACFtmC,GAAQ,CAAC0a,OAHwB,CAACvc,EAAGgoC,GAGLvrB,QAAAA,EAAS+B,MAFV,CAACjhB,MAAO0qC,KAOrCG,EACFV,GAAU,CAACnrB,OAJ0B,CAACvc,EAAGmoC,GAIL1rB,QAAAA,EAAS+B,MAF5B,CAACgH,KAAM0iB,KAMtB9lC,EAASP,GACX,CAAC0a,OAHsC,CAACvc,EAAGooC,GAGb3rB,QAAAA,EAAS+B,MAFF,CAACjhB,MAAOse,KAQjD,OAJAY,EAAQmC,8BAA8BopB,GACtCvrB,EAAQmC,8BAA8BupB,GACtC1rB,EAAQmC,8BAA8BwpB,GAE/BhmC,IC5DIqhB,GAAOlC,EAAgB8mB,OAAOzmB,GAAOne,KAAKggB,KAAK7B,IAE/C0mB,GAA2B,CACtCpsB,WAAYmsB,OACZjsB,YAAa,MACbC,WAAYoH,ICJD8kB,GAA6B,CACxCrsB,WAAYssB,SACZpsB,YAAa,MACbC,WAAY,EAAEE,OAAAA,EAAQE,QAAAA,MACpB,MAAMzc,EAACA,GAAKuc,EACNC,EAAaC,EACnB3gB,EAAiBkE,EAAG,UAEpB,MAAM1C,EAASkf,EAAWrf,KAAKO,IAAIsC,EAAEnC,QAAQP,OACvC0I,EAAY,IAAIY,aAAatJ,EAAOW,QAC1C,IAAK,IAAI4C,EAAI,EAAGA,EAAIvD,EAAOW,SAAU4C,EAAG,CACtC,MAAMsE,EAAQ7H,EAAOuD,GACrBmF,EAAUnF,GAAKsE,EAAQA,EAGzB,MAAO,CAACtH,OADO2e,EAAWje,MAAMyH,EAAWhG,EAAEzC,MAAOyC,EAAEzD,OACtCgB,MAAOyC,EAAEzC,MAAOhB,MAAOyD,EAAEzD,SChBhCksC,GAAOlnB,EAAgBmnB,OAAM,CAAC9mB,EAAIpD,KAC7C,MAAMmqB,EAAYnqB,EAClB,OAAIjS,MAAMqV,GACDgnB,IAEAhnB,EAAK,EAAI,EAAI+mB,EAAUl1B,QAIrBo1B,GAA2B,CACtC3sB,WAAYwsB,OACZtsB,YAAa,MACbC,WAAYosB,ICZDK,GAAMvnB,EAAgBwnB,MAAMnnB,GAAOne,KAAKqlC,IAAIlnB,IAE5ConB,GAA0B,CACrC9sB,WAAY6sB,MACZ3sB,YAAa,MACbC,WAAYysB,ICLDG,GAAO1nB,EAAgB2nB,OAAOtnB,GAAOne,KAAKwlC,KAAKrnB,IAE/CunB,GAA2B,CACtCjtB,WAAYgtB,OACZ9sB,YAAa,MACbC,WAAY4sB,ICeP,MAAMG,GAA6B,CACxCltB,WAAYmtB,SACZjtB,YAAa,MACbC,oBAnBEC,GAEF,MAAMC,OAACA,EAAMiC,MAAEA,EAAK/B,QAAEA,GAAWH,GAC3B9b,KAACA,GAAQge,GACTxe,EAACA,GAAKuc,EACZzgB,EAAiBkE,EAAG,UAEpB,MAAM1C,EAASmf,EAAQtf,KAAKO,IAAIsC,EAAEnC,QAAQP,QACpCupB,aAACA,EAAYrM,YAAEA,EAAWtT,QAAEA,GAC9Bye,GAAWroB,EAAQkD,EAAMR,EAAEzC,MAAOyC,EAAEzD,OACxC,MAAO,CACLkgB,EAAQmB,eAAepD,EAAaxa,EAAEzD,MAAOsqB,GAC7CpK,EAAQmB,eAAe,CAAC1W,EAAQjJ,QAAS,QAASiJ,MC0EhDoiC,GAAgC,CACpCze,GACA5O,EACAoP,GACAG,GACAnK,EACAsK,GACAG,GACAG,GACAG,GACAkB,GACAS,GACApD,GACAyD,GACAhP,EACA0C,EACA6N,GACA9R,EACAmT,GACAiC,GACAW,GACAb,GACAmC,GACAmB,GACA9B,GACAwC,GACAG,GACAK,GACAE,GACAI,GACAE,GACA0B,GACAV,GACAiB,GACAhT,GACAgU,GACA9Y,EACAI,EACAsd,GACAK,GACAI,GACA5d,EACAme,GACAG,GACA9iB,EACAijB,GACArR,GACAyR,GACAI,GACAE,GACA/e,EACAkf,GACAG,GACAU,GACAE,GACAE,GACAb,GACAqB,GACArgB,EACA4gB,GACAM,GACA9gB,EACAshB,GACAzd,GACA/I,EACA8mB,GACA3d,GACAG,GACAO,GACAkd,GACAc,GACAtiB,GACA4iB,GACAG,GACAE,GACAE,GACAG,GACAviB,GACA8iB,GACAI,GACAS,GACAC,GACAvjB,GACA6jB,GACAxjB,GACA2jB,GACAG,GACAxB,GACAyB,IAGF,IAAK,MAAMG,KAAgBD,GACzBE,iBAAeD,gDCxMD"}