{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOWSz70VAMHlAxaOCR7FlI5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/defeng1/asl-assistant/blob/back-end/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjrXA-r_ZzBQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1D2d5dzadDt",
        "outputId": "a4f204d0-6e13-438a-cd93-99144196b9f2"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn6Mbya-ar3s"
      },
      "source": [
        "IMAGE_SIZE = (200, 200)\n",
        "batch_size = 32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc4WreLebgYG",
        "outputId": "98b235c3-3672-4836-f9e6-65f2aa6d301d"
      },
      "source": [
        "#Load the training, validation and test data sets\n",
        "train_dir = \"/content/gdrive/My Drive/Capstone/Dataset/demo_training_set\"\n",
        "test_dir = \"/content/gdrive/My Drive/Capstone/Dataset/demo_test\"\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=IMAGE_SIZE,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=IMAGE_SIZE,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  image_size=IMAGE_SIZE,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "print(\"Successfully loaded train and test set\")\n",
        "print('Number of training batches: %d' % tf.data.experimental.cardinality(train_ds))\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 26100 files belonging to 29 classes.\n",
            "Using 20880 files for training.\n",
            "Found 26100 files belonging to 29 classes.\n",
            "Using 5220 files for validation.\n",
            "Found 2900 files belonging to 29 classes.\n",
            "Successfully loaded train and test set\n",
            "Number of training batches: 653\n",
            "Number of validation batches: 164\n",
            "Number of test batches: 91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA89pZiHgbJD"
      },
      "source": [
        "#Run this block to load images from disk without having I/O become blocking\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dir = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkS6YOh5gzS0"
      },
      "source": [
        "#Run this block for adding artificial training data variations to reduce\n",
        "#overfitting for smaller datasets\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIsPXy6liki5"
      },
      "source": [
        "#Preprocessing input for compatibility with MobileNetV2 Model\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "#or\n",
        "# rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9227OdfciRs0",
        "outputId": "37e1488b-2e1c-4ac8-d502-415299465910"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMAGE_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps-S6bXNj7n1"
      },
      "source": [
        "image_batch, label_batch = next(iter(train_ds))\n",
        "feature_batch = base_model(image_batch)\n",
        "# print(feature_batch.shape)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqaMLj9Dki2E"
      },
      "source": [
        "# base_model.trainable = False\n",
        "# base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyFfgaXbmAHq",
        "outputId": "6766c39f-8aa2-473a-97eb-509983c8b62f"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)\n",
        "\n",
        "prediction_layer = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(len(class_names))\n",
        "])\n",
        "\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(200, 200, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1280)\n",
            "(32, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aRJYa3ovdbY",
        "outputId": "4da37daf-276a-4266-c6af-7ad72d57c40f"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['sparse_categorical_accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential_1 (Sequential)    (None, 200, 200, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_2 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "sequential_3 (Sequential)    (None, 29)                167709    \n",
            "=================================================================\n",
            "Total params: 2,425,693\n",
            "Trainable params: 2,391,581\n",
            "Non-trainable params: 34,112\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZYqM8bPww7Q",
        "outputId": "950acce2-7d87-41f6-d4d3-18677afaced6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Training the new model\n",
        "initial_epochs = 10\n",
        "\n",
        "loss0, accuracy0 = model.evaluate(val_ds)\n",
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=val_ds)\n",
        "\n",
        "# model.save(\"directory to save\")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "164/164 [==============================] - 695s 4s/step - loss: 3.7533 - sparse_categorical_accuracy: 0.0320\n",
            "initial loss: 3.75\n",
            "initial accuracy: 0.03\n",
            "Epoch 1/10\n",
            "653/653 [==============================] - 3733s 6s/step - loss: 3.3851 - sparse_categorical_accuracy: 0.0333 - val_loss: 3.3679 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 2/10\n",
            "653/653 [==============================] - 465s 713ms/step - loss: 3.3683 - sparse_categorical_accuracy: 0.0331 - val_loss: 3.3682 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 3/10\n",
            "653/653 [==============================] - 464s 711ms/step - loss: 3.3678 - sparse_categorical_accuracy: 0.0338 - val_loss: 3.3684 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 4/10\n",
            "653/653 [==============================] - 453s 694ms/step - loss: 3.3678 - sparse_categorical_accuracy: 0.0341 - val_loss: 3.3685 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 5/10\n",
            "653/653 [==============================] - 511s 783ms/step - loss: 3.3677 - sparse_categorical_accuracy: 0.0343 - val_loss: 3.3685 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 6/10\n",
            "653/653 [==============================] - 451s 690ms/step - loss: 3.3678 - sparse_categorical_accuracy: 0.0344 - val_loss: 3.3685 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 7/10\n",
            "653/653 [==============================] - 452s 692ms/step - loss: 3.3679 - sparse_categorical_accuracy: 0.0345 - val_loss: 3.3685 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 8/10\n",
            "653/653 [==============================] - 450s 689ms/step - loss: 3.3678 - sparse_categorical_accuracy: 0.0341 - val_loss: 3.3686 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 9/10\n",
            "653/653 [==============================] - 442s 676ms/step - loss: 3.3676 - sparse_categorical_accuracy: 0.0343 - val_loss: 3.3686 - val_sparse_categorical_accuracy: 0.0299\n",
            "Epoch 10/10\n",
            "653/653 [==============================] - 474s 726ms/step - loss: 3.3676 - sparse_categorical_accuracy: 0.0336 - val_loss: 3.3685 - val_sparse_categorical_accuracy: 0.0299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjEM6PG44xRU",
        "outputId": "1a962257-94a6-49c6-a703-15283cc735fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model.save(\"gdrive/My Drive/Capstone/models/transfer_dec_4_2020\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
            "INFO:tensorflow:Assets written to: gdrive/My Drive/Capstone/models/transfer_dec_4_2020/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b22kQe3mxvdK"
      },
      "source": [
        "#Run to evaluate model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
        "print(\"Trained model accuracy {}\".format(test_acc))\n",
        "\n",
        "# loaded_model = tf.keras.models.load_model(\"saved directory\")\n",
        "# test_loss, test_acc = loaded_model.evaluate(test_ds, verbose=1)\n",
        "# print(\"Loaded trained model accuracy {}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D2cCRSMzAM4"
      },
      "source": [
        "#Run to show learning curve of the model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}