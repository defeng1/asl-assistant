{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transfer_learning.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyN82hBSfjP3EwBBITM3vtpB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/defeng1/asl-assistant/blob/back-end/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjrXA-r_ZzBQ"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1D2d5dzadDt",
        "outputId": "39216e30-e59d-4441-9561-5db726cfd274"
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nn6Mbya-ar3s"
      },
      "source": [
        "IMAGE_SIZE = (200, 200)\n",
        "batch_size = 32"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zc4WreLebgYG",
        "outputId": "b9bbb023-81f4-467b-861c-e164f42737fc"
      },
      "source": [
        "#Load the training, validation and test data sets\n",
        "train_dir = \"/content/gdrive/My Drive/Capstone/Dataset/demo_training_set\"\n",
        "test_dir = \"/content/gdrive/My Drive/Capstone/Dataset/demo_test\"\n",
        "\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=IMAGE_SIZE,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  train_dir,\n",
        "  validation_split=0.2,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=IMAGE_SIZE,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "test_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  test_dir,\n",
        "  image_size=IMAGE_SIZE,\n",
        "  batch_size=batch_size\n",
        ")\n",
        "\n",
        "class_names = train_ds.class_names\n",
        "\n",
        "print(\"Successfully loaded train and test set\")\n",
        "print('Number of training batches: %d' % tf.data.experimental.cardinality(train_ds))\n",
        "print('Number of validation batches: %d' % tf.data.experimental.cardinality(val_ds))\n",
        "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_ds))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 26100 files belonging to 29 classes.\n",
            "Using 20880 files for training.\n",
            "Found 26100 files belonging to 29 classes.\n",
            "Using 5220 files for validation.\n",
            "Found 2900 files belonging to 29 classes.\n",
            "Successfully loaded train and test set\n",
            "Number of training batches: 653\n",
            "Number of validation batches: 164\n",
            "Number of test batches: 91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vA89pZiHgbJD"
      },
      "source": [
        "#Run this block to load images from disk without having I/O become blocking\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
        "test_dir = test_ds.prefetch(buffer_size=AUTOTUNE)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nkS6YOh5gzS0"
      },
      "source": [
        "#Run this block for adding artificial training data variations to reduce\n",
        "#overfitting for smaller datasets\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal'),\n",
        "  tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n",
        "])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIsPXy6liki5"
      },
      "source": [
        "#Preprocessing input for compatibility with MobileNetV2 Model\n",
        "preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n",
        "#or\n",
        "# rescale = tf.keras.layers.experimental.preprocessing.Rescaling(1./127.5, offset= -1)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9227OdfciRs0",
        "outputId": "9b374e77-64f9-4ae4-dce6-0df416222f27"
      },
      "source": [
        "# Create the base model from the pre-trained model MobileNet V2\n",
        "IMG_SHAPE = IMAGE_SIZE + (3,)\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
            "9412608/9406464 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ps-S6bXNj7n1",
        "outputId": "6c08413b-b231-4b0b-bd9c-e3d3fa02a3a2"
      },
      "source": [
        "# image_batch, label_batch = next(iter(train_ds))\n",
        "# feature_batch = base_model(image_batch)\n",
        "# print(feature_batch.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 7, 7, 1280)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqaMLj9Dki2E"
      },
      "source": [
        "# base_model.trainable = False\n",
        "# base_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyFfgaXbmAHq",
        "outputId": "8d065cdb-4966-43ad-94d1-e927c4eb290b"
      },
      "source": [
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)\n",
        "print(feature_batch_average.shape)\n",
        "\n",
        "predition_layer = tf.keras.Sequential([\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(len(class_names))\n",
        "])\n",
        "\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape)\n",
        "\n",
        "inputs = tf.keras.Input(shape=(200, 200, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = preprocess_input(x)\n",
        "x = base_model(x, training=False)\n",
        "x = global_average_layer(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "outputs = prediction_layer(x)\n",
        "model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(32, 1280)\n",
            "(32, 29)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7aRJYa3ovdbY",
        "outputId": "08d5e149-ea37-4bce-fd36-0d8500ff7910"
      },
      "source": [
        "model.compile(\n",
        "  optimizer='adam',\n",
        "  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "  metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      (None, 200, 200, 3)       0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_RealDiv (TensorF [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Sub (TensorFlowO [(None, 200, 200, 3)]     0         \n",
            "_________________________________________________________________\n",
            "mobilenetv2_1.00_224 (Functi (None, 7, 7, 1280)        2257984   \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d_4 ( (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 1280)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 29)                37149     \n",
            "=================================================================\n",
            "Total params: 2,295,133\n",
            "Trainable params: 37,149\n",
            "Non-trainable params: 2,257,984\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZYqM8bPww7Q"
      },
      "source": [
        "# Training the new model\n",
        "initial_epochs = 2\n",
        "\n",
        "loss0, accuracy0 = model.evaluate(val_ds)\n",
        "print(\"initial loss: {:.2f}\".format(loss0))\n",
        "print(\"initial accuracy: {:.2f}\".format(accuracy0))\n",
        "\n",
        "history = model.fit(train_ds,\n",
        "                    epochs=initial_epochs,\n",
        "                    validation_data=val_ds)\n",
        "\n",
        "# model.save(\"directory to save\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b22kQe3mxvdK"
      },
      "source": [
        "#Run to evaluate model on the test set\n",
        "test_loss, test_acc = model.evaluate(test_ds, verbose=1)\n",
        "print(\"Trained model accuracy {}\".format(test_acc))\n",
        "\n",
        "# loaded_model = tf.keras.models.load_model(\"saved directory\")\n",
        "# test_loss, test_acc = loaded_model.evaluate(test_ds, verbose=1)\n",
        "# print(\"Loaded trained model accuracy {}\".format(test_acc))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8D2cCRSMzAM4"
      },
      "source": [
        "#Run to show learning curve of the model\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}