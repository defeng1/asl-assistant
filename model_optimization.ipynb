{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model_optimization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOMD3FCLGb5Efi2YzCs5l8H"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ca7qJA03P7o0",
        "outputId": "87cee9fa-2b44-4fd2-988d-b1630f6f330e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "import pathlib\n",
        "from tensorflow.keras import layers\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSXk2D9UTmNQ"
      },
      "source": [
        "#Parameters\n",
        "img_height = 200\n",
        "img_width = 200\n",
        "\n",
        "num_classes = 29\n",
        "num_samples = 2048\n",
        "batch_size = 32"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znhkA38PQEZx"
      },
      "source": [
        "# Function to create model, required for KerasClassifier\n",
        "def create_model(learn_rate=0.01, neurons = 128):\n",
        "\t# create model\n",
        "\tmodel = tf.keras.Sequential([\n",
        "\t\tlayers.experimental.preprocessing.Rescaling(1./255),\n",
        "\t\tlayers.Conv2D(32, 3, activation='relu'),\n",
        "\t\tlayers.MaxPooling2D(),\n",
        "\t\tlayers.Conv2D(32, 3, activation='relu'),\n",
        "\t\tlayers.MaxPooling2D(),\n",
        "\t\tlayers.Conv2D(32, 3, activation='relu'),\n",
        "\t\tlayers.MaxPooling2D(),\n",
        "\t\tlayers.Flatten(),\n",
        "\t\tlayers.Dense(neurons, activation='relu'),\n",
        "\t\tlayers.Dense(num_classes)\n",
        "\t])\n",
        " \n",
        "\t# Compile model\n",
        "\tadam = tf.keras.optimizers.Adam(learning_rate=learn_rate)\n",
        "\tmodel.compile(\n",
        "\t\toptimizer = adam,\n",
        "\t\tloss = tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "\t\tmetrics=['accuracy'])\n",
        "\t\n",
        "\treturn model"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5CXCdMVQ_lH",
        "outputId": "ad56e623-6e41-40c5-9502-4561a88d2e7e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Importing the dataset\n",
        "data_dir = \"/content/gdrive/My Drive/Capstone/Dataset/test_set\"\n",
        "data_dir = pathlib.Path(data_dir)\n",
        "\n",
        "ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  image_size=(img_height, img_width))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8702 files belonging to 29 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDYsenGLbDxf",
        "outputId": "08718f6f-a933-495a-ec89-be12298cd813",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "images = np.zeros(shape=(num_samples, img_height, img_width, 3))\n",
        "labels = np.zeros(shape=(num_samples))\n",
        "\n",
        "i = 0\n",
        "for images_batch, labels_batch in ds.as_numpy_iterator():\n",
        "  images[i*batch_size : (i+1)*batch_size] = images_batch\n",
        "  labels[i*batch_size : (i+1)*batch_size] = labels_batch\n",
        "  print(\"Loading batch {} done\".format(i))\n",
        "  if (i + 1) * batch_size == num_samples:\n",
        "    print(\"Finished loading samples for grid search\")\n",
        "    break\n",
        "  i += 1"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading batch 0 done\n",
            "Loading batch 1 done\n",
            "Loading batch 2 done\n",
            "Loading batch 3 done\n",
            "Loading batch 4 done\n",
            "Loading batch 5 done\n",
            "Loading batch 6 done\n",
            "Loading batch 7 done\n",
            "Loading batch 8 done\n",
            "Loading batch 9 done\n",
            "Loading batch 10 done\n",
            "Loading batch 11 done\n",
            "Loading batch 12 done\n",
            "Loading batch 13 done\n",
            "Loading batch 14 done\n",
            "Loading batch 15 done\n",
            "Loading batch 16 done\n",
            "Loading batch 17 done\n",
            "Loading batch 18 done\n",
            "Loading batch 19 done\n",
            "Loading batch 20 done\n",
            "Loading batch 21 done\n",
            "Loading batch 22 done\n",
            "Loading batch 23 done\n",
            "Loading batch 24 done\n",
            "Loading batch 25 done\n",
            "Loading batch 26 done\n",
            "Loading batch 27 done\n",
            "Loading batch 28 done\n",
            "Loading batch 29 done\n",
            "Loading batch 30 done\n",
            "Loading batch 31 done\n",
            "Loading batch 32 done\n",
            "Loading batch 33 done\n",
            "Loading batch 34 done\n",
            "Loading batch 35 done\n",
            "Loading batch 36 done\n",
            "Loading batch 37 done\n",
            "Loading batch 38 done\n",
            "Loading batch 39 done\n",
            "Loading batch 40 done\n",
            "Loading batch 41 done\n",
            "Loading batch 42 done\n",
            "Loading batch 43 done\n",
            "Loading batch 44 done\n",
            "Loading batch 45 done\n",
            "Loading batch 46 done\n",
            "Loading batch 47 done\n",
            "Loading batch 48 done\n",
            "Loading batch 49 done\n",
            "Loading batch 50 done\n",
            "Loading batch 51 done\n",
            "Loading batch 52 done\n",
            "Loading batch 53 done\n",
            "Loading batch 54 done\n",
            "Loading batch 55 done\n",
            "Loading batch 56 done\n",
            "Loading batch 57 done\n",
            "Loading batch 58 done\n",
            "Loading batch 59 done\n",
            "Loading batch 60 done\n",
            "Loading batch 61 done\n",
            "Loading batch 62 done\n",
            "Loading batch 63 done\n",
            "Finished loading samples for grid search\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWuR13wiQtNY",
        "outputId": "f92dd23a-b938-42c6-c719-7759f280d59e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# create model\n",
        "model = KerasClassifier(build_fn=create_model, epochs=100, batch_size=10, verbose=1)\n",
        "\n",
        "# define the grid search parameters\n",
        "# learn_rate = [0.01, 0.1, 0.2, 0.3]\n",
        "# batch_sizes = [20, 40, 60, 80, 100]\n",
        "# epochs = [1, 5, 10]\n",
        "learn_rate = [0.01, 0.1, 0.2]\n",
        "batch_sizes = [16, 32, 64]\n",
        "epochs = [1, 5, 10]\n",
        "neurons = [64, 128, 256]\n",
        "param_grid = dict(batch_size=batch_sizes, epochs=epochs, learn_rate=learn_rate, neurons=neurons)\n",
        "\n",
        "# grid search\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-2, cv=3)\n",
        "grid_result = grid.fit(images, labels)\n",
        "\n",
        "# summarize results\n",
        "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
        "means = grid_result.cv_results_['mean_test_score']\n",
        "stds = grid_result.cv_results_['std_test_score']\n",
        "params = grid_result.cv_results_['params']\n",
        "for mean, stdev, param in zip(means, stds, params):\n",
        "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 1s 22ms/step - loss: 5.4665 - accuracy: 0.0332\n",
            "Best: 0.051770 using {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.033201 (0.006576) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.034177 (0.004182) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.035157 (0.001217) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.040037 (0.002464) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.035157 (0.004316) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.028809 (0.008973) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.035650 (0.008512) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.034675 (0.009770) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.031741 (0.003676) with: {'batch_size': 16, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.033201 (0.006576) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.030273 (0.002483) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.030273 (0.002483) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.032714 (0.002750) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.030272 (0.004515) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.037599 (0.002775) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.031248 (0.002470) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.038578 (0.006613) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.037106 (0.006567) with: {'batch_size': 16, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.030273 (0.002483) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.030273 (0.002483) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.034177 (0.004182) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.033201 (0.006573) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.035641 (0.006120) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.037108 (0.004820) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.038570 (0.011096) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.029300 (0.008384) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.035161 (0.009509) with: {'batch_size': 16, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.034177 (0.004182) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.034177 (0.004182) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.038085 (0.004304) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.028811 (0.003474) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.034187 (0.010059) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.039061 (0.003438) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.035156 (0.005474) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.028321 (0.001391) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.032225 (0.006319) with: {'batch_size': 32, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.030273 (0.002483) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.034177 (0.004182) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.035641 (0.006120) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.029297 (0.001196) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.031737 (0.002475) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.035641 (0.006120) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.035153 (0.004764) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.034179 (0.006583) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.032713 (0.005889) with: {'batch_size': 32, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.035641 (0.006120) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.030273 (0.002483) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.030273 (0.002483) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.033201 (0.007678) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.037106 (0.005630) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.034177 (0.004182) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.039065 (0.007973) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.040035 (0.006563) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.041013 (0.003138) with: {'batch_size': 32, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.046870 (0.009005) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.051770 (0.018815) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.038570 (0.014152) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.035644 (0.002749) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.035153 (0.005463) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.037115 (0.009002) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.037596 (0.003635) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.031250 (0.004197) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.036128 (0.007287) with: {'batch_size': 64, 'epochs': 1, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.030273 (0.002483) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.032713 (0.002469) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.035641 (0.006120) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.038085 (0.004304) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.034177 (0.004182) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.036621 (0.004782) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.032713 (0.004821) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.029785 (0.000680) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.038085 (0.001174) with: {'batch_size': 64, 'epochs': 5, 'learn_rate': 0.2, 'neurons': 256}\n",
            "0.034177 (0.004182) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 64}\n",
            "0.030273 (0.002483) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 128}\n",
            "0.030273 (0.002483) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.01, 'neurons': 256}\n",
            "0.029297 (0.001196) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 64}\n",
            "0.038082 (0.006637) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 128}\n",
            "0.033689 (0.006202) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.1, 'neurons': 256}\n",
            "0.033201 (0.006576) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 64}\n",
            "0.036130 (0.005635) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 128}\n",
            "0.031739 (0.002772) with: {'batch_size': 64, 'epochs': 10, 'learn_rate': 0.2, 'neurons': 256}\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}