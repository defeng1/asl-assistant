{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "handpose.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbZenXatqLrV"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import PIL.Image\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import pathlib\n",
        "import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout\n",
        "from google.colab import drive\n",
        "from IPython.display import Image\n",
        "import json\n",
        "import re\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jLmYdsjD3EdW"
      },
      "source": [
        "import cv2\n",
        "!pip install mediapipe\n",
        "import mediapipe as mp\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_hands = mp.solutions.hands\n",
        "hands = mp_hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=1,\n",
        "    min_detection_confidence=0.7)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6KQj7fhn6v3G"
      },
      "source": [
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/gdrive')\n",
        "#drive.mount('/content/gdrive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_3oznL7YXSQ"
      },
      "source": [
        "# check number of files in each directory\n",
        "\n",
        "import glob\n",
        "\n",
        "classnames = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
        "#lassnames = ['W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
        "totalcount = 0\n",
        "\n",
        "for name in classnames:\n",
        "  data_files = glob.glob(\"/content/gdrive/My Drive/Capstone/Dataset/demo_test/\" + name + \"/*\")\n",
        "  count = 0\n",
        "  path = \"/content/gdrive/My Drive/Capstone/Dataset/handpose_test/{0}/\".format(name)\n",
        "  ! mkdir -pv \"$path\"\n",
        "  for i, data_file in enumerate(data_files):\n",
        "    count += 1\n",
        "    totalcount += 1\n",
        "    file_name = data_file.split('/')[-1].replace('.png', '')\n",
        "\n",
        "    image = cv2.flip(cv2.imread(data_file), 1)\n",
        "    # Convert the BGR image to RGB before processing.\n",
        "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "    with open(\"/content/gdrive/My Drive/Capstone/Dataset/handpose_test/{0}/{1}.json\".format(name, file_name), 'w') as f:\n",
        "\n",
        "       if not results.multi_hand_landmarks:\n",
        "          continue\n",
        "       for hand_landmarks in results.multi_hand_landmarks:\n",
        "          oneline = str.join(\" \", str(hand_landmarks).splitlines())\n",
        "          \n",
        "          \"\"\"\n",
        "          Ugly text pre-processing\n",
        "          \"\"\"\n",
        "          for r in (('x:', '\"x\":'), ('z:', ',\"z\":'), ('visibility:', ',\"visibility\":'), ('y:', ',\"y\":'),('presence:', ',\"presence\":')):\n",
        "              oneline = oneline.replace(*r)\n",
        "          landmarks = re.findall(r'\\{(.*?)\\}', oneline)\n",
        "          json_o = '{'\n",
        "          for idx, x in enumerate(landmarks):\n",
        "            json_o += '\"{0}\": '.format(idx) + '{' + x + '}, \\n'\n",
        "          json_o = json_o[:-3] + '}'\n",
        "\n",
        "          #Finally gets json in right format! Yay\n",
        "          hello = json.loads(json_o)\n",
        "          f.write(str(hello))\n",
        "\n",
        "  print(name + \":\" + str(count))\n",
        "print(\"total number of images:\" + str(totalcount))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IAb77sHUq5U"
      },
      "source": [
        "help(mp.solutions.hands)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZdxGQxvqLmZR"
      },
      "source": [
        "classnames = ['A']\n",
        "totalcount = 0\n",
        "\n",
        "for name in classnames:\n",
        "  data_files = glob.glob(\"/content/gdrive/My Drive/Capstone/Dataset/demo_test/\" + name + \"/*\")\n",
        "  count = 0\n",
        "  path = \"/content/gdrive/My Drive/Capstone/Dataset/handpose_test/{0}/\".format(name)\n",
        "  ! mkdir -pv \"$path\"\n",
        "  for i, data_file in enumerate(data_files[:1]):\n",
        "    count += 1\n",
        "    totalcount += 1\n",
        "    file_name = data_file.split('/')[-1].replace('.png', '')\n",
        "\n",
        "    image = cv2.flip(cv2.imread(data_file), 1)\n",
        "    # Convert the BGR image to RGB before processing.\n",
        "    results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "\n",
        "    if not results.multi_hand_landmarks:\n",
        "      continue\n",
        "    for hand_landmarks in results.multi_hand_landmarks:\n",
        "      oneline = str.join(\" \", str(hand_landmarks).splitlines())\n",
        "      \n",
        "      \"\"\"\n",
        "      Ugly text pre-processing\n",
        "      \"\"\"\n",
        "      for r in (('x:', '\"x\":'), ('z:', ',\"z\":'), ('visibility:', ',\"visibility\":'), ('y:', ',\"y\":'),('presence:', ',\"presence\":')):\n",
        "          oneline = oneline.replace(*r)\n",
        "      landmarks = re.findall(r'\\{(.*?)\\}', oneline)\n",
        "      json_o = '{'\n",
        "      for idx, x in enumerate(landmarks):\n",
        "        json_o += '\"{0}\": '.format(idx) + '{' + x + '}, \\n'\n",
        "      json_o = json_o[:-3] + '}'\n",
        "\n",
        "      #Finally gets json in right format! Yay\n",
        "      hello = json.loads(json_o)\n",
        "      image = []\n",
        "      for idx, i in enumerate(hello.items()):\n",
        "          image.append([i[1]['x'], i[1]['y'], i[1]['z']])\n",
        "      \n",
        "      print(tf.convert_to_tensor(image))\n",
        "  print(name + \":\" + str(count))\n",
        "print(\"total number of images:\" + str(totalcount))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAIzyKK-EvTj"
      },
      "source": [
        "df = pd.DataFrame(columns=['x', 'class'])\n",
        "\n",
        "import glob\n",
        "classnames = ['A','B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
        "#classnames = ['W', 'X', 'Y', 'Z', 'del', 'nothing', 'space']\n",
        "totalcount = 0\n",
        "\n",
        "for name in classnames:\n",
        "  data_files = glob.glob(\"/content/gdrive/My Drive/Capstone/Dataset/handpose_test/\"+ name + \"/*\")\n",
        "  count = 0\n",
        "  for i, data_file in enumerate(data_files):\n",
        "      with open(data_file, 'r') as json_file: \n",
        "          data = json_file.read().replace('\\n', '')\n",
        "          data = data.replace(\"'\", '\"')\n",
        "          try:\n",
        "            data = json.loads(data) \n",
        "          except:\n",
        "            continue\n",
        "      image = []\n",
        "      for idx, i in enumerate(data.items()):\n",
        "          image.append([i[1]['x'], i[1]['y'], i[1]['z']])\n",
        "      image = np.array(image)\n",
        "      df.loc[len(df)] = [image, name]\n",
        "      \n",
        "\n",
        "  print(name + \":\" + str(count))\n",
        "print(\"total number of images:\" + str(totalcount))\n",
        "df.to_csv(\"/content/gdrive/My Drive/Capstone/Dataset/handpose_test.csv\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kt61-SS4DXDS"
      },
      "source": [
        "#df = df[(df['class'] < 26)]\n",
        "df.to_csv(\"/content/gdrive/My Drive/Capstone/Dataset/df.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgISLRq-Csqf"
      },
      "source": [
        "def converter(x):\n",
        "    astr = x.split('\\n')\n",
        "    astr = [ x.replace('[','').replace(']','').split('\\n') for x in astr]\n",
        "    astr = [ x[0].split() for x in astr]\n",
        "    new_arr = np.array( astr, 'float32' )\n",
        "    return new_arr\n",
        "\n",
        "df = pd.read_csv(\"/content/gdrive/My Drive/Capstone/Dataset/df.csv\", usecols=['x', 'class'])\n",
        "#print(df.loc[0, 'x'])\n",
        "df2 = pd.DataFrame(columns=['x', 'class'])\n",
        "for idx, row in df.iterrows():\n",
        "  arr = converter(row['x'])\n",
        "  df2.loc[len(df2)] = [arr, row['class']]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIRCDAPkFZ0o"
      },
      "source": [
        "df = df2.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raQFh6Flra27"
      },
      "source": [
        "from collections import Counter\n",
        "\n",
        "Counter(df['class'].values)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Xx1u6GuslC"
      },
      "source": [
        "#df = pd.read_csv(\"/content/gdrive/My Drive/Capstone/Dataset/handpose_test.csv\", usecols=['x', 'class'])\n",
        "\n",
        "#for idx, row in df.iterrows():\n",
        "#  df.loc[idx, 'x'] = converter(row['x'])\n",
        "\n",
        "df['class'] = pd.Categorical(df['class'])\n",
        "df['class'] = df['class'].cat.codes\n",
        "#test_df = df.copy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vj7q65-vFRCi"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VjXdxazRxIai"
      },
      "source": [
        "ds\n",
        "for feat, targ in ds.take(5):\n",
        "  #print ('Features: {}, Target: {}'.format(feat, targ))\n",
        "  print(len(feat), len(targ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpnyzos9gQpW"
      },
      "source": [
        "def df_to_dataset(dataframe, shuffle=True, batch_size=32):\n",
        "  dataframe = dataframe.copy()\n",
        "  labels = dataframe.pop('class')\n",
        "  vals = [tf.convert_to_tensor(x) for x in dataframe['x'].values]\n",
        "  ds = tf.data.Dataset.from_tensor_slices((vals, labels))\n",
        "  print(ds)\n",
        "  if shuffle:\n",
        "    ds = ds.shuffle(buffer_size=len(dataframe))\n",
        "  ds = ds.batch(batch_size)\n",
        "  ds = ds.prefetch(batch_size)\n",
        "  return ds\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zzn8pEyjFZKb"
      },
      "source": [
        "ds = df_to_dataset(df)\n",
        "for feat, targ in ds.take(5):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHiSQedkPNWh"
      },
      "source": [
        "test_df = test_df[(test_df['class'] < 26)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9yJ-1O4UFdDx"
      },
      "source": [
        "test_ds = df_to_dataset(test_df)\n",
        "for feat, targ in test_ds.take(5):\n",
        "  print ('Features: {}, Target: {}'.format(feat, targ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5IxCol4zxl0"
      },
      "source": [
        "test_ds.element_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nupn9ofUjB9I"
      },
      "source": [
        "\n",
        "model = Sequential([\n",
        "    Dense(32, input_shape=(21, 3), kernel_initializer='he_uniform'),\n",
        "    Flatten(),\n",
        "    Activation('relu'),\n",
        "    Dense(26),\n",
        "    Activation('sigmoid'),\n",
        "])\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), \n",
        "              metrics=['sparse_categorical_accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IsZ8jptzNrj"
      },
      "source": [
        "model.fit(ds, epochs=50)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YDHuv-15y9A"
      },
      "source": [
        "model.save(\"/content/gdrive/My Drive/Capstone/models/handpose.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zdsIa7jG8m1W"
      },
      "source": [
        "model = keras.models.load_model(\"/content/gdrive/My Drive/Capstone/models/handpose.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPsAqtTKIe7I"
      },
      "source": [
        "test_ds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T01LMZ1pELJU"
      },
      "source": [
        "print(\"Evaluate\")\n",
        "result = model.evaluate(test_ds)\n",
        "dict(zip(model.metrics_names, result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_ZeheJ5fNe8"
      },
      "source": [
        "model.predict(test_ds[:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4f4kNKVMdBuB"
      },
      "source": [
        "hands = mp_hands.Hands(\n",
        "    static_image_mode=True,\n",
        "    max_num_hands=1,\n",
        "    min_detection_confidence=0.5)\n",
        "\n",
        "image = cv2.flip(cv2.imread(\"/content/gdrive/My Drive/Capstone/Dataset/demo_training_set/F/MaxF299.png\"), 1)\n",
        "# Convert the BGR image to RGB before processing.\n",
        "results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "annotated_image = image.copy()\n",
        "\n",
        "for hand_landmarks in results.multi_hand_landmarks:\n",
        "\n",
        "    mp_drawing.draw_landmarks(\n",
        "        annotated_image, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
        "    cv2.imwrite(\n",
        "        'annotated_image.png', cv2.flip(image, 1))\n",
        "    oneline = str.join(\" \", str(hand_landmarks).splitlines())\n",
        "\n",
        "    \"\"\"\n",
        "    Ugly text pre-processing\n",
        "    \"\"\"\n",
        "    for r in (('x:', '\"x\":'), ('z:', ',\"z\":'), ('visibility:', ',\"visibility\":'), ('y:', ',\"y\":'),('presence:', ',\"presence\":')):\n",
        "        oneline = oneline.replace(*r)\n",
        "    landmarks = re.findall(r'\\{(.*?)\\}', oneline)\n",
        "    json_o = '{'\n",
        "    for idx, x in enumerate(landmarks):\n",
        "        json_o += '\"{0}\": '.format(idx) + '{' + x + '}, \\n'\n",
        "    json_o = json_o[:-3] + '}'\n",
        "\n",
        "    #Finally gets json in right format! Yay\n",
        "    hello = json.loads(json_o)\n",
        "\n",
        "    image_arr = []\n",
        "    for idx, i in enumerate(hello.items()):\n",
        "        #print(i)\n",
        "        image_arr.append([i[1]['x'], i[1]['y'], i[1]['z']])\n",
        "    \n",
        "    \n",
        "    \n",
        "    #print(image_arr)\n",
        "    image_arr = np.array(image_arr)\n",
        "    image_arr = np.expand_dims(image_arr, 0)\n",
        "    im_tensor = tf.convert_to_tensor(image_arr)\n",
        "\n",
        "    pred = model.predict(im_tensor, batch_size=1)\n",
        "    print(np.argmax(pred))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}